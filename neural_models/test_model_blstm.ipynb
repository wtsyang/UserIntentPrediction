{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-f\n",
      "Indexing word vectors.\n",
      "Processing text dataset\n",
      "Found 10020 texts.\n",
      "Found 18098 unique tokens.\n",
      "Shape of data tensor: (10020, 1)\n",
      "Shape of label tensor: (10020, 12)\n",
      "Preparing embedding matrix.\n",
      "Training model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8064 samples, validate on 986 samples\n",
      "Epoch 1/100\n",
      "8064/8064 [==============================] - 3s 427us/step - loss: 0.6785 - binary_accuracy: 0.5422 - val_loss: 0.6599 - val_binary_accuracy: 0.5622\n",
      "Epoch 2/100\n",
      "8064/8064 [==============================] - 2s 200us/step - loss: 0.6353 - binary_accuracy: 0.5668 - val_loss: 0.6055 - val_binary_accuracy: 0.6344\n",
      "Epoch 3/100\n",
      "8064/8064 [==============================] - 2s 211us/step - loss: 0.5796 - binary_accuracy: 0.7013 - val_loss: 0.5495 - val_binary_accuracy: 0.7098\n",
      "Epoch 4/100\n",
      "8064/8064 [==============================] - 2s 229us/step - loss: 0.5262 - binary_accuracy: 0.8109 - val_loss: 0.4980 - val_binary_accuracy: 0.8950\n",
      "Epoch 5/100\n",
      "8064/8064 [==============================] - 2s 214us/step - loss: 0.4776 - binary_accuracy: 0.8936 - val_loss: 0.4523 - val_binary_accuracy: 0.8950\n",
      "Epoch 6/100\n",
      "8064/8064 [==============================] - 2s 214us/step - loss: 0.4350 - binary_accuracy: 0.8936 - val_loss: 0.4131 - val_binary_accuracy: 0.8950\n",
      "Epoch 7/100\n",
      "8064/8064 [==============================] - 2s 224us/step - loss: 0.3989 - binary_accuracy: 0.8936 - val_loss: 0.3809 - val_binary_accuracy: 0.8950\n",
      "Epoch 8/100\n",
      "8064/8064 [==============================] - 2s 223us/step - loss: 0.3696 - binary_accuracy: 0.8936 - val_loss: 0.3556 - val_binary_accuracy: 0.8950\n",
      "Epoch 9/100\n",
      "8064/8064 [==============================] - 2s 214us/step - loss: 0.3468 - binary_accuracy: 0.8936 - val_loss: 0.3364 - val_binary_accuracy: 0.8950\n",
      "Epoch 10/100\n",
      "8064/8064 [==============================] - 2s 219us/step - loss: 0.3297 - binary_accuracy: 0.8936 - val_loss: 0.3224 - val_binary_accuracy: 0.8950\n",
      "Epoch 11/100\n",
      "8064/8064 [==============================] - 2s 204us/step - loss: 0.3172 - binary_accuracy: 0.8936 - val_loss: 0.3124 - val_binary_accuracy: 0.8950\n",
      "Epoch 12/100\n",
      "8064/8064 [==============================] - 2s 196us/step - loss: 0.3082 - binary_accuracy: 0.8936 - val_loss: 0.3053 - val_binary_accuracy: 0.8950\n",
      "Epoch 13/100\n",
      "8064/8064 [==============================] - 2s 196us/step - loss: 0.3018 - binary_accuracy: 0.8936 - val_loss: 0.3004 - val_binary_accuracy: 0.8950\n",
      "Epoch 14/100\n",
      "8064/8064 [==============================] - 2s 210us/step - loss: 0.2973 - binary_accuracy: 0.8936 - val_loss: 0.2969 - val_binary_accuracy: 0.8950\n",
      "Epoch 15/100\n",
      "8064/8064 [==============================] - 2s 241us/step - loss: 0.2940 - binary_accuracy: 0.8936 - val_loss: 0.2944 - val_binary_accuracy: 0.8950\n",
      "Epoch 16/100\n",
      "8064/8064 [==============================] - 2s 242us/step - loss: 0.2917 - binary_accuracy: 0.8936 - val_loss: 0.2927 - val_binary_accuracy: 0.8950\n",
      "Epoch 17/100\n",
      "8064/8064 [==============================] - 2s 227us/step - loss: 0.2900 - binary_accuracy: 0.8936 - val_loss: 0.2914 - val_binary_accuracy: 0.8950\n",
      "Epoch 18/100\n",
      "8064/8064 [==============================] - 2s 223us/step - loss: 0.2888 - binary_accuracy: 0.8936 - val_loss: 0.2905 - val_binary_accuracy: 0.8950\n",
      "Epoch 19/100\n",
      "8064/8064 [==============================] - 2s 228us/step - loss: 0.2879 - binary_accuracy: 0.8936 - val_loss: 0.2899 - val_binary_accuracy: 0.8950\n",
      "Epoch 20/100\n",
      "8064/8064 [==============================] - 2s 226us/step - loss: 0.2872 - binary_accuracy: 0.8936 - val_loss: 0.2893 - val_binary_accuracy: 0.8950\n",
      "Epoch 21/100\n",
      "8064/8064 [==============================] - 2s 229us/step - loss: 0.2866 - binary_accuracy: 0.8936 - val_loss: 0.2889 - val_binary_accuracy: 0.8950\n",
      "Epoch 22/100\n",
      "8064/8064 [==============================] - 2s 218us/step - loss: 0.2862 - binary_accuracy: 0.8936 - val_loss: 0.2886 - val_binary_accuracy: 0.8950\n",
      "Epoch 23/100\n",
      "8064/8064 [==============================] - 2s 216us/step - loss: 0.2859 - binary_accuracy: 0.8936 - val_loss: 0.2884 - val_binary_accuracy: 0.8950\n",
      "Epoch 24/100\n",
      "8064/8064 [==============================] - 2s 206us/step - loss: 0.2856 - binary_accuracy: 0.8936 - val_loss: 0.2881 - val_binary_accuracy: 0.8950\n",
      "Epoch 25/100\n",
      "8064/8064 [==============================] - 2s 196us/step - loss: 0.2854 - binary_accuracy: 0.8936 - val_loss: 0.2880 - val_binary_accuracy: 0.8950\n",
      "Epoch 26/100\n",
      "8064/8064 [==============================] - 2s 224us/step - loss: 0.2852 - binary_accuracy: 0.8936 - val_loss: 0.2878 - val_binary_accuracy: 0.8950\n",
      "Epoch 27/100\n",
      "8064/8064 [==============================] - 2s 228us/step - loss: 0.2851 - binary_accuracy: 0.8936 - val_loss: 0.2877 - val_binary_accuracy: 0.8950\n",
      "Epoch 28/100\n",
      "8064/8064 [==============================] - 2s 220us/step - loss: 0.2850 - binary_accuracy: 0.8936 - val_loss: 0.2876 - val_binary_accuracy: 0.8950\n",
      "Epoch 29/100\n",
      "8064/8064 [==============================] - 2s 207us/step - loss: 0.2849 - binary_accuracy: 0.8936 - val_loss: 0.2875 - val_binary_accuracy: 0.8950\n",
      "Epoch 30/100\n",
      "8064/8064 [==============================] - 2s 217us/step - loss: 0.2847 - binary_accuracy: 0.8936 - val_loss: 0.2874 - val_binary_accuracy: 0.8950\n",
      "Epoch 31/100\n",
      "8064/8064 [==============================] - 2s 269us/step - loss: 0.2847 - binary_accuracy: 0.8936 - val_loss: 0.2873 - val_binary_accuracy: 0.8950\n",
      "Epoch 32/100\n",
      "8064/8064 [==============================] - 2s 215us/step - loss: 0.2846 - binary_accuracy: 0.8936 - val_loss: 0.2872 - val_binary_accuracy: 0.8950\n",
      "Epoch 33/100\n",
      "8064/8064 [==============================] - 2s 210us/step - loss: 0.2845 - binary_accuracy: 0.8936 - val_loss: 0.2872 - val_binary_accuracy: 0.8950\n",
      "Epoch 34/100\n",
      "8064/8064 [==============================] - 2s 224us/step - loss: 0.2845 - binary_accuracy: 0.8936 - val_loss: 0.2871 - val_binary_accuracy: 0.8950\n",
      "Epoch 35/100\n",
      "8064/8064 [==============================] - 2s 222us/step - loss: 0.2844 - binary_accuracy: 0.8936 - val_loss: 0.2870 - val_binary_accuracy: 0.8950\n",
      "Epoch 36/100\n",
      "8064/8064 [==============================] - 2s 209us/step - loss: 0.2843 - binary_accuracy: 0.8936 - val_loss: 0.2870 - val_binary_accuracy: 0.8950\n",
      "Epoch 37/100\n",
      "8064/8064 [==============================] - 2s 285us/step - loss: 0.2843 - binary_accuracy: 0.8936 - val_loss: 0.2870 - val_binary_accuracy: 0.8950\n",
      "Epoch 38/100\n",
      "8064/8064 [==============================] - 2s 259us/step - loss: 0.2842 - binary_accuracy: 0.8936 - val_loss: 0.2869 - val_binary_accuracy: 0.8950\n",
      "Epoch 39/100\n",
      "8064/8064 [==============================] - 2s 231us/step - loss: 0.2842 - binary_accuracy: 0.8936 - val_loss: 0.2869 - val_binary_accuracy: 0.8950\n",
      "Epoch 40/100\n",
      "8064/8064 [==============================] - 2s 275us/step - loss: 0.2841 - binary_accuracy: 0.8936 - val_loss: 0.2869 - val_binary_accuracy: 0.8950\n",
      "Epoch 41/100\n",
      "8064/8064 [==============================] - 2s 281us/step - loss: 0.2841 - binary_accuracy: 0.8936 - val_loss: 0.2868 - val_binary_accuracy: 0.8950\n",
      "Epoch 42/100\n",
      "8064/8064 [==============================] - 2s 285us/step - loss: 0.2841 - binary_accuracy: 0.8936 - val_loss: 0.2868 - val_binary_accuracy: 0.8950\n",
      "Epoch 43/100\n",
      "8064/8064 [==============================] - 2s 269us/step - loss: 0.2841 - binary_accuracy: 0.8936 - val_loss: 0.2868 - val_binary_accuracy: 0.8950\n",
      "Epoch 44/100\n",
      "8064/8064 [==============================] - 2s 252us/step - loss: 0.2840 - binary_accuracy: 0.8936 - val_loss: 0.2867 - val_binary_accuracy: 0.8950\n",
      "Epoch 45/100\n",
      "8064/8064 [==============================] - 2s 255us/step - loss: 0.2840 - binary_accuracy: 0.8936 - val_loss: 0.2867 - val_binary_accuracy: 0.8950\n",
      "Epoch 46/100\n",
      "8064/8064 [==============================] - 2s 230us/step - loss: 0.2840 - binary_accuracy: 0.8936 - val_loss: 0.2867 - val_binary_accuracy: 0.8950\n",
      "Epoch 47/100\n",
      "8064/8064 [==============================] - 2s 220us/step - loss: 0.2840 - binary_accuracy: 0.8936 - val_loss: 0.2867 - val_binary_accuracy: 0.8950\n",
      "Epoch 48/100\n",
      "8064/8064 [==============================] - 2s 242us/step - loss: 0.2839 - binary_accuracy: 0.8936 - val_loss: 0.2867 - val_binary_accuracy: 0.8950ss: 0.2816 - binar\n",
      "Epoch 49/100\n",
      "8064/8064 [==============================] - 2s 260us/step - loss: 0.2839 - binary_accuracy: 0.8936 - val_loss: 0.2866 - val_binary_accuracy: 0.8950\n",
      "Epoch 50/100\n",
      "8064/8064 [==============================] - 2s 246us/step - loss: 0.2839 - binary_accuracy: 0.8936 - val_loss: 0.2866 - val_binary_accuracy: 0.8950\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8064/8064 [==============================] - 2s 220us/step - loss: 0.2839 - binary_accuracy: 0.8936 - val_loss: 0.2866 - val_binary_accuracy: 0.8950\n",
      "Epoch 52/100\n",
      "8064/8064 [==============================] - 2s 221us/step - loss: 0.2839 - binary_accuracy: 0.8936 - val_loss: 0.2866 - val_binary_accuracy: 0.8950\n",
      "Epoch 53/100\n",
      "8064/8064 [==============================] - 2s 205us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2866 - val_binary_accuracy: 0.8950\n",
      "Epoch 54/100\n",
      "8064/8064 [==============================] - 2s 202us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2866 - val_binary_accuracy: 0.8950\n",
      "Epoch 55/100\n",
      "8064/8064 [==============================] - 2s 201us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2866 - val_binary_accuracy: 0.8950\n",
      "Epoch 56/100\n",
      "8064/8064 [==============================] - 2s 210us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 57/100\n",
      "8064/8064 [==============================] - 2s 215us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 58/100\n",
      "8064/8064 [==============================] - 2s 218us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 59/100\n",
      "8064/8064 [==============================] - 2s 207us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 60/100\n",
      "8064/8064 [==============================] - 2s 211us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 61/100\n",
      "8064/8064 [==============================] - 2s 209us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 62/100\n",
      "8064/8064 [==============================] - 2s 203us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 63/100\n",
      "8064/8064 [==============================] - 2s 207us/step - loss: 0.2838 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 64/100\n",
      "8064/8064 [==============================] - 2s 214us/step - loss: 0.2837 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n",
      "Epoch 65/100\n",
      "8064/8064 [==============================] - 2s 206us/step - loss: 0.2837 - binary_accuracy: 0.8936 - val_loss: 0.2865 - val_binary_accuracy: 0.8950\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load blstm.py\n",
    "\n",
    "from __future__ import print_function\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "\n",
    "# import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Bidirectional, LSTM\n",
    "from keras.models import Model\n",
    "from custom_metrics import hamming_score, f1\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "# import matplotlib.pyplot as plt\n",
    "import logging, pickle\n",
    "\n",
    "print(sys.argv[1])\n",
    "lstm_units = 1 #int(sys.argv[1])\n",
    "dropout_rate = 1 # float(sys.argv[2])\n",
    "dense_units = 1 # int(sys.argv[3])\n",
    "max_len = 1  # int(sys.argv[4])\n",
    "# In[3]:\n",
    "\n",
    "logging.basicConfig(filename='res/blstm/{}_{}_{}_{}.log'.format(lstm_units, dropout_rate, dense_units, max_len), level=logging.INFO)\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "BASE_DIR = ''\n",
    "GLOVE_DIR = ''\n",
    "# EMBEDDING_FILE = 'glove.6B.100d.txt'\n",
    "EMBEDDING_FILE = ''\n",
    "MAX_SEQUENCE_LENGTH = max_len\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "EMBED_INIT_GLOVE = False\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "train_file = '../data/msdialog/train.tsv'\n",
    "valid_file = '../data/msdialog/valid.tsv'\n",
    "test_file = '../data/msdialog/test.tsv'\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# first, build index mapping words in the embeddings set to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "# embeddings_index = {}\n",
    "# with open(os.path.join(GLOVE_DIR, EMBEDDING_FILE)) as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         coefs = np.asarray(values[1:], dtype='float32')\n",
    "#         embeddings_index[word] = coefs\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {'OQ': 0, 'RQ': 1, 'FQ': 2, 'IR': 3, 'PF': 4, 'NF': 5, 'O': 6, 'PA': 7, 'GG': 8, 'FD': 9, 'CQ': 10, 'JK': 11}\n",
    "id2label = {v: k for k, v in labels_index.items()}\n",
    "classes_num = len(labels_index)\n",
    "\n",
    "def load_data_and_labels(data_file):\n",
    "    x = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    with open(data_file) as raw_data:\n",
    "        for line in raw_data:\n",
    "            i += 1\n",
    "#             print(i)\n",
    "            if line != '\\n':\n",
    "                line = line.strip()\n",
    "                tokens = line.split('\\t')\n",
    "                labels = tokens[0].split('_')\n",
    "                x.append(tokens[1])\n",
    "                each_y = [0] * classes_num\n",
    "                for label in labels:\n",
    "                    each_y[labels_index[label]] = 1\n",
    "                y.append(each_y)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = load_data_and_labels(train_file)\n",
    "x_valid, y_valid = load_data_and_labels(valid_file)\n",
    "x_test, y_test = load_data_and_labels(test_file)\n",
    "# MAX_SEQUENCE_LENGTH = max(max(map(len, x_train)), max(map(len, x_valid)), max(map(len, x_test)))\n",
    "# print(MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(y_train + y_valid + y_test)\n",
    "\n",
    "print('Found %s texts.' % len(x_train + x_valid + x_test))\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(x_train + x_valid)\n",
    "sequences = tokenizer.texts_to_sequences(x_train + x_valid + x_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# labels = to_categorical(np.asarray(y_train))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "\n",
    "if EMBED_INIT_GLOVE:\n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    # load pre-trained word embeddings into an Embedding layer\n",
    "    # note that we set trainable = False so as to keep the embeddings fixed\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True)\n",
    "else:\n",
    "    embedding_layer = Embedding(num_words, \n",
    "                                EMBEDDING_DIM, \n",
    "                                embeddings_initializer='uniform', \n",
    "                                input_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "num_validation_samples = len(y_valid)\n",
    "num_test_samples = len(y_test)\n",
    "num_train_samples = len(y_train)\n",
    "num_total_samples = len(labels)\n",
    "\n",
    "x_train = data[:num_train_samples]\n",
    "y_train = labels[:num_train_samples]\n",
    "x_val = data[num_train_samples: num_train_samples + num_validation_samples]\n",
    "y_val = labels[num_train_samples: num_train_samples + num_validation_samples]\n",
    "x_test = data[-num_test_samples:]\n",
    "y_test = labels[-num_test_samples:]\n",
    "\n",
    "assert len(x_train) + len(x_val) + len(x_test) == len(labels)\n",
    "assert len(y_train) + len(y_val) + len(y_test) == len(labels)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(lstm_units))(embedded_sequences)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "x = Dense(dense_units)(x)\n",
    "preds = Dense(len(labels_index), activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                  min_delta=0,\n",
    "                  patience=2,\n",
    "                  verbose=0, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=100,\n",
    "          callbacks=[es],\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def show_example(idx):\n",
    "#     N_true = int(np.sum(y_test[idx]))\n",
    "    N_true = 12\n",
    "    print(\"Prediction: {}\".format(\"|\".join([\"{} ({:.3})\".format(id2label[s],\n",
    "                                                                pred[idx][s])\n",
    "                                            for s in pred[idx].argsort()[-N_true:][::-1]])))\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "pred_val = model.predict(np.array(x_val))\n",
    "pred_test = model.predict(np.array(x_test))\n",
    "from copy import deepcopy\n",
    "# In[ ]:\n",
    "for th in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "\n",
    "    pred = deepcopy(pred_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# if predicted proba >= 0.5, this label is set to 1. if all probas < 0.5, the label with largest proba is set to 1\n",
    "    for i in range(pred.shape[0]):\n",
    "        if len(np.where(pred[i] >= th)[0]) > 0:\n",
    "            pred[i][pred[i] >= th] = 1\n",
    "            pred[i][pred[i] < th] = 0\n",
    "        else:\n",
    "            max_index = np.argmax(pred[i])\n",
    "            pred[i] = 0\n",
    "            pred[i][max_index] = 1\n",
    "\n",
    "\n",
    "    acc_val = hamming_score(y_val, pred)\n",
    "    p_val, r_val, f1_val = f1(y_val, pred)\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "    pred = deepcopy(pred_test)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(pred.shape[0]):\n",
    "        if len(np.where(pred[i] >= th)[0]) > 0:\n",
    "            pred[i][pred[i] >= th] = 1\n",
    "            pred[i][pred[i] < th] = 0\n",
    "        else:\n",
    "            max_index = np.argmax(pred[i])\n",
    "            pred[i] = 0\n",
    "            pred[i][max_index] = 1\n",
    "\n",
    "    acc_test = hamming_score(y_test, pred)\n",
    "    p_test, r_test, f1_test = f1(y_test, pred)\n",
    "\n",
    "    pickle_name = 'res/blstm/{}_{}_{}_{}_{}.res'.format(lstm_units, dropout_rate, dense_units, max_len, th)\n",
    "    pickle_file = open(pickle_name, 'wb')\n",
    "    pickle.dump(pred, pickle_file, pickle.HIGHEST_PROTOCOL)\n",
    "    pickle_file.close()\n",
    "\n",
    "    logging.info('{},{},{},{},{},{},{},{},{},{},{},{},{}'.format(\n",
    "        lstm_units, dropout_rate, dense_units, max_len, th, acc_val, p_val, r_val, f1_val, acc_test, p_test, r_test, f1_test\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_f = '../data/Experiment/Valid_328853_34308.npy'\n",
    "X = np.load(array_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42388505, -0.00777789,  0.23651005, ..., -0.11761022,\n",
       "         0.29358882,  0.3746736 ],\n",
       "       [ 0.6072346 , -0.54473937,  0.6851583 , ..., -0.2108932 ,\n",
       "         0.07921334,  0.33541626],\n",
       "       [ 0.30296996, -0.30779636,  0.26667506, ...,  0.38648814,\n",
       "         0.13085765,  0.8317897 ],\n",
       "       ...,\n",
       "       [ 0.7904673 ,  0.02980215,  0.4440329 , ...,  0.32058296,\n",
       "        -0.05098233,  0.27760336],\n",
       "       [ 0.5624872 ,  0.17496133, -0.11323217, ..., -0.32359922,\n",
       "         0.57077616, -0.20259726],\n",
       "       [ 0.472658  ,  0.27651823, -0.12045603, ..., -0.33342186,\n",
       "         0.5865195 , -0.19277444]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.07234597e-01, -5.44739366e-01,  6.85158312e-01, -2.32821897e-01,\n",
       "       -5.33920527e-01,  3.83219421e-01,  2.70928085e-01, -2.57108659e-02,\n",
       "        1.21941991e-01, -1.34292078e+00, -3.29492897e-01,  4.10439998e-01,\n",
       "        3.15013155e-02,  1.04366288e-01, -6.84510589e-01,  2.03647241e-02,\n",
       "        8.85440335e-02,  7.52348185e-01,  1.14841349e-01, -3.55980337e-01,\n",
       "       -1.31744534e-01, -3.90325248e-01,  1.13205063e+00, -2.42788464e-01,\n",
       "       -3.05838615e-01,  2.36626968e-01,  4.73049402e-01, -1.25819575e-02,\n",
       "       -1.03556991e+00, -3.36251855e-02,  3.91320169e-01,  9.93486121e-02,\n",
       "       -4.84311461e-01,  1.17801145e-01, -6.42261028e-01, -1.57996103e-01,\n",
       "        4.27277684e-01,  3.81359830e-02,  2.90774226e-01,  2.38268554e-01,\n",
       "       -3.27565789e-01, -6.59237653e-02,  7.64864206e-01, -2.63270020e-01,\n",
       "       -4.38236475e-01, -3.62743020e-01, -4.16132212e-01,  4.26907301e-01,\n",
       "       -1.28081366e-01,  2.51143634e-01, -1.78008657e-02, -6.75877690e-01,\n",
       "        5.27033627e-01, -4.17398065e-02, -4.30172116e-01,  3.08706284e-01,\n",
       "       -4.36267942e-01, -2.04181492e-01, -6.26897752e-01,  3.56525779e-02,\n",
       "        1.66787803e-02, -3.39420974e-01,  4.12393719e-01, -5.58121316e-02,\n",
       "       -7.47134238e-02,  1.95772290e-01,  2.32251555e-01,  1.27657771e-01,\n",
       "       -1.24836504e-01,  2.03483194e-01,  2.12099195e-01, -4.26684529e-01,\n",
       "        1.58482820e-01,  1.63180375e+00,  9.67986435e-02, -8.90031159e-01,\n",
       "        1.29372865e-01,  8.16214263e-01, -7.09907264e-02, -7.74060607e-01,\n",
       "        5.05561233e-01, -3.45817685e-01, -5.02659008e-02, -1.08503953e-01,\n",
       "       -2.28773728e-02,  3.84941816e-01, -7.03018606e-02, -5.32130897e-01,\n",
       "        2.58035362e-01,  4.24759835e-01,  2.92229176e-01,  4.18037951e-01,\n",
       "        1.22110367e-01,  5.86139178e-03,  3.55528235e-01,  3.01871598e-01,\n",
       "       -1.06960334e-01, -3.49506885e-01,  6.67651844e+00,  1.23329446e-01,\n",
       "       -2.82691270e-01,  3.57763767e-01, -4.95959044e-01, -2.07943231e-01,\n",
       "        1.36960924e-01, -7.63461590e-01,  4.37338859e-01, -3.77104640e-01,\n",
       "       -3.02645862e-01,  2.61096239e-01,  1.18171978e+00, -8.92112702e-02,\n",
       "        4.72541541e-01, -3.89514267e-01,  8.97653326e-02,  7.06349969e-01,\n",
       "       -2.00111657e-01,  1.47809684e-02, -2.05105439e-01, -1.43544987e-01,\n",
       "       -2.72731669e-02,  5.29942751e-01,  1.10731530e+00,  3.17819595e-01,\n",
       "        7.53895938e-02, -1.65730372e-01,  3.48280579e-01,  1.16774693e-01,\n",
       "        5.20340502e-01, -9.54137892e-02, -8.74432683e-01,  6.32122830e-02,\n",
       "        1.44901037e-01,  1.74985945e-01,  3.09038043e-01,  6.52254879e-01,\n",
       "       -4.13996607e-01,  6.25713706e-01, -6.66695237e-01,  1.51917219e-01,\n",
       "        4.09067094e-01, -7.98934639e-01,  4.23500031e-01, -2.28062510e-01,\n",
       "       -3.18067670e-01,  3.83127546e+00, -4.05621171e-01, -2.12391093e-02,\n",
       "        2.08682880e-01,  1.60454750e-01, -4.25631106e-02, -6.07352734e-01,\n",
       "       -4.09910917e-01,  3.32179368e-02, -6.63722634e-01,  8.33647773e-02,\n",
       "        5.15055120e-01, -2.07579926e-01,  3.34546030e-01, -2.53410876e-01,\n",
       "       -1.55834520e+00, -6.89176679e-01, -8.35000575e-01,  2.77343184e-01,\n",
       "       -1.81712329e-01,  8.78703520e-02,  1.03376113e-01, -1.22805429e+00,\n",
       "        1.04157645e-02,  1.83197513e-01, -1.46413058e-01, -3.54740947e-01,\n",
       "       -3.27776241e+00,  1.86242834e-01, -8.84916782e-02,  2.73744106e-01,\n",
       "       -1.62468463e-01, -1.47017941e-01, -1.46352917e-01, -2.87891388e-01,\n",
       "        4.31616396e-01, -3.47939730e-01,  1.27631992e-01,  2.06320539e-01,\n",
       "       -6.65988177e-02,  2.06736952e-01,  3.10768068e-01,  4.64245453e-02,\n",
       "        4.51848567e-01,  2.00433835e-01,  2.23148197e-01,  9.47829485e-02,\n",
       "        1.99944064e-01,  1.53392658e-01,  1.23897813e-01, -7.09673613e-02,\n",
       "       -6.46880686e-01, -4.96528536e-01,  6.42602444e-01,  2.13328481e-01,\n",
       "       -3.80953759e-01,  1.92135394e-01, -6.00226462e-01, -3.69330272e-02,\n",
       "        5.05154788e-01,  2.72177696e-01,  4.37368751e-01, -6.54111147e-01,\n",
       "       -1.52510777e-02, -5.68407297e-01, -5.45871615e-01, -4.59197581e-01,\n",
       "       -2.62071937e-03,  1.79211020e-01,  7.73100972e-01, -8.20239782e-02,\n",
       "        1.04972258e-01, -7.47563541e-02,  2.46972293e-01, -3.41630965e-01,\n",
       "       -4.45534587e-01, -1.26883626e-01,  4.35450822e-01, -3.73266637e-01,\n",
       "        4.09813493e-01, -4.71141189e-03, -1.38812348e-01, -4.98282492e-01,\n",
       "        4.14023012e-01, -3.57274681e-01, -1.01400137e-01,  1.09388977e-01,\n",
       "        4.18546230e-01,  4.79434337e-03, -9.46336925e-01, -2.50031829e-01,\n",
       "       -3.57132778e-03,  4.24609408e-02, -5.17704725e-01,  5.95894992e-01,\n",
       "       -3.24172378e-01,  5.60130179e-01,  1.26596892e+00, -2.11737528e-02,\n",
       "        2.09194392e-01,  2.27100641e-01,  7.05351949e-01,  5.38237154e-01,\n",
       "       -7.23610640e-01,  3.28922927e-01,  1.49262750e+00,  4.74140644e-01,\n",
       "       -7.46013999e-01,  5.08421883e-02,  9.92144495e-02,  4.55892652e-01,\n",
       "       -3.72754127e-01, -2.02084470e+00, -6.75141394e-01,  1.68788165e-01,\n",
       "       -2.93158144e-01, -2.76596260e+00, -5.57166971e-02, -3.29672277e-01,\n",
       "        4.95268792e-01, -5.40674627e-01,  3.75011116e-01,  4.47358191e-01,\n",
       "       -3.75712782e-01,  1.17279112e-01, -8.10773194e-01, -5.48148513e-01,\n",
       "       -7.36114502e-01, -3.74200583e-01, -5.54226756e-01,  4.81108427e-01,\n",
       "        2.43969753e-01,  2.89603353e-01,  1.75218284e-01, -4.98916656e-01,\n",
       "       -3.28705162e-01, -4.28481817e-01, -6.44386232e-01,  6.74364150e-01,\n",
       "       -1.37823835e-01, -1.07518405e-01,  6.05257340e-02,  2.60519147e-01,\n",
       "       -6.26832321e-02,  4.78128099e+00,  5.39047837e-01, -5.00288606e-02,\n",
       "       -3.35018128e-01, -5.93686104e-03,  1.07303090e-01, -1.65634125e-01,\n",
       "       -8.45178783e-01,  7.51516700e-01, -1.20317884e-01,  6.38981387e-02,\n",
       "        3.92517358e-01, -6.97900653e-01, -1.29332411e+00, -2.44657502e-01,\n",
       "       -7.12820232e-01, -1.92909136e-01, -8.19728494e-01,  6.36097670e-01,\n",
       "       -1.49927819e+00,  3.18019390e-01,  1.71236977e-01,  1.82639062e-01,\n",
       "       -3.41283530e-01,  8.98672789e-02, -4.68255371e-01, -5.67139983e-01,\n",
       "       -5.54100156e-01,  8.98207068e-01,  2.09331930e-01, -1.44820273e+00,\n",
       "        8.90287757e-01,  2.77260959e-01, -5.34471929e-01,  1.87216341e-01,\n",
       "       -2.76410788e-01, -4.07455474e-01, -3.75257194e-01, -5.51575661e-01,\n",
       "        1.87144846e-01, -2.02997819e-01,  2.71180421e-01,  1.48594677e-01,\n",
       "       -5.41469455e-01, -3.58104445e-02, -3.52098614e-01,  5.04819751e-01,\n",
       "       -2.23787740e-01,  8.17604437e-02, -4.27451193e-01, -4.21456963e-01,\n",
       "       -3.37817639e-01, -4.59779263e-01, -1.64717436e-01, -2.32028924e-02,\n",
       "        9.05406475e-02,  7.41874874e-01, -2.58197486e-02, -4.05060768e-01,\n",
       "        3.47649693e-01,  4.14361149e-01, -4.39052969e-01,  1.56153440e-01,\n",
       "       -5.68841100e-01,  4.74005371e-01,  4.80587721e-01,  7.28374571e-02,\n",
       "       -4.25122857e-01,  5.15711978e-02, -1.58115953e-01, -8.54272842e-02,\n",
       "        4.23463434e-01, -2.35765743e+00,  8.62089574e-01,  2.94369489e-01,\n",
       "       -4.07751650e-02, -3.61511022e-01,  6.31979480e-02,  2.23174572e-01,\n",
       "       -1.49158798e-02,  3.83219391e-01,  5.58512099e-02, -1.56263307e-01,\n",
       "        2.03156203e-01,  3.14798534e-01, -2.67139137e-01,  3.02651554e-01,\n",
       "       -4.94515777e-01,  1.23299271e-01,  4.52815503e-01, -5.47353327e-01,\n",
       "       -7.09475577e-01,  4.80259120e-01, -3.97393525e-01,  1.20758176e-01,\n",
       "       -4.53121588e-03,  3.55734617e-01,  6.78364515e-01, -4.60090846e-01,\n",
       "        2.79038846e-01,  4.58853066e-01,  6.31164968e-01, -4.85578865e-01,\n",
       "       -5.78921258e-01, -4.94482905e-01,  2.01163888e-01, -6.42777458e-02,\n",
       "       -4.14298862e-01,  5.80441415e-01,  4.05952036e-02, -4.35252935e-01,\n",
       "       -1.34980232e-01,  3.47700924e-01,  4.94308054e-01, -5.56379035e-02,\n",
       "        3.19754660e-01, -8.83901417e-01, -1.11671478e-01, -1.43916175e-01,\n",
       "       -2.72320127e+00,  5.03471717e-02,  2.59404778e-01, -8.74316692e-02,\n",
       "        2.70173907e-01,  3.90442789e-01, -3.94842148e-01, -1.38008792e-03,\n",
       "        9.32498872e-01,  1.88115641e-01,  8.42142031e-02,  2.46280760e-01,\n",
       "        4.58088368e-01, -1.07681051e-01, -2.46626176e-02, -2.67967790e-01,\n",
       "        1.57662872e-02, -3.39493424e-01,  7.03280419e-02,  1.20170996e-01,\n",
       "        1.73229888e-01,  3.88263375e-01, -7.37752080e-01,  6.72825933e-01,\n",
       "        1.42276809e-01, -5.51073134e-01, -4.92981046e-01, -2.65333802e-01,\n",
       "        5.78280762e-02, -4.58675325e-01, -3.12641591e-01,  6.08953381e+00,\n",
       "       -1.99709415e-01,  4.03386950e-01,  3.61395366e-02, -2.35479698e-01,\n",
       "       -7.92677477e-02, -2.09470630e-01,  3.12198550e-01,  1.02532792e+00,\n",
       "        2.12309629e-01, -4.31016326e-01, -4.89970565e-01,  4.35507834e-01,\n",
       "        3.86536300e-01, -5.01532555e-01,  8.15751195e-01,  5.85109890e-01,\n",
       "       -2.00919732e-02,  3.20181213e-02, -1.65272027e-01,  3.70504946e-01,\n",
       "       -2.56389789e-02,  3.39225888e-01, -6.41662240e-01,  2.36702666e-01,\n",
       "        3.84532750e-01, -6.47189319e-02, -5.92329800e-01, -7.70259202e-02,\n",
       "       -6.81745589e-01,  6.48462892e-01,  2.88963944e-01,  7.68725947e-02,\n",
       "        2.17992976e-01,  7.23728120e-01,  1.66373953e-01,  6.13064647e-01,\n",
       "       -2.24935994e-01, -1.96908489e-01, -6.00690603e-01,  7.74078220e-02,\n",
       "        4.90569949e-01,  1.56237698e+00, -5.61076760e-01,  7.20504701e-01,\n",
       "       -3.70665565e-02, -4.59124774e-01, -2.88977563e-01,  1.91294849e-01,\n",
       "        3.87487054e-01, -3.41768742e-01,  6.71177506e-01,  4.77912694e-01,\n",
       "        1.33041352e-01,  2.49565825e-01,  4.14498955e-01, -4.77499887e-02,\n",
       "        4.52403396e-01,  2.24795770e-02,  1.45388290e-01, -1.01708442e-01,\n",
       "       -2.07973212e-01, -4.52882081e-01, -2.22592607e-01, -1.78521931e-01,\n",
       "       -4.75266159e-01,  5.38737714e-01, -2.46827483e-01, -8.03602457e-01,\n",
       "       -2.67930269e-01, -6.32053673e-01, -3.11451033e-02, -4.84404743e-01,\n",
       "       -1.35471448e-01, -2.10722797e-02, -5.67292571e-01, -2.18582362e-01,\n",
       "       -8.54156539e-03,  1.83280766e-01,  1.51283056e-01, -7.48601079e-01,\n",
       "       -3.72627914e-01,  1.95049107e-01, -5.60361445e-01,  1.48680449e-01,\n",
       "        2.56545484e-01, -1.07775664e+00,  1.38655066e-01,  4.74912345e-01,\n",
       "       -4.21639174e-01, -1.94842502e-01, -5.76845169e-01, -5.92484772e-01,\n",
       "       -6.89365715e-02, -8.93476605e-03,  1.47743538e-01,  4.62181747e-01,\n",
       "       -1.83829665e-01, -5.63103139e-01,  1.09113678e-01,  9.86112535e-01,\n",
       "       -8.23959559e-02,  6.91131353e-01,  3.63674611e-01,  2.03568488e-01,\n",
       "        1.45110577e-01,  3.43030423e-01,  2.11812437e-01,  3.59971017e-01,\n",
       "        3.41755629e-01,  3.24307203e-01,  3.75941426e-01,  6.85865879e-01,\n",
       "       -4.95958269e-01,  4.90963548e-01,  3.89516950e-01,  3.25718522e-01,\n",
       "       -2.60892928e-01, -4.32577038e+00, -2.79699087e-01,  2.98441052e-01,\n",
       "        5.56167185e-01, -3.10706347e-01, -7.55963802e-01,  3.80486131e-01,\n",
       "        3.23959202e-01,  6.77179694e-01,  3.65000188e-01, -1.52706712e-01,\n",
       "       -9.78603363e-01, -2.68981314e+00,  1.56779826e-01,  9.90752727e-02,\n",
       "       -3.26842964e-01, -6.65244311e-02, -1.01592171e+00,  8.53218585e-02,\n",
       "        5.53099737e-02, -1.35675408e-02, -6.50265664e-02,  6.97688237e-02,\n",
       "       -1.59802437e-01, -1.68372989e-01,  5.69692373e-01, -1.48624197e-01,\n",
       "       -7.94706404e-01,  6.05007350e-01, -5.94672039e-02,  6.53697737e-03,\n",
       "        4.11630459e-02,  7.13865817e-01,  3.62199813e-01,  5.81698000e-01,\n",
       "        1.45264894e-01, -6.39748454e-01,  5.39041519e-01,  3.18231076e-01,\n",
       "        1.34308845e-01,  3.17430556e-01,  5.86220287e-02,  1.48636065e-02,\n",
       "        7.18560219e-01, -1.30574465e+00, -6.94535792e-01, -7.96782553e-01,\n",
       "       -1.77124310e+00,  2.67562792e-02, -6.00699484e-02,  3.56792063e-01,\n",
       "        3.19529355e-01, -4.67143148e-01, -5.48456967e-01, -2.30632454e-01,\n",
       "        1.37447610e-01,  2.02861220e-01,  6.81318402e-01,  7.25865006e-01,\n",
       "        8.55219364e-02, -3.72605950e-01, -6.85113907e-01,  5.02080679e-01,\n",
       "       -4.28417057e-01, -9.75537598e-02, -1.82350725e-01, -4.15466309e-01,\n",
       "        9.81795788e-02, -2.53894627e-01,  9.33487564e-02, -4.93066579e-01,\n",
       "        4.54489887e-01,  1.40624344e-01,  2.74391919e-02,  4.55991626e-02,\n",
       "        6.88711286e-01,  2.64501065e-01, -3.90613019e-01,  5.20676374e-01,\n",
       "        8.68753850e-01, -1.41660899e-01, -4.11848098e-01, -2.36479156e-02,\n",
       "        1.40060410e-01, -1.61326945e-01, -3.90083134e-01,  1.39372215e-01,\n",
       "        1.77722186e-01, -7.87826061e-01, -5.48109710e-02, -6.18119761e-02,\n",
       "       -3.95155549e-01, -4.52509046e-01, -3.77457678e-01, -1.23010069e-01,\n",
       "       -1.02184936e-02, -4.65417475e-01, -1.01265296e-01, -4.16345000e-01,\n",
       "        2.07526937e-01, -9.12381336e-02,  2.23127872e-01,  4.83276471e-02,\n",
       "       -5.83480000e-01, -3.25687289e-01, -4.57213849e-01,  2.93562531e+00,\n",
       "        1.57518938e-01, -5.48298657e-01, -6.00603223e-01, -7.30582187e-03,\n",
       "       -5.47874808e-01,  8.78675729e-02, -1.53002158e-01,  2.03113890e+00,\n",
       "       -3.79173726e-01, -1.02292933e-01,  8.61203253e-01, -1.41307145e-01,\n",
       "        5.36900520e-01,  1.10984948e-02,  7.24009216e-01,  3.35084230e-01,\n",
       "        4.60035264e-01, -6.10621870e-01, -3.40539038e-01,  7.94438943e-02,\n",
       "       -3.62506479e-01, -7.77213871e-01, -2.76328195e-02,  9.92940187e-01,\n",
       "       -2.72739381e-01, -6.17915154e-01, -2.83849001e-01,  3.80290672e-03,\n",
       "       -6.97041988e-01,  7.23066688e-01, -5.50797820e-01, -7.86324322e-01,\n",
       "        1.28991234e+00, -5.18910110e-01,  9.13278982e-02,  9.87420380e-02,\n",
       "        2.52026528e-01,  3.48778218e-01, -1.06846895e-02,  4.22875911e-01,\n",
       "       -5.35589814e-01, -6.18115783e-01,  1.14535069e+00,  1.15641750e-01,\n",
       "        1.55267835e-01, -2.17392772e-01, -7.38372982e-01, -1.35229871e-01,\n",
       "        4.01398659e-01, -4.35368598e-01, -1.63220569e-01, -5.04471958e-01,\n",
       "        6.18399024e-01, -1.90506861e-01, -4.09709841e-01, -7.06998348e-01,\n",
       "       -9.73020941e-02, -3.37935597e-01, -4.30885136e-01, -7.63782021e-03,\n",
       "        2.01953426e-01, -3.52384508e-01, -2.25981340e-01, -5.00500321e-01,\n",
       "        7.32453227e-01, -3.15271355e-02, -3.49302530e-01, -3.78492862e-01,\n",
       "        9.23061818e-02,  3.92344952e-01, -1.99259892e-01, -2.59997702e+00,\n",
       "       -3.88091654e-01, -2.05804914e-01, -4.91313964e-01, -4.74714577e-01,\n",
       "        1.69071481e-02,  5.15372276e-01,  5.52730203e-01, -2.02385917e-01,\n",
       "        1.27513900e-01, -4.30746585e-01,  2.27370691e+00, -3.68697912e-01,\n",
       "       -2.98754781e-01, -3.25109720e-01, -1.41154863e-02, -4.61673945e-01,\n",
       "        6.70951188e-01,  1.71823546e-01, -7.01048523e-02, -9.83481258e-02,\n",
       "        1.88354874e+00,  3.29440050e-02,  4.42383766e-01,  1.00886390e-01,\n",
       "       -4.64648753e-01, -3.82476836e-01, -3.55127491e-02,  2.51869857e-01,\n",
       "        2.30280578e-01, -2.10893199e-01,  7.92133361e-02,  3.35416257e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
