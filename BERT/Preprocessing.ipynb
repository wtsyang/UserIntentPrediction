{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_json('data/MSDialog-Intent.json')\n",
    "index=data.index\n",
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labelTable={'OQ':0,'RQ':1,'CQ':2,'FD':3,'FQ':4,\\\n",
    "            'IR':5,'PA':6,'PF':7,'NF':8,'GG':9,'JK':10,'O':11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utterances=[]\n",
    "label=[]\n",
    "otherFeatures={}\n",
    "diaglogKey=index[:-1]\n",
    "utterancesKey=list(data.iloc[4,0][0].keys())\n",
    "utterancesKey.remove('utterance')\n",
    "utterancesKey.remove('tags')\n",
    "maxLen=0\n",
    "IDs=[]\n",
    "\n",
    "for i in range(len(data.columns)):\n",
    "    temp=data.iloc[4,i]\n",
    "    ID=data.columns[i]\n",
    "    for j in range(len(temp)):\n",
    "        \n",
    "        # ID of dialog\n",
    "        IDs+=[ID]\n",
    "        \n",
    "        # Utterance\n",
    "        text=temp[j]['utterance']\n",
    "        if len(text)> maxLen:\n",
    "            maxLen=len(text)\n",
    "        utterances+=[text]\n",
    "        \n",
    "        # Other features\n",
    "        for k in range(4):\n",
    "            otherFeatures.setdefault(diaglogKey[k], []).append(data.iloc[k,i])\n",
    "        for k in range(len(utterancesKey)):\n",
    "            otherFeatures.setdefault(utterancesKey[k],[]).append(temp[j][utterancesKey[k]])\n",
    "        # Label \n",
    "        tempLabel=[0]*12\n",
    "        labels=temp[j]['tags']\n",
    "        labels = labels.split(' ')\n",
    "        if '' in labels:\n",
    "            labels.remove('')\n",
    "        if len(labels) > 1 and 'GG' in labels:\n",
    "            labels.remove('GG')\n",
    "        if len(labels) > 1 and 'O' in labels:\n",
    "            labels.remove('O')\n",
    "        if len(labels) > 1 and 'JK' in labels:\n",
    "            labels.remove('JK')\n",
    "        if 'RQ' in labels and 'CQ' in labels and 'FD' in labels and 'IR' in labels:\n",
    "            labels=['CQ']\n",
    "        if 'PF' in labels and 'CQ' in labels and 'FD' in labels and 'FQ' in labels:\n",
    "            labels=['CQ']\n",
    "        for k in range(len(labels)):\n",
    "            tempLabel[labelTable[labels[k]]]=1\n",
    "            \n",
    "        label+=[tempLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Data=pd.DataFrame(label,columns=labelTable)\n",
    "Data['utterance']=utterances\n",
    "Data['diaglogID']=IDs\n",
    "for k in utterancesKey:\n",
    "    Data[k]=otherFeatures[k]\n",
    "for k in diaglogKey:\n",
    "    Data[k]=otherFeatures[k]\n",
    "Data['diaglogID']=Data['diaglogID'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OQ</th>\n",
       "      <th>RQ</th>\n",
       "      <th>CQ</th>\n",
       "      <th>FD</th>\n",
       "      <th>FQ</th>\n",
       "      <th>IR</th>\n",
       "      <th>PA</th>\n",
       "      <th>PF</th>\n",
       "      <th>NF</th>\n",
       "      <th>GG</th>\n",
       "      <th>...</th>\n",
       "      <th>actor_type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>vote</th>\n",
       "      <th>utterance_time</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>is_answer</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>dialog_time</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>User</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>Freq_0</td>\n",
       "      <td>2017-10-02T11:07:29</td>\n",
       "      <td>Common User</td>\n",
       "      <td>0</td>\n",
       "      <td>backgroundTaskHost.exe stopped working</td>\n",
       "      <td>Windows_10</td>\n",
       "      <td>2017-10-02T11:07:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Agent</td>\n",
       "      <td>Cheryl</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-02T11:12:52</td>\n",
       "      <td>MVP Community Moderator | Article Author</td>\n",
       "      <td>1</td>\n",
       "      <td>backgroundTaskHost.exe stopped working</td>\n",
       "      <td>Windows_10</td>\n",
       "      <td>2017-10-02T11:07:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>User</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-02T11:49:16</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>backgroundTaskHost.exe stopped working</td>\n",
       "      <td>Windows_10</td>\n",
       "      <td>2017-10-02T11:07:29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>User</td>\n",
       "      <td>James</td>\n",
       "      <td>Freq_3</td>\n",
       "      <td>2015-11-05T03:50:07</td>\n",
       "      <td>Common User</td>\n",
       "      <td>0</td>\n",
       "      <td>Windows 10 Microsoft Edge is slow - System Per...</td>\n",
       "      <td>Windows_10</td>\n",
       "      <td>2015-11-05T03:50:07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Agent</td>\n",
       "      <td>Faith</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-05T09:37:10</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1</td>\n",
       "      <td>Windows 10 Microsoft Edge is slow - System Per...</td>\n",
       "      <td>Windows_10</td>\n",
       "      <td>2015-11-05T03:50:07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OQ  RQ  CQ  FD  FQ  IR  PA  PF  NF  GG  ...  actor_type  user_id    vote  \\\n",
       "0   1   0   0   0   0   0   0   0   0   0  ...        User   Sandra  Freq_0   \n",
       "1   0   0   0   0   0   0   1   0   0   0  ...       Agent   Cheryl       1   \n",
       "2   0   0   0   0   0   0   0   1   0   0  ...        User   Sandra       0   \n",
       "3   1   0   0   0   0   1   0   0   1   0  ...        User    James  Freq_3   \n",
       "4   0   0   0   0   0   0   1   1   0   0  ...       Agent    Faith       0   \n",
       "\n",
       "        utterance_time                               affiliation  is_answer  \\\n",
       "0  2017-10-02T11:07:29                               Common User          0   \n",
       "1  2017-10-02T11:12:52  MVP Community Moderator | Article Author          1   \n",
       "2  2017-10-02T11:49:16                                                    0   \n",
       "3  2015-11-05T03:50:07                               Common User          0   \n",
       "4  2015-11-05T09:37:10                                 Microsoft          1   \n",
       "\n",
       "                                               title    category  \\\n",
       "0             backgroundTaskHost.exe stopped working  Windows_10   \n",
       "1             backgroundTaskHost.exe stopped working  Windows_10   \n",
       "2             backgroundTaskHost.exe stopped working  Windows_10   \n",
       "3  Windows 10 Microsoft Edge is slow - System Per...  Windows_10   \n",
       "4  Windows 10 Microsoft Edge is slow - System Per...  Windows_10   \n",
       "\n",
       "           dialog_time frequency  \n",
       "0  2017-10-02T11:07:29         0  \n",
       "1  2017-10-02T11:07:29         0  \n",
       "2  2017-10-02T11:07:29         0  \n",
       "3  2015-11-05T03:50:07         3  \n",
       "4  2015-11-05T03:50:07         3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocesser():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.table = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    def remove_hyperlinks(self,text_list):\n",
    "        corrected_text = []\n",
    "        for word in text_list:\n",
    "            if ':' in word and '/' in word:\n",
    "                continue\n",
    "            if 'http' not in word:\n",
    "                corrected_text.append(word)\n",
    "        return corrected_text\n",
    "    \n",
    "    def remove_punctuations(self,text_lst):\n",
    "        stripped=[]\n",
    "        for word in text_lst:\n",
    "            if '.' in word or '?' in word or '!' in word or ',' in word:\n",
    "                stripped+=[word]\n",
    "            else:\n",
    "                stripped +=[ word.translate(self.table)]\n",
    "        return stripped\n",
    "    \n",
    "    def remove_htmlStructure(self,text_lst):     \n",
    "        stripped=[]\n",
    "        for word in text_lst:\n",
    "            if '/>' in word or '<' in word or 'Â·' in word or word.count('.')>=2:\n",
    "                continue\n",
    "            else:\n",
    "                stripped +=[ word]\n",
    "        return stripped\n",
    "    \n",
    "    def remove_otherInf(self,text_lst):\n",
    "        stripped=[]\n",
    "        for word in text_lst:\n",
    "            if '@' in word:\n",
    "                continue\n",
    "            elif '(' in word and ')' in word:\n",
    "                continue\n",
    "            else:\n",
    "                stripped +=[ word]\n",
    "        return stripped\n",
    "    \n",
    "    def remove_number(self,text_lst):\n",
    "        stripped=[]\n",
    "        for word in text_lst:\n",
    "            count=0\n",
    "            for i in range(10):\n",
    "                if str(i) in word:\n",
    "                    count+=1\n",
    "            if count<2:\n",
    "                stripped +=[word]\n",
    "        return stripped\n",
    "    \n",
    "    def remove_errorPunctuation(self,text_lst):\n",
    "        stripped=[]\n",
    "        for word in text_lst:\n",
    "            if '.' in word:\n",
    "                fragement=word.split('.')\n",
    "                \n",
    "        return stripped\n",
    "    \n",
    "    def preprocess(self,text):\n",
    "        # preprocess pipline\n",
    "        text_lst = text.split()\n",
    "        text_lst = self.remove_hyperlinks(text_lst)\n",
    "        text_lst = self.remove_otherInf(text_lst)\n",
    "        text_lst = self.remove_htmlStructure(text_lst)\n",
    "        text_lst = self.remove_number(text_lst)\n",
    "        text_lst = self.remove_punctuations(text_lst)\n",
    "        \n",
    "        return \" \".join(text_lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesser=Preprocesser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=Data.dropna(subset=['utterance']).reset_index(drop=True)\n",
    "newData=Data.copy()\n",
    "for i in range(len(Data)):\n",
    "    newData.at[i,'utterance']=preprocesser.preprocess(Data['utterance'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "sentence_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5542    Hi. I want to play City Bus Simulator 2 Munich...\n",
       "5543    JD Your system does not meet the minimum reqs ...\n",
       "5544    Thank you. Ill buy a another computer. Or Ill ...\n",
       "5545                                             windows8\n",
       "Name: utterance, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData.loc[Data['diaglogID']==15287,'utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop the index of  6963 910\n",
      "Drop the index of  7088 698\n"
     ]
    }
   ],
   "source": [
    "lens=510\n",
    "index=[]\n",
    "for i in range(len(newData)):\n",
    "    text=newData['utterance'][i]\n",
    "    sentences=sentence_tokenizer.tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        token=tokenizer.tokenize(sentence)\n",
    "        if len(token)>lens:\n",
    "            print('Drop the index of ',i,len(token))\n",
    "            index+=[i]\n",
    "            break\n",
    "newData=newData.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData=newData.replace({'utterance': ''}, {'utterance': '.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "lens=len(Data['diaglogID'].unique())\n",
    "uniqueIndex=Data['diaglogID'].unique()\n",
    "index=np.random.permutation(lens)\n",
    "uniqueIndex=uniqueIndex[index]\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TrainP=[]\n",
    "ValidP=[]\n",
    "TestP=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(np.floor(lens*0.81))):\n",
    "    Train+=[pd.DataFrame(Data.loc[Data['diaglogID']==uniqueIndex[i],:])]\n",
    "    TrainP+=[pd.DataFrame(newData.loc[newData['diaglogID']==uniqueIndex[i],:])]\n",
    "Train=pd.concat(Train)\n",
    "TrainP=pd.concat(TrainP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(np.floor(lens*0.81)),int(np.floor(lens*0.91))):\n",
    "    Valid+=[pd.DataFrame(Data.loc[Data['diaglogID']==uniqueIndex[i],:])]\n",
    "    ValidP+=[pd.DataFrame(newData.loc[newData['diaglogID']==uniqueIndex[i],:])]\n",
    "Valid=pd.concat(Valid)\n",
    "ValidP=pd.concat(ValidP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(np.floor(lens*0.91)),int(lens)):\n",
    "    Test+=[pd.DataFrame(Data.loc[Data['diaglogID']==uniqueIndex[i],:])]\n",
    "    TestP+=[pd.DataFrame(newData.loc[newData['diaglogID']==uniqueIndex[i],:])]\n",
    "Test=pd.concat(Test)\n",
    "TestP=pd.concat(TestP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_csv('data/Data.csv',index=False)\n",
    "Train.to_csv('data/Train.csv',index=False)\n",
    "Valid.to_csv('data/Valid.csv',index=False)\n",
    "Test.to_csv('data/Test.csv',index=False)\n",
    "TrainP.to_csv('data/Train_Preprocessing.csv',index=False)\n",
    "ValidP.to_csv('data/Valid_Preprocessing.csv',index=False)\n",
    "TestP.to_csv('data/Test_Preprocessing.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
