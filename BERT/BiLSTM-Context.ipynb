{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1TfB4QwrD41EDQyv3z+Ce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtsyang/UserIntentPrediction/blob/BERT/BERT/BiLSTM-Context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot0Ha--FR-S1",
        "colab_type": "code",
        "outputId": "b886a731-910c-442b-e6ba-d46c0a0f1199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6DT7DNwSNn9",
        "colab_type": "code",
        "outputId": "2fe476ce-b216-4ef9-878d-a336394d2005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/UserIntentPrediction'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/UserIntentPrediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De681umQRanU",
        "colab_type": "code",
        "outputId": "74002dc2-1ee9-4b71-a17b-eff97cdeecfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
        "from tensorflow.keras.layers  import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import pickle\n",
        "import sklearn\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import smart_cond\n",
        "from functools import partial\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print('Tensorflow Version:',tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIpXSpeYR4rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_MODELS = 1\n",
        "BATCH_SIZE = 32\n",
        "LSTM_UNITS = 64\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS \n",
        "EPOCHS = 15\n",
        "MAX_LEN = 1259\n",
        "N_CHANNELS=768\n",
        "N_CLASS=12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lcdmN7BSHGl",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p2_0TqoR9ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train=pd.read_csv('data/Train_Preprocessing.csv').reset_index(drop=True)\n",
        "Valid=pd.read_csv('data/Valid_Preprocessing.csv').reset_index(drop=True)\n",
        "Test=pd.read_csv('data/Test_Preprocessing.csv').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjliEKeAhO4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=BATCH_SIZE, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim*3, self.n_channels))\n",
        "        y = np.zeros((self.batch_size,self.n_classes), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            pos=list_IDs_temp.loc[i,'utterance_pos']\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            \n",
        "            if pos==1:\n",
        "              try:\n",
        "                temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp=np.zeros(( 512, self.n_channels))\n",
        "\n",
        "            elif pos==2:\n",
        "              try:\n",
        "                temp1=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-1)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp1=np.ones(( 512, self.n_channels))\n",
        "\n",
        "              try:\n",
        "                temp2=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp2=np.zeros(( 512, self.n_channels))\n",
        "\n",
        "              temp=np.concatenate((temp1,temp2),axis=0)\n",
        "\n",
        "            elif pos>=3:  \n",
        "              try:\n",
        "                temp1=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-2)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp1=np.ones(( 512, self.n_channels))\n",
        "\n",
        "              try:\n",
        "                temp2=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-1)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp2=np.ones(( 512, self.n_channels))              \n",
        "              \n",
        "              try:\n",
        "                temp3=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp3=np.ones(( 512, self.n_channels))   \n",
        "\n",
        "              temp=np.concatenate((temp1,temp2,temp3),axis=0)\n",
        "\n",
        "            # Store sample\n",
        "            X[i,0:temp.shape[0],:] =temp \n",
        "            # Store class\n",
        "            y[i,:] = np.array(list_IDs_temp.iloc[i,0:self.n_classes])\n",
        "\n",
        "        Y=[]\n",
        "        for i in range(self.n_classes):\n",
        "          Y+=[y[:,i].reshape((self.batch_size,))]\n",
        "        return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ijHEnaK7opB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_generator = DataGenerator(Train,'Train')\n",
        "validation_generator = DataGenerator(Valid,'Valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBl5lHEfSGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict={}\n",
        "for i in range(N_CLASS):\n",
        "  ratioTrue=np.sum(Train.iloc[:,i])/len(Train)\n",
        "  classWeight_Dict['output'+str(i+1)]={0:1+1/((1-ratioTrue)/(ratioTrue)+1),1:1+(1-ratioTrue)/(ratioTrue)/((1-ratioTrue)/(ratioTrue)+1)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8C5_nNdl9Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict['output4'][1]+=1\n",
        "classWeight_Dict['output4'][0]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaoPIhG5PE0e",
        "colab_type": "code",
        "outputId": "b9e35767-518d-48e4-d7ed-bcb1c7783b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "classWeight_Dict"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output1': {0: 1.2345571818407344, 1: 1.7654428181592656},\n",
              " 'output10': {0: 1.0336144877201687, 1: 1.9663855122798313},\n",
              " 'output11': {0: 1.0100471347060282, 1: 1.9899528652939718},\n",
              " 'output12': {0: 1.0018605805011163, 1: 1.9981394194988837},\n",
              " 'output2': {0: 1.0604068469362442, 1: 1.9395931530637558},\n",
              " 'output3': {0: 1.074423220044654, 1: 1.925576779955346},\n",
              " 'output4': {0: 2.247085090548251, 1: 2.752914909451749},\n",
              " 'output5': {0: 1.0875713222525427, 1: 1.912428677747457},\n",
              " 'output6': {0: 1.1071694368643017, 1: 1.8928305631356983},\n",
              " 'output7': {0: 1.3979161498387498, 1: 1.6020838501612502},\n",
              " 'output8': {0: 1.1070453981642272, 1: 1.8929546018357728},\n",
              " 'output9': {0: 1.076779955346068, 1: 1.923220044653932}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2mz_N6c7mEx",
        "colab_type": "text"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytjcvIOnMiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_crossentropy(y_true, y_pred, weights,from_logits=False,label_smoothing=0):\n",
        "\n",
        "    y_pred = ops.convert_to_tensor(y_pred)\n",
        "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
        "    label_smoothing = ops.convert_to_tensor(label_smoothing, dtype=K.floatx())\n",
        "    def _smooth_labels():\n",
        "      return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
        "    y_true = smart_cond.smart_cond(label_smoothing,_smooth_labels, lambda: y_true)\n",
        "    \n",
        "    mask0 = tf.subtract(tf.constant(1.0, dtype=K.floatx()),y_true)\n",
        "    mask0=tf.math.scalar_mul(tf.constant(weights[0], dtype=K.floatx()),mask0)\n",
        "    mask1 =tf.math.scalar_mul(tf.constant(weights[1], dtype=K.floatx()),y_true)\n",
        "    mask=tf.math.add(mask0,mask1)\n",
        "\n",
        "    return K.mean(tf.math.multiply(K.binary_crossentropy(y_true, y_pred, from_logits=from_logits),mask), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKQSOUM5saC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    inputs = Input(shape=(MAX_LEN*3,N_CHANNELS))\n",
        "    x = SpatialDropout1D(0.2)(inputs)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "\n",
        "    hidden = concatenate([\n",
        "        GlobalMaxPooling1D()(x),\n",
        "        GlobalAveragePooling1D()(x),\n",
        "    ])\n",
        "\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    RESULT=[]\n",
        "    for i in range(N_CLASS):\n",
        "      RESULT+=[Dense(1, activation='sigmoid',name='output'+str(i+1))(hidden)]\n",
        "    LOSS={}\n",
        "    for i in  range(N_CLASS):\n",
        "      LOSS['output'+str(i+1)]=partial(binary_crossentropy, weights=classWeight_Dict['output'+str(i+1)])\n",
        "      LOSS['output'+str(i+1)].__name__ = 'loss'+str(i+1)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=RESULT)\n",
        "    model.compile(loss=LOSS, optimizer='adam',metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N37opYym6CCC",
        "colab_type": "code",
        "outputId": "9121d112-1181-40d4-9d3f-c581946f89d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           [(None, 3777, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_6 (SpatialDro (None, 3777, 768)    0           input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_12 (Bidirectional (None, 3777, 128)    426496      spatial_dropout1d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_13 (Bidirectional (None, 3777, 128)    98816       bidirectional_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 256)          0           global_max_pooling1d_6[0][0]     \n",
            "                                                                 global_average_pooling1d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 256)          65792       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 256)          0           concatenate_6[0][0]              \n",
            "                                                                 dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 256)          65792       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 256)          0           add_12[0][0]                     \n",
            "                                                                 dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            257         add_13[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 659,980\n",
            "Trainable params: 659,980\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sb5GQmKeI_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback=ReduceLROnPlateau(patience=1,min_lr=0.00001,factor=0.3)\n",
        "Name='BERT/BiLSTM_Contex.h5'\n",
        "checkpointer = ModelCheckpoint(filepath=Name, verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4To3UbV67kft",
        "colab_type": "code",
        "outputId": "ed45aeea-2d04-47bd-a2d2-fd94886afa8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=training_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpointer,callback])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 5.4262 - output1_loss: 0.3959 - output2_loss: 0.3400 - output3_loss: 0.4258 - output4_loss: 1.3192 - output5_loss: 0.4575 - output6_loss: 0.5198 - output7_loss: 0.7455 - output8_loss: 0.4843 - output9_loss: 0.3946 - output10_loss: 0.2090 - output11_loss: 0.1014 - output12_loss: 0.0331 - output1_binary_accuracy: 0.8939 - output2_binary_accuracy: 0.9394 - output3_binary_accuracy: 0.9252 - output4_binary_accuracy: 0.7602 - output5_binary_accuracy: 0.9086 - output6_binary_accuracy: 0.8882 - output7_binary_accuracy: 0.7549 - output8_binary_accuracy: 0.8891 - output9_binary_accuracy: 0.9212 - output10_binary_accuracy: 0.9651 - output11_binary_accuracy: 0.9900 - output12_binary_accuracy: 0.9944\n",
            "Epoch 00001: val_loss improved from inf to 4.67420, saving model to BERT/BiLSTM_Contex.h5\n",
            "251/251 [==============================] - 207s 824ms/step - loss: 5.4262 - output1_loss: 0.3959 - output2_loss: 0.3400 - output3_loss: 0.4258 - output4_loss: 1.3192 - output5_loss: 0.4575 - output6_loss: 0.5198 - output7_loss: 0.7455 - output8_loss: 0.4843 - output9_loss: 0.3946 - output10_loss: 0.2090 - output11_loss: 0.1014 - output12_loss: 0.0331 - output1_binary_accuracy: 0.8939 - output2_binary_accuracy: 0.9394 - output3_binary_accuracy: 0.9252 - output4_binary_accuracy: 0.7602 - output5_binary_accuracy: 0.9086 - output6_binary_accuracy: 0.8882 - output7_binary_accuracy: 0.7549 - output8_binary_accuracy: 0.8891 - output9_binary_accuracy: 0.9212 - output10_binary_accuracy: 0.9651 - output11_binary_accuracy: 0.9900 - output12_binary_accuracy: 0.9944 - val_loss: 4.6742 - val_output1_loss: 0.2807 - val_output2_loss: 0.2975 - val_output3_loss: 0.3860 - val_output4_loss: 1.3310 - val_output5_loss: 0.3956 - val_output6_loss: 0.5019 - val_output7_loss: 0.5522 - val_output8_loss: 0.3522 - val_output9_loss: 0.3416 - val_output10_loss: 0.1713 - val_output11_loss: 0.0596 - val_output12_loss: 0.0046 - val_output1_binary_accuracy: 0.9316 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9287 - val_output4_binary_accuracy: 0.7549 - val_output5_binary_accuracy: 0.9199 - val_output6_binary_accuracy: 0.8955 - val_output7_binary_accuracy: 0.8438 - val_output8_binary_accuracy: 0.9092 - val_output9_binary_accuracy: 0.9326 - val_output10_binary_accuracy: 0.9453 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 4.5527 - output1_loss: 0.2537 - output2_loss: 0.2890 - output3_loss: 0.3954 - output4_loss: 1.2333 - output5_loss: 0.3980 - output6_loss: 0.4663 - output7_loss: 0.5436 - output8_loss: 0.3747 - output9_loss: 0.3380 - output10_loss: 0.1447 - output11_loss: 0.0931 - output12_loss: 0.0229 - output1_binary_accuracy: 0.9437 - output2_binary_accuracy: 0.9345 - output3_binary_accuracy: 0.9252 - output4_binary_accuracy: 0.7761 - output5_binary_accuracy: 0.9140 - output6_binary_accuracy: 0.8945 - output7_binary_accuracy: 0.8491 - output8_binary_accuracy: 0.8983 - output9_binary_accuracy: 0.9124 - output10_binary_accuracy: 0.9608 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00002: val_loss improved from 4.67420 to 4.11498, saving model to BERT/BiLSTM_Contex.h5\n",
            "251/251 [==============================] - 204s 814ms/step - loss: 4.5527 - output1_loss: 0.2537 - output2_loss: 0.2890 - output3_loss: 0.3954 - output4_loss: 1.2333 - output5_loss: 0.3980 - output6_loss: 0.4663 - output7_loss: 0.5436 - output8_loss: 0.3747 - output9_loss: 0.3380 - output10_loss: 0.1447 - output11_loss: 0.0931 - output12_loss: 0.0229 - output1_binary_accuracy: 0.9437 - output2_binary_accuracy: 0.9345 - output3_binary_accuracy: 0.9252 - output4_binary_accuracy: 0.7761 - output5_binary_accuracy: 0.9140 - output6_binary_accuracy: 0.8945 - output7_binary_accuracy: 0.8491 - output8_binary_accuracy: 0.8983 - output9_binary_accuracy: 0.9124 - output10_binary_accuracy: 0.9608 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981 - val_loss: 4.1150 - val_output1_loss: 0.2287 - val_output2_loss: 0.2878 - val_output3_loss: 0.3659 - val_output4_loss: 1.1744 - val_output5_loss: 0.3572 - val_output6_loss: 0.4310 - val_output7_loss: 0.4626 - val_output8_loss: 0.2978 - val_output9_loss: 0.3158 - val_output10_loss: 0.1402 - val_output11_loss: 0.0486 - val_output12_loss: 0.0051 - val_output1_binary_accuracy: 0.9473 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9277 - val_output4_binary_accuracy: 0.7998 - val_output5_binary_accuracy: 0.8877 - val_output6_binary_accuracy: 0.8906 - val_output7_binary_accuracy: 0.8809 - val_output8_binary_accuracy: 0.9199 - val_output9_binary_accuracy: 0.9287 - val_output10_binary_accuracy: 0.9629 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 4.1852 - output1_loss: 0.2168 - output2_loss: 0.2701 - output3_loss: 0.3702 - output4_loss: 1.1884 - output5_loss: 0.3565 - output6_loss: 0.4107 - output7_loss: 0.4754 - output8_loss: 0.3360 - output9_loss: 0.3341 - output10_loss: 0.1203 - output11_loss: 0.0849 - output12_loss: 0.0217 - output1_binary_accuracy: 0.9536 - output2_binary_accuracy: 0.9330 - output3_binary_accuracy: 0.9223 - output4_binary_accuracy: 0.7877 - output5_binary_accuracy: 0.9128 - output6_binary_accuracy: 0.9004 - output7_binary_accuracy: 0.8746 - output8_binary_accuracy: 0.9087 - output9_binary_accuracy: 0.9171 - output10_binary_accuracy: 0.9666 - output11_binary_accuracy: 0.9900 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00003: val_loss improved from 4.11498 to 3.94794, saving model to BERT/BiLSTM_Contex.h5\n",
            "251/251 [==============================] - 204s 814ms/step - loss: 4.1852 - output1_loss: 0.2168 - output2_loss: 0.2701 - output3_loss: 0.3702 - output4_loss: 1.1884 - output5_loss: 0.3565 - output6_loss: 0.4107 - output7_loss: 0.4754 - output8_loss: 0.3360 - output9_loss: 0.3341 - output10_loss: 0.1203 - output11_loss: 0.0849 - output12_loss: 0.0217 - output1_binary_accuracy: 0.9536 - output2_binary_accuracy: 0.9330 - output3_binary_accuracy: 0.9223 - output4_binary_accuracy: 0.7877 - output5_binary_accuracy: 0.9128 - output6_binary_accuracy: 0.9004 - output7_binary_accuracy: 0.8746 - output8_binary_accuracy: 0.9087 - output9_binary_accuracy: 0.9171 - output10_binary_accuracy: 0.9666 - output11_binary_accuracy: 0.9900 - output12_binary_accuracy: 0.9981 - val_loss: 3.9479 - val_output1_loss: 0.2266 - val_output2_loss: 0.2686 - val_output3_loss: 0.3428 - val_output4_loss: 1.1576 - val_output5_loss: 0.3382 - val_output6_loss: 0.3719 - val_output7_loss: 0.4408 - val_output8_loss: 0.3094 - val_output9_loss: 0.3019 - val_output10_loss: 0.1305 - val_output11_loss: 0.0548 - val_output12_loss: 0.0048 - val_output1_binary_accuracy: 0.9551 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9277 - val_output4_binary_accuracy: 0.7939 - val_output5_binary_accuracy: 0.9180 - val_output6_binary_accuracy: 0.9160 - val_output7_binary_accuracy: 0.8848 - val_output8_binary_accuracy: 0.8936 - val_output9_binary_accuracy: 0.9336 - val_output10_binary_accuracy: 0.9707 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.9460 - output1_loss: 0.1900 - output2_loss: 0.2601 - output3_loss: 0.3480 - output4_loss: 1.1627 - output5_loss: 0.3338 - output6_loss: 0.3732 - output7_loss: 0.4323 - output8_loss: 0.3235 - output9_loss: 0.3150 - output10_loss: 0.1057 - output11_loss: 0.0804 - output12_loss: 0.0213 - output1_binary_accuracy: 0.9595 - output2_binary_accuracy: 0.9356 - output3_binary_accuracy: 0.9206 - output4_binary_accuracy: 0.7939 - output5_binary_accuracy: 0.9160 - output6_binary_accuracy: 0.9102 - output7_binary_accuracy: 0.8843 - output8_binary_accuracy: 0.9141 - output9_binary_accuracy: 0.9143 - output10_binary_accuracy: 0.9707 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00004: val_loss improved from 3.94794 to 3.78282, saving model to BERT/BiLSTM_Contex.h5\n",
            "251/251 [==============================] - 204s 811ms/step - loss: 3.9460 - output1_loss: 0.1900 - output2_loss: 0.2601 - output3_loss: 0.3480 - output4_loss: 1.1627 - output5_loss: 0.3338 - output6_loss: 0.3732 - output7_loss: 0.4323 - output8_loss: 0.3235 - output9_loss: 0.3150 - output10_loss: 0.1057 - output11_loss: 0.0804 - output12_loss: 0.0213 - output1_binary_accuracy: 0.9595 - output2_binary_accuracy: 0.9356 - output3_binary_accuracy: 0.9206 - output4_binary_accuracy: 0.7939 - output5_binary_accuracy: 0.9160 - output6_binary_accuracy: 0.9102 - output7_binary_accuracy: 0.8843 - output8_binary_accuracy: 0.9141 - output9_binary_accuracy: 0.9143 - output10_binary_accuracy: 0.9707 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981 - val_loss: 3.7828 - val_output1_loss: 0.1985 - val_output2_loss: 0.2561 - val_output3_loss: 0.3316 - val_output4_loss: 1.1652 - val_output5_loss: 0.3282 - val_output6_loss: 0.3372 - val_output7_loss: 0.4144 - val_output8_loss: 0.2808 - val_output9_loss: 0.2965 - val_output10_loss: 0.1169 - val_output11_loss: 0.0546 - val_output12_loss: 0.0027 - val_output1_binary_accuracy: 0.9531 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9229 - val_output4_binary_accuracy: 0.7939 - val_output5_binary_accuracy: 0.9150 - val_output6_binary_accuracy: 0.9238 - val_output7_binary_accuracy: 0.8955 - val_output8_binary_accuracy: 0.9170 - val_output9_binary_accuracy: 0.9336 - val_output10_binary_accuracy: 0.9619 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.7434 - output1_loss: 0.1680 - output2_loss: 0.2488 - output3_loss: 0.3317 - output4_loss: 1.1273 - output5_loss: 0.3208 - output6_loss: 0.3529 - output7_loss: 0.4015 - output8_loss: 0.2920 - output9_loss: 0.3069 - output10_loss: 0.0987 - output11_loss: 0.0754 - output12_loss: 0.0196 - output1_binary_accuracy: 0.9650 - output2_binary_accuracy: 0.9343 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8069 - output5_binary_accuracy: 0.9191 - output6_binary_accuracy: 0.9187 - output7_binary_accuracy: 0.8954 - output8_binary_accuracy: 0.9236 - output9_binary_accuracy: 0.9146 - output10_binary_accuracy: 0.9724 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00005: val_loss improved from 3.78282 to 3.74092, saving model to BERT/BiLSTM_Contex.h5\n",
            "251/251 [==============================] - 204s 815ms/step - loss: 3.7434 - output1_loss: 0.1680 - output2_loss: 0.2488 - output3_loss: 0.3317 - output4_loss: 1.1273 - output5_loss: 0.3208 - output6_loss: 0.3529 - output7_loss: 0.4015 - output8_loss: 0.2920 - output9_loss: 0.3069 - output10_loss: 0.0987 - output11_loss: 0.0754 - output12_loss: 0.0196 - output1_binary_accuracy: 0.9650 - output2_binary_accuracy: 0.9343 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8069 - output5_binary_accuracy: 0.9191 - output6_binary_accuracy: 0.9187 - output7_binary_accuracy: 0.8954 - output8_binary_accuracy: 0.9236 - output9_binary_accuracy: 0.9146 - output10_binary_accuracy: 0.9724 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981 - val_loss: 3.7409 - val_output1_loss: 0.1935 - val_output2_loss: 0.2564 - val_output3_loss: 0.3280 - val_output4_loss: 1.1549 - val_output5_loss: 0.3332 - val_output6_loss: 0.3278 - val_output7_loss: 0.3923 - val_output8_loss: 0.2600 - val_output9_loss: 0.3108 - val_output10_loss: 0.1292 - val_output11_loss: 0.0512 - val_output12_loss: 0.0036 - val_output1_binary_accuracy: 0.9570 - val_output2_binary_accuracy: 0.9307 - val_output3_binary_accuracy: 0.9209 - val_output4_binary_accuracy: 0.7988 - val_output5_binary_accuracy: 0.9170 - val_output6_binary_accuracy: 0.9238 - val_output7_binary_accuracy: 0.8994 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9316 - val_output10_binary_accuracy: 0.9551 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.5793 - output1_loss: 0.1538 - output2_loss: 0.2369 - output3_loss: 0.3246 - output4_loss: 1.0939 - output5_loss: 0.3099 - output6_loss: 0.3336 - output7_loss: 0.3772 - output8_loss: 0.2779 - output9_loss: 0.2926 - output10_loss: 0.0906 - output11_loss: 0.0690 - output12_loss: 0.0191 - output1_binary_accuracy: 0.9696 - output2_binary_accuracy: 0.9364 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8154 - output5_binary_accuracy: 0.9221 - output6_binary_accuracy: 0.9203 - output7_binary_accuracy: 0.9051 - output8_binary_accuracy: 0.9260 - output9_binary_accuracy: 0.9171 - output10_binary_accuracy: 0.9760 - output11_binary_accuracy: 0.9903 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00006: val_loss improved from 3.74092 to 3.73500, saving model to BERT/BiLSTM_Contex.h5\n",
            "251/251 [==============================] - 205s 816ms/step - loss: 3.5793 - output1_loss: 0.1538 - output2_loss: 0.2369 - output3_loss: 0.3246 - output4_loss: 1.0939 - output5_loss: 0.3099 - output6_loss: 0.3336 - output7_loss: 0.3772 - output8_loss: 0.2779 - output9_loss: 0.2926 - output10_loss: 0.0906 - output11_loss: 0.0690 - output12_loss: 0.0191 - output1_binary_accuracy: 0.9696 - output2_binary_accuracy: 0.9364 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8154 - output5_binary_accuracy: 0.9221 - output6_binary_accuracy: 0.9203 - output7_binary_accuracy: 0.9051 - output8_binary_accuracy: 0.9260 - output9_binary_accuracy: 0.9171 - output10_binary_accuracy: 0.9760 - output11_binary_accuracy: 0.9903 - output12_binary_accuracy: 0.9981 - val_loss: 3.7350 - val_output1_loss: 0.1867 - val_output2_loss: 0.2501 - val_output3_loss: 0.3356 - val_output4_loss: 1.1468 - val_output5_loss: 0.3255 - val_output6_loss: 0.3281 - val_output7_loss: 0.4203 - val_output8_loss: 0.2482 - val_output9_loss: 0.2961 - val_output10_loss: 0.1269 - val_output11_loss: 0.0643 - val_output12_loss: 0.0064 - val_output1_binary_accuracy: 0.9541 - val_output2_binary_accuracy: 0.9238 - val_output3_binary_accuracy: 0.9277 - val_output4_binary_accuracy: 0.7979 - val_output5_binary_accuracy: 0.9141 - val_output6_binary_accuracy: 0.9248 - val_output7_binary_accuracy: 0.9004 - val_output8_binary_accuracy: 0.9268 - val_output9_binary_accuracy: 0.9336 - val_output10_binary_accuracy: 0.9678 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.3930 - output1_loss: 0.1403 - output2_loss: 0.2164 - output3_loss: 0.3139 - output4_loss: 1.0513 - output5_loss: 0.2992 - output6_loss: 0.3142 - output7_loss: 0.3542 - output8_loss: 0.2650 - output9_loss: 0.2801 - output10_loss: 0.0777 - output11_loss: 0.0620 - output12_loss: 0.0186 - output1_binary_accuracy: 0.9731 - output2_binary_accuracy: 0.9421 - output3_binary_accuracy: 0.9199 - output4_binary_accuracy: 0.8258 - output5_binary_accuracy: 0.9217 - output6_binary_accuracy: 0.9254 - output7_binary_accuracy: 0.9084 - output8_binary_accuracy: 0.9293 - output9_binary_accuracy: 0.9221 - output10_binary_accuracy: 0.9782 - output11_binary_accuracy: 0.9903 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00007: val_loss improved from 3.73500 to 3.71490, saving model to BERT/BiLSTM_Contex.h5\n",
            "251/251 [==============================] - 205s 815ms/step - loss: 3.3930 - output1_loss: 0.1403 - output2_loss: 0.2164 - output3_loss: 0.3139 - output4_loss: 1.0513 - output5_loss: 0.2992 - output6_loss: 0.3142 - output7_loss: 0.3542 - output8_loss: 0.2650 - output9_loss: 0.2801 - output10_loss: 0.0777 - output11_loss: 0.0620 - output12_loss: 0.0186 - output1_binary_accuracy: 0.9731 - output2_binary_accuracy: 0.9421 - output3_binary_accuracy: 0.9199 - output4_binary_accuracy: 0.8258 - output5_binary_accuracy: 0.9217 - output6_binary_accuracy: 0.9254 - output7_binary_accuracy: 0.9084 - output8_binary_accuracy: 0.9293 - output9_binary_accuracy: 0.9221 - output10_binary_accuracy: 0.9782 - output11_binary_accuracy: 0.9903 - output12_binary_accuracy: 0.9981 - val_loss: 3.7149 - val_output1_loss: 0.1991 - val_output2_loss: 0.2461 - val_output3_loss: 0.3444 - val_output4_loss: 1.1340 - val_output5_loss: 0.3410 - val_output6_loss: 0.3211 - val_output7_loss: 0.3942 - val_output8_loss: 0.2601 - val_output9_loss: 0.2979 - val_output10_loss: 0.1171 - val_output11_loss: 0.0511 - val_output12_loss: 0.0088 - val_output1_binary_accuracy: 0.9570 - val_output2_binary_accuracy: 0.9375 - val_output3_binary_accuracy: 0.9258 - val_output4_binary_accuracy: 0.8037 - val_output5_binary_accuracy: 0.9170 - val_output6_binary_accuracy: 0.9238 - val_output7_binary_accuracy: 0.8975 - val_output8_binary_accuracy: 0.9189 - val_output9_binary_accuracy: 0.9346 - val_output10_binary_accuracy: 0.9639 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.2214 - output1_loss: 0.1270 - output2_loss: 0.1996 - output3_loss: 0.3046 - output4_loss: 1.0135 - output5_loss: 0.2828 - output6_loss: 0.3031 - output7_loss: 0.3334 - output8_loss: 0.2468 - output9_loss: 0.2621 - output10_loss: 0.0757 - output11_loss: 0.0560 - output12_loss: 0.0169 - output1_binary_accuracy: 0.9761 - output2_binary_accuracy: 0.9486 - output3_binary_accuracy: 0.9211 - output4_binary_accuracy: 0.8325 - output5_binary_accuracy: 0.9247 - output6_binary_accuracy: 0.9294 - output7_binary_accuracy: 0.9171 - output8_binary_accuracy: 0.9384 - output9_binary_accuracy: 0.9229 - output10_binary_accuracy: 0.9780 - output11_binary_accuracy: 0.9914 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00008: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 205s 816ms/step - loss: 3.2214 - output1_loss: 0.1270 - output2_loss: 0.1996 - output3_loss: 0.3046 - output4_loss: 1.0135 - output5_loss: 0.2828 - output6_loss: 0.3031 - output7_loss: 0.3334 - output8_loss: 0.2468 - output9_loss: 0.2621 - output10_loss: 0.0757 - output11_loss: 0.0560 - output12_loss: 0.0169 - output1_binary_accuracy: 0.9761 - output2_binary_accuracy: 0.9486 - output3_binary_accuracy: 0.9211 - output4_binary_accuracy: 0.8325 - output5_binary_accuracy: 0.9247 - output6_binary_accuracy: 0.9294 - output7_binary_accuracy: 0.9171 - output8_binary_accuracy: 0.9384 - output9_binary_accuracy: 0.9229 - output10_binary_accuracy: 0.9780 - output11_binary_accuracy: 0.9914 - output12_binary_accuracy: 0.9981 - val_loss: 3.7431 - val_output1_loss: 0.1820 - val_output2_loss: 0.2465 - val_output3_loss: 0.3320 - val_output4_loss: 1.1628 - val_output5_loss: 0.3431 - val_output6_loss: 0.3197 - val_output7_loss: 0.3934 - val_output8_loss: 0.2751 - val_output9_loss: 0.2904 - val_output10_loss: 0.1543 - val_output11_loss: 0.0398 - val_output12_loss: 0.0040 - val_output1_binary_accuracy: 0.9648 - val_output2_binary_accuracy: 0.9199 - val_output3_binary_accuracy: 0.9043 - val_output4_binary_accuracy: 0.8057 - val_output5_binary_accuracy: 0.9258 - val_output6_binary_accuracy: 0.9316 - val_output7_binary_accuracy: 0.8965 - val_output8_binary_accuracy: 0.9326 - val_output9_binary_accuracy: 0.9131 - val_output10_binary_accuracy: 0.9678 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.8287 - output1_loss: 0.1041 - output2_loss: 0.1745 - output3_loss: 0.2884 - output4_loss: 0.8935 - output5_loss: 0.2558 - output6_loss: 0.2735 - output7_loss: 0.2738 - output8_loss: 0.2132 - output9_loss: 0.2362 - output10_loss: 0.0559 - output11_loss: 0.0442 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9807 - output2_binary_accuracy: 0.9532 - output3_binary_accuracy: 0.9197 - output4_binary_accuracy: 0.8532 - output5_binary_accuracy: 0.9321 - output6_binary_accuracy: 0.9374 - output7_binary_accuracy: 0.9340 - output8_binary_accuracy: 0.9480 - output9_binary_accuracy: 0.9331 - output10_binary_accuracy: 0.9834 - output11_binary_accuracy: 0.9915 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00009: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 205s 816ms/step - loss: 2.8287 - output1_loss: 0.1041 - output2_loss: 0.1745 - output3_loss: 0.2884 - output4_loss: 0.8935 - output5_loss: 0.2558 - output6_loss: 0.2735 - output7_loss: 0.2738 - output8_loss: 0.2132 - output9_loss: 0.2362 - output10_loss: 0.0559 - output11_loss: 0.0442 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9807 - output2_binary_accuracy: 0.9532 - output3_binary_accuracy: 0.9197 - output4_binary_accuracy: 0.8532 - output5_binary_accuracy: 0.9321 - output6_binary_accuracy: 0.9374 - output7_binary_accuracy: 0.9340 - output8_binary_accuracy: 0.9480 - output9_binary_accuracy: 0.9331 - output10_binary_accuracy: 0.9834 - output11_binary_accuracy: 0.9915 - output12_binary_accuracy: 0.9981 - val_loss: 3.7448 - val_output1_loss: 0.2048 - val_output2_loss: 0.2664 - val_output3_loss: 0.3308 - val_output4_loss: 1.1863 - val_output5_loss: 0.3384 - val_output6_loss: 0.3106 - val_output7_loss: 0.3793 - val_output8_loss: 0.2631 - val_output9_loss: 0.2782 - val_output10_loss: 0.1438 - val_output11_loss: 0.0402 - val_output12_loss: 0.0028 - val_output1_binary_accuracy: 0.9561 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9150 - val_output4_binary_accuracy: 0.7852 - val_output5_binary_accuracy: 0.9248 - val_output6_binary_accuracy: 0.9355 - val_output7_binary_accuracy: 0.9150 - val_output8_binary_accuracy: 0.9248 - val_output9_binary_accuracy: 0.9199 - val_output10_binary_accuracy: 0.9707 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 3.0000e-04\n",
            "Epoch 10/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6056 - output1_loss: 0.0926 - output2_loss: 0.1618 - output3_loss: 0.2721 - output4_loss: 0.8218 - output5_loss: 0.2417 - output6_loss: 0.2549 - output7_loss: 0.2474 - output8_loss: 0.1935 - output9_loss: 0.2187 - output10_loss: 0.0482 - output11_loss: 0.0385 - output12_loss: 0.0143 - output1_binary_accuracy: 0.9821 - output2_binary_accuracy: 0.9577 - output3_binary_accuracy: 0.9227 - output4_binary_accuracy: 0.8660 - output5_binary_accuracy: 0.9353 - output6_binary_accuracy: 0.9430 - output7_binary_accuracy: 0.9404 - output8_binary_accuracy: 0.9527 - output9_binary_accuracy: 0.9394 - output10_binary_accuracy: 0.9858 - output11_binary_accuracy: 0.9935 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00010: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 205s 818ms/step - loss: 2.6056 - output1_loss: 0.0926 - output2_loss: 0.1618 - output3_loss: 0.2721 - output4_loss: 0.8218 - output5_loss: 0.2417 - output6_loss: 0.2549 - output7_loss: 0.2474 - output8_loss: 0.1935 - output9_loss: 0.2187 - output10_loss: 0.0482 - output11_loss: 0.0385 - output12_loss: 0.0143 - output1_binary_accuracy: 0.9821 - output2_binary_accuracy: 0.9577 - output3_binary_accuracy: 0.9227 - output4_binary_accuracy: 0.8660 - output5_binary_accuracy: 0.9353 - output6_binary_accuracy: 0.9430 - output7_binary_accuracy: 0.9404 - output8_binary_accuracy: 0.9527 - output9_binary_accuracy: 0.9394 - output10_binary_accuracy: 0.9858 - output11_binary_accuracy: 0.9935 - output12_binary_accuracy: 0.9981 - val_loss: 3.7719 - val_output1_loss: 0.1964 - val_output2_loss: 0.2587 - val_output3_loss: 0.3326 - val_output4_loss: 1.1986 - val_output5_loss: 0.3492 - val_output6_loss: 0.3192 - val_output7_loss: 0.3845 - val_output8_loss: 0.2715 - val_output9_loss: 0.2786 - val_output10_loss: 0.1440 - val_output11_loss: 0.0356 - val_output12_loss: 0.0030 - val_output1_binary_accuracy: 0.9600 - val_output2_binary_accuracy: 0.9375 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.7920 - val_output5_binary_accuracy: 0.9121 - val_output6_binary_accuracy: 0.9297 - val_output7_binary_accuracy: 0.9082 - val_output8_binary_accuracy: 0.9258 - val_output9_binary_accuracy: 0.9268 - val_output10_binary_accuracy: 0.9707 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 9.0000e-05\n",
            "Epoch 11/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.5298 - output1_loss: 0.0899 - output2_loss: 0.1542 - output3_loss: 0.2710 - output4_loss: 0.7949 - output5_loss: 0.2387 - output6_loss: 0.2484 - output7_loss: 0.2390 - output8_loss: 0.1846 - output9_loss: 0.2126 - output10_loss: 0.0454 - output11_loss: 0.0372 - output12_loss: 0.0139 - output1_binary_accuracy: 0.9828 - output2_binary_accuracy: 0.9599 - output3_binary_accuracy: 0.9257 - output4_binary_accuracy: 0.8750 - output5_binary_accuracy: 0.9364 - output6_binary_accuracy: 0.9446 - output7_binary_accuracy: 0.9422 - output8_binary_accuracy: 0.9543 - output9_binary_accuracy: 0.9406 - output10_binary_accuracy: 0.9879 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00011: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 206s 819ms/step - loss: 2.5298 - output1_loss: 0.0899 - output2_loss: 0.1542 - output3_loss: 0.2710 - output4_loss: 0.7949 - output5_loss: 0.2387 - output6_loss: 0.2484 - output7_loss: 0.2390 - output8_loss: 0.1846 - output9_loss: 0.2126 - output10_loss: 0.0454 - output11_loss: 0.0372 - output12_loss: 0.0139 - output1_binary_accuracy: 0.9828 - output2_binary_accuracy: 0.9599 - output3_binary_accuracy: 0.9257 - output4_binary_accuracy: 0.8750 - output5_binary_accuracy: 0.9364 - output6_binary_accuracy: 0.9446 - output7_binary_accuracy: 0.9422 - output8_binary_accuracy: 0.9543 - output9_binary_accuracy: 0.9406 - output10_binary_accuracy: 0.9879 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981 - val_loss: 3.7873 - val_output1_loss: 0.2018 - val_output2_loss: 0.2576 - val_output3_loss: 0.3263 - val_output4_loss: 1.2136 - val_output5_loss: 0.3516 - val_output6_loss: 0.3122 - val_output7_loss: 0.3898 - val_output8_loss: 0.2671 - val_output9_loss: 0.2786 - val_output10_loss: 0.1496 - val_output11_loss: 0.0360 - val_output12_loss: 0.0029 - val_output1_binary_accuracy: 0.9580 - val_output2_binary_accuracy: 0.9375 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.7988 - val_output5_binary_accuracy: 0.9170 - val_output6_binary_accuracy: 0.9307 - val_output7_binary_accuracy: 0.9082 - val_output8_binary_accuracy: 0.9258 - val_output9_binary_accuracy: 0.9189 - val_output10_binary_accuracy: 0.9697 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 2.7000e-05\n",
            "Epoch 12/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.5176 - output1_loss: 0.0915 - output2_loss: 0.1505 - output3_loss: 0.2677 - output4_loss: 0.7861 - output5_loss: 0.2378 - output6_loss: 0.2514 - output7_loss: 0.2372 - output8_loss: 0.1845 - output9_loss: 0.2173 - output10_loss: 0.0426 - output11_loss: 0.0371 - output12_loss: 0.0140 - output1_binary_accuracy: 0.9823 - output2_binary_accuracy: 0.9593 - output3_binary_accuracy: 0.9238 - output4_binary_accuracy: 0.8715 - output5_binary_accuracy: 0.9377 - output6_binary_accuracy: 0.9412 - output7_binary_accuracy: 0.9425 - output8_binary_accuracy: 0.9532 - output9_binary_accuracy: 0.9399 - output10_binary_accuracy: 0.9884 - output11_binary_accuracy: 0.9937 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00012: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 205s 817ms/step - loss: 2.5176 - output1_loss: 0.0915 - output2_loss: 0.1505 - output3_loss: 0.2677 - output4_loss: 0.7861 - output5_loss: 0.2378 - output6_loss: 0.2514 - output7_loss: 0.2372 - output8_loss: 0.1845 - output9_loss: 0.2173 - output10_loss: 0.0426 - output11_loss: 0.0371 - output12_loss: 0.0140 - output1_binary_accuracy: 0.9823 - output2_binary_accuracy: 0.9593 - output3_binary_accuracy: 0.9238 - output4_binary_accuracy: 0.8715 - output5_binary_accuracy: 0.9377 - output6_binary_accuracy: 0.9412 - output7_binary_accuracy: 0.9425 - output8_binary_accuracy: 0.9532 - output9_binary_accuracy: 0.9399 - output10_binary_accuracy: 0.9884 - output11_binary_accuracy: 0.9937 - output12_binary_accuracy: 0.9981 - val_loss: 3.7965 - val_output1_loss: 0.2033 - val_output2_loss: 0.2511 - val_output3_loss: 0.3342 - val_output4_loss: 1.2088 - val_output5_loss: 0.3517 - val_output6_loss: 0.3195 - val_output7_loss: 0.3917 - val_output8_loss: 0.2676 - val_output9_loss: 0.2768 - val_output10_loss: 0.1527 - val_output11_loss: 0.0362 - val_output12_loss: 0.0028 - val_output1_binary_accuracy: 0.9570 - val_output2_binary_accuracy: 0.9375 - val_output3_binary_accuracy: 0.9160 - val_output4_binary_accuracy: 0.7920 - val_output5_binary_accuracy: 0.9170 - val_output6_binary_accuracy: 0.9307 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9268 - val_output9_binary_accuracy: 0.9180 - val_output10_binary_accuracy: 0.9707 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 13/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.5107 - output1_loss: 0.0890 - output2_loss: 0.1539 - output3_loss: 0.2689 - output4_loss: 0.7857 - output5_loss: 0.2386 - output6_loss: 0.2494 - output7_loss: 0.2353 - output8_loss: 0.1850 - output9_loss: 0.2123 - output10_loss: 0.0433 - output11_loss: 0.0359 - output12_loss: 0.0135 - output1_binary_accuracy: 0.9822 - output2_binary_accuracy: 0.9593 - output3_binary_accuracy: 0.9197 - output4_binary_accuracy: 0.8730 - output5_binary_accuracy: 0.9356 - output6_binary_accuracy: 0.9434 - output7_binary_accuracy: 0.9429 - output8_binary_accuracy: 0.9539 - output9_binary_accuracy: 0.9410 - output10_binary_accuracy: 0.9887 - output11_binary_accuracy: 0.9934 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00013: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 205s 816ms/step - loss: 2.5107 - output1_loss: 0.0890 - output2_loss: 0.1539 - output3_loss: 0.2689 - output4_loss: 0.7857 - output5_loss: 0.2386 - output6_loss: 0.2494 - output7_loss: 0.2353 - output8_loss: 0.1850 - output9_loss: 0.2123 - output10_loss: 0.0433 - output11_loss: 0.0359 - output12_loss: 0.0135 - output1_binary_accuracy: 0.9822 - output2_binary_accuracy: 0.9593 - output3_binary_accuracy: 0.9197 - output4_binary_accuracy: 0.8730 - output5_binary_accuracy: 0.9356 - output6_binary_accuracy: 0.9434 - output7_binary_accuracy: 0.9429 - output8_binary_accuracy: 0.9539 - output9_binary_accuracy: 0.9410 - output10_binary_accuracy: 0.9887 - output11_binary_accuracy: 0.9934 - output12_binary_accuracy: 0.9981 - val_loss: 3.7821 - val_output1_loss: 0.2006 - val_output2_loss: 0.2552 - val_output3_loss: 0.3303 - val_output4_loss: 1.2018 - val_output5_loss: 0.3437 - val_output6_loss: 0.3194 - val_output7_loss: 0.3906 - val_output8_loss: 0.2685 - val_output9_loss: 0.2797 - val_output10_loss: 0.1532 - val_output11_loss: 0.0361 - val_output12_loss: 0.0029 - val_output1_binary_accuracy: 0.9570 - val_output2_binary_accuracy: 0.9375 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.7930 - val_output5_binary_accuracy: 0.9180 - val_output6_binary_accuracy: 0.9307 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9277 - val_output9_binary_accuracy: 0.9150 - val_output10_binary_accuracy: 0.9707 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.4923 - output1_loss: 0.0892 - output2_loss: 0.1531 - output3_loss: 0.2653 - output4_loss: 0.7737 - output5_loss: 0.2385 - output6_loss: 0.2484 - output7_loss: 0.2359 - output8_loss: 0.1853 - output9_loss: 0.2125 - output10_loss: 0.0419 - output11_loss: 0.0351 - output12_loss: 0.0133 - output1_binary_accuracy: 0.9823 - output2_binary_accuracy: 0.9587 - output3_binary_accuracy: 0.9252 - output4_binary_accuracy: 0.8765 - output5_binary_accuracy: 0.9368 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9416 - output8_binary_accuracy: 0.9551 - output9_binary_accuracy: 0.9396 - output10_binary_accuracy: 0.9898 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00014: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 205s 816ms/step - loss: 2.4923 - output1_loss: 0.0892 - output2_loss: 0.1531 - output3_loss: 0.2653 - output4_loss: 0.7737 - output5_loss: 0.2385 - output6_loss: 0.2484 - output7_loss: 0.2359 - output8_loss: 0.1853 - output9_loss: 0.2125 - output10_loss: 0.0419 - output11_loss: 0.0351 - output12_loss: 0.0133 - output1_binary_accuracy: 0.9823 - output2_binary_accuracy: 0.9587 - output3_binary_accuracy: 0.9252 - output4_binary_accuracy: 0.8765 - output5_binary_accuracy: 0.9368 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9416 - output8_binary_accuracy: 0.9551 - output9_binary_accuracy: 0.9396 - output10_binary_accuracy: 0.9898 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981 - val_loss: 3.8084 - val_output1_loss: 0.2015 - val_output2_loss: 0.2602 - val_output3_loss: 0.3345 - val_output4_loss: 1.2220 - val_output5_loss: 0.3517 - val_output6_loss: 0.3169 - val_output7_loss: 0.3854 - val_output8_loss: 0.2679 - val_output9_loss: 0.2805 - val_output10_loss: 0.1490 - val_output11_loss: 0.0360 - val_output12_loss: 0.0028 - val_output1_binary_accuracy: 0.9580 - val_output2_binary_accuracy: 0.9365 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.7939 - val_output5_binary_accuracy: 0.9170 - val_output6_binary_accuracy: 0.9307 - val_output7_binary_accuracy: 0.9082 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9150 - val_output10_binary_accuracy: 0.9707 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.4937 - output1_loss: 0.0897 - output2_loss: 0.1536 - output3_loss: 0.2683 - output4_loss: 0.7735 - output5_loss: 0.2352 - output6_loss: 0.2484 - output7_loss: 0.2365 - output8_loss: 0.1864 - output9_loss: 0.2084 - output10_loss: 0.0442 - output11_loss: 0.0353 - output12_loss: 0.0142 - output1_binary_accuracy: 0.9828 - output2_binary_accuracy: 0.9607 - output3_binary_accuracy: 0.9243 - output4_binary_accuracy: 0.8745 - output5_binary_accuracy: 0.9358 - output6_binary_accuracy: 0.9427 - output7_binary_accuracy: 0.9415 - output8_binary_accuracy: 0.9521 - output9_binary_accuracy: 0.9416 - output10_binary_accuracy: 0.9872 - output11_binary_accuracy: 0.9934 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00015: val_loss did not improve from 3.71490\n",
            "251/251 [==============================] - 205s 818ms/step - loss: 2.4937 - output1_loss: 0.0897 - output2_loss: 0.1536 - output3_loss: 0.2683 - output4_loss: 0.7735 - output5_loss: 0.2352 - output6_loss: 0.2484 - output7_loss: 0.2365 - output8_loss: 0.1864 - output9_loss: 0.2084 - output10_loss: 0.0442 - output11_loss: 0.0353 - output12_loss: 0.0142 - output1_binary_accuracy: 0.9828 - output2_binary_accuracy: 0.9607 - output3_binary_accuracy: 0.9243 - output4_binary_accuracy: 0.8745 - output5_binary_accuracy: 0.9358 - output6_binary_accuracy: 0.9427 - output7_binary_accuracy: 0.9415 - output8_binary_accuracy: 0.9521 - output9_binary_accuracy: 0.9416 - output10_binary_accuracy: 0.9872 - output11_binary_accuracy: 0.9934 - output12_binary_accuracy: 0.9981 - val_loss: 3.8106 - val_output1_loss: 0.1999 - val_output2_loss: 0.2589 - val_output3_loss: 0.3335 - val_output4_loss: 1.2179 - val_output5_loss: 0.3526 - val_output6_loss: 0.3188 - val_output7_loss: 0.3917 - val_output8_loss: 0.2679 - val_output9_loss: 0.2801 - val_output10_loss: 0.1506 - val_output11_loss: 0.0360 - val_output12_loss: 0.0028 - val_output1_binary_accuracy: 0.9590 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7910 - val_output5_binary_accuracy: 0.9150 - val_output6_binary_accuracy: 0.9297 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9277 - val_output9_binary_accuracy: 0.9141 - val_output10_binary_accuracy: 0.9697 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faac6e140f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfSJxN--xs1",
        "colab_type": "text"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDym2PgJ6ml",
        "colab_type": "code",
        "outputId": "5fdeeba1-1d65-4054-9515-6b27bc8cee3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           [(None, 3777, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_6 (SpatialDro (None, 3777, 768)    0           input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_12 (Bidirectional (None, 3777, 128)    426496      spatial_dropout1d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_13 (Bidirectional (None, 3777, 128)    98816       bidirectional_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_6 (GlobalM (None, 128)          0           bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_6 (Glo (None, 128)          0           bidirectional_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 256)          0           global_max_pooling1d_6[0][0]     \n",
            "                                                                 global_average_pooling1d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 256)          65792       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 256)          0           concatenate_6[0][0]              \n",
            "                                                                 dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 256)          65792       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 256)          0           add_12[0][0]                     \n",
            "                                                                 dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            257         add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            257         add_13[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 659,980\n",
            "Trainable params: 659,980\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onSOnIBxPXa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(Name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZwqpZmP_pVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class testDataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=25, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim*3, self.n_channels))\n",
        "\n",
        "       # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            pos=list_IDs_temp.loc[i,'utterance_pos']\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            \n",
        "            if pos==1:\n",
        "              try:\n",
        "                temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp=np.zeros(( 512, self.n_channels))\n",
        "\n",
        "            elif pos==2:\n",
        "              try:\n",
        "                temp1=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-1)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp1=np.ones(( 512, self.n_channels))\n",
        "\n",
        "              try:\n",
        "                temp2=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp2=np.zeros(( 512, self.n_channels))\n",
        "\n",
        "              temp=np.concatenate((temp1,temp2),axis=0)\n",
        "\n",
        "            elif pos>=3:  \n",
        "              try:\n",
        "                temp1=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-2)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp1=np.ones(( 512, self.n_channels))\n",
        "\n",
        "              try:\n",
        "                temp2=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-1)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp2=np.ones(( 512, self.n_channels))              \n",
        "              \n",
        "              try:\n",
        "                temp3=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              except:\n",
        "                temp3=np.ones(( 512, self.n_channels))   \n",
        "\n",
        "              temp=np.concatenate((temp1,temp2,temp3),axis=0)\n",
        "\n",
        "            # Store sample\n",
        "            X[i,0:temp.shape[0],:] =temp \n",
        "\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnTSkm2_EBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator=testDataGenerator(Test,'Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MneDN8jV-spA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict_generator(test_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0iEXswMaFjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Prediction=np.array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3GWspxEe93u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true=np.array(Test.iloc[:,0:N_CLASS])\n",
        "y_pred=Prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHjjga8Rf5pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hamming_score(y_true, y_pred, toggle_output=False):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        if toggle_output:\n",
        "            print('set_true: {0}'.format([id2label[id] for id in set_true]), 'set_pred: {0}'.format([id2label[id] for id in set_pred]))\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        #print('tmp_a: {0}'.format(tmp_a))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIWmhjAYgzlg",
        "colab_type": "code",
        "outputId": "20cf2c5e-b86d-4d72-928b-92b527345d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hamming_score(y_true, y_pred, toggle_output=False)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.619963963963964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHKfPrFie7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "def f1(y_true, y_pred):\n",
        "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        \n",
        "        correct_preds += len(set_true & set_pred)\n",
        "        total_preds += len(set_pred)\n",
        "        total_correct += len(set_true)\n",
        "\n",
        "    p = correct_preds / total_preds if correct_preds > 0 else 0\n",
        "    r = correct_preds / total_correct if correct_preds > 0 else 0\n",
        "    f1 = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
        "    return p, r, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seCa3eD5cvdx",
        "colab_type": "code",
        "outputId": "1b2ee1ad-3c39-4de9-d4e3-56753a15f056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1(y_true, y_pred)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7181571815718157, 0.5915178571428571, 0.6487148102815178)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TShpwbNovrP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}