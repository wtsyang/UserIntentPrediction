{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNn+/H8k4ktnH+ifpuUXu2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtsyang/UserIntentPrediction/blob/BERT/BERT/LSTM-multiPrediction_addPenality_ReduceParameters_lrschedule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot0Ha--FR-S1",
        "colab_type": "code",
        "outputId": "5b26fcc4-9e61-4c4f-fe03-95af01ea4c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6DT7DNwSNn9",
        "colab_type": "code",
        "outputId": "37b17c45-4bf3-44ee-aa70-163fb64ed61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/UserIntentPrediction'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/UserIntentPrediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De681umQRanU",
        "colab_type": "code",
        "outputId": "11442190-bf29-42e2-d786-882ef68e177e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
        "from tensorflow.keras.layers  import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import pickle\n",
        "import sklearn\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import smart_cond\n",
        "from functools import partial\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print('Tensorflow Version:',tf.__version__)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIpXSpeYR4rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_MODELS = 1\n",
        "BATCH_SIZE = 32\n",
        "LSTM_UNITS = 64\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
        "EPOCHS = 24\n",
        "MAX_LEN = 1259\n",
        "N_CHANNELS=768\n",
        "N_CLASS=12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lcdmN7BSHGl",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p2_0TqoR9ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train=pd.read_csv('data/Train_Preprocessing.csv').reset_index(drop=True)\n",
        "Valid=pd.read_csv('data/Valid_Preprocessing.csv').reset_index(drop=True)\n",
        "Test=pd.read_csv('data/Test_Preprocessing.csv').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjliEKeAhO4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=BATCH_SIZE, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim, self.n_channels))\n",
        "        y = np.zeros((self.batch_size,self.n_classes), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            try:\n",
        "              temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              X[i,0:temp.shape[0],:] =temp \n",
        "              del temp\n",
        "            except:\n",
        "              print('Faile to load the data: BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "            # Store sample\n",
        "            # Store class\n",
        "            y[i,:] = np.array(list_IDs_temp.iloc[i,0:12])\n",
        "        Y=[]\n",
        "        for i in range(self.n_classes):\n",
        "          Y+=[y[:,i].reshape((self.batch_size,))]\n",
        "        return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ijHEnaK7opB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_generator = DataGenerator(Train,'Train')\n",
        "validation_generator = DataGenerator(Valid,'Valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBl5lHEfSGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict={}\n",
        "for i in range(N_CLASS):\n",
        "  ratioTrue=np.sum(Train.iloc[:,i])/len(Train)\n",
        "  classWeight_Dict['output'+str(i+1)]={0:1+1/((1-ratioTrue)/(ratioTrue)+1),1:1+(1-ratioTrue)/(ratioTrue)/((1-ratioTrue)/(ratioTrue)+1)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8C5_nNdl9Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict['output4'][1]+=1\n",
        "classWeight_Dict['output4'][0]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaoPIhG5PE0e",
        "colab_type": "code",
        "outputId": "c853a810-77e1-4967-b4e7-c2ef54aae1e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "classWeight_Dict"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output1': {0: 1.2345571818407344, 1: 1.7654428181592656},\n",
              " 'output10': {0: 1.0336144877201687, 1: 1.9663855122798313},\n",
              " 'output11': {0: 1.0100471347060282, 1: 1.9899528652939718},\n",
              " 'output12': {0: 1.0018605805011163, 1: 1.9981394194988837},\n",
              " 'output2': {0: 1.0604068469362442, 1: 1.9395931530637558},\n",
              " 'output3': {0: 1.074423220044654, 1: 1.925576779955346},\n",
              " 'output4': {0: 2.247085090548251, 1: 2.752914909451749},\n",
              " 'output5': {0: 1.0875713222525427, 1: 1.912428677747457},\n",
              " 'output6': {0: 1.1071694368643017, 1: 1.8928305631356983},\n",
              " 'output7': {0: 1.3979161498387498, 1: 1.6020838501612502},\n",
              " 'output8': {0: 1.1070453981642272, 1: 1.8929546018357728},\n",
              " 'output9': {0: 1.076779955346068, 1: 1.923220044653932}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2mz_N6c7mEx",
        "colab_type": "text"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytjcvIOnMiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_crossentropy(y_true, y_pred, weights,from_logits=False,label_smoothing=0):\n",
        "\n",
        "    y_pred = ops.convert_to_tensor(y_pred)\n",
        "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
        "    label_smoothing = ops.convert_to_tensor(label_smoothing, dtype=K.floatx())\n",
        "    def _smooth_labels():\n",
        "      return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
        "    y_true = smart_cond.smart_cond(label_smoothing,_smooth_labels, lambda: y_true)\n",
        "    \n",
        "    mask0 = tf.subtract(tf.constant(1.0, dtype=K.floatx()),y_true)\n",
        "    mask0=tf.math.scalar_mul(tf.constant(weights[0], dtype=K.floatx()),mask0)\n",
        "    mask1 =tf.math.scalar_mul(tf.constant(weights[1], dtype=K.floatx()),y_true)\n",
        "    mask=tf.math.add(mask0,mask1)\n",
        "\n",
        "    return K.mean(tf.math.multiply(K.binary_crossentropy(y_true, y_pred, from_logits=from_logits),mask), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKQSOUM5saC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    inputs = Input(shape=(MAX_LEN,N_CHANNELS))\n",
        "    x = SpatialDropout1D(0.2)(inputs)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "\n",
        "    hidden = concatenate([\n",
        "        GlobalMaxPooling1D()(x),\n",
        "        GlobalAveragePooling1D()(x),\n",
        "    ])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    RESULT=[]\n",
        "    for i in range(N_CLASS):\n",
        "      RESULT+=[Dense(1, activation='sigmoid',name='output'+str(i+1))(hidden)]\n",
        "    LOSS={}\n",
        "    for i in  range(N_CLASS):\n",
        "      LOSS['output'+str(i+1)]=partial(binary_crossentropy, weights=classWeight_Dict['output'+str(i+1)])\n",
        "      LOSS['output'+str(i+1)].__name__ = 'loss'+str(i+1)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=RESULT)\n",
        "    model.compile(loss=LOSS, optimizer='adam',metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N37opYym6CCC",
        "colab_type": "code",
        "outputId": "455352ad-f394-4811-c360-3af73a7a7628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1259, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 1259, 768)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 1259, 128)    426496      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1259, 128)    98816       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          65792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256)          0           concatenate[0][0]                \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           add[0][0]                        \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 659,980\n",
            "Trainable params: 659,980\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sb5GQmKeI_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback=ReduceLROnPlateau(patience=1,min_lr=0.00001,factor=0.3)\n",
        "Name='BERT/LSTM_addPenalty_64_lr.h5'\n",
        "checkpointer = ModelCheckpoint(filepath=Name, verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4To3UbV67kft",
        "colab_type": "code",
        "outputId": "814c16cf-3e03-4c0a-a040-1ecc20b191d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=training_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpointer,callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-d8713d19c50f>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Faile to load the data: BERT/vector/Train_123379_12798.npy\n",
            "Epoch 1/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 5.2986 - output1_loss: 0.5565 - output2_loss: 0.3381 - output3_loss: 0.4177 - output4_loss: 1.3617 - output5_loss: 0.4529 - output6_loss: 0.4783 - output7_loss: 0.5956 - output8_loss: 0.4166 - output9_loss: 0.4090 - output10_loss: 0.1453 - output11_loss: 0.0915 - output12_loss: 0.0355 - output1_binary_accuracy: 0.8186 - output2_binary_accuracy: 0.9360 - output3_binary_accuracy: 0.9241 - output4_binary_accuracy: 0.7522 - output5_binary_accuracy: 0.9094 - output6_binary_accuracy: 0.8909 - output7_binary_accuracy: 0.8225 - output8_binary_accuracy: 0.8947 - output9_binary_accuracy: 0.9219 - output10_binary_accuracy: 0.9622 - output11_binary_accuracy: 0.9856 - output12_binary_accuracy: 0.9945 \n",
            "Epoch 00001: val_loss improved from inf to 4.19736, saving model to BERT/LSTM_addPenalty_64_lr.h5\n",
            "251/251 [==============================] - 3985s 16s/step - loss: 5.2986 - output1_loss: 0.5565 - output2_loss: 0.3381 - output3_loss: 0.4177 - output4_loss: 1.3617 - output5_loss: 0.4529 - output6_loss: 0.4783 - output7_loss: 0.5956 - output8_loss: 0.4166 - output9_loss: 0.4090 - output10_loss: 0.1453 - output11_loss: 0.0915 - output12_loss: 0.0355 - output1_binary_accuracy: 0.8186 - output2_binary_accuracy: 0.9360 - output3_binary_accuracy: 0.9241 - output4_binary_accuracy: 0.7522 - output5_binary_accuracy: 0.9094 - output6_binary_accuracy: 0.8909 - output7_binary_accuracy: 0.8225 - output8_binary_accuracy: 0.8947 - output9_binary_accuracy: 0.9219 - output10_binary_accuracy: 0.9622 - output11_binary_accuracy: 0.9856 - output12_binary_accuracy: 0.9945 - val_loss: 4.1974 - val_output1_loss: 0.3288 - val_output2_loss: 0.2946 - val_output3_loss: 0.3619 - val_output4_loss: 1.2416 - val_output5_loss: 0.3874 - val_output6_loss: 0.3764 - val_output7_loss: 0.4295 - val_output8_loss: 0.2867 - val_output9_loss: 0.3070 - val_output10_loss: 0.1265 - val_output11_loss: 0.0520 - val_output12_loss: 0.0050 - val_output1_binary_accuracy: 0.9141 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9248 - val_output4_binary_accuracy: 0.7881 - val_output5_binary_accuracy: 0.9189 - val_output6_binary_accuracy: 0.9131 - val_output7_binary_accuracy: 0.8916 - val_output8_binary_accuracy: 0.9092 - val_output9_binary_accuracy: 0.9326 - val_output10_binary_accuracy: 0.9619 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 4.2655 - output1_loss: 0.3520 - output2_loss: 0.3019 - output3_loss: 0.3605 - output4_loss: 1.2278 - output5_loss: 0.3693 - output6_loss: 0.3563 - output7_loss: 0.4319 - output8_loss: 0.3303 - output9_loss: 0.3443 - output10_loss: 0.0959 - output11_loss: 0.0719 - output12_loss: 0.0235 - output1_binary_accuracy: 0.8975 - output2_binary_accuracy: 0.9392 - output3_binary_accuracy: 0.9172 - output4_binary_accuracy: 0.7749 - output5_binary_accuracy: 0.9115 - output6_binary_accuracy: 0.9161 - output7_binary_accuracy: 0.8870 - output8_binary_accuracy: 0.9101 - output9_binary_accuracy: 0.9194 - output10_binary_accuracy: 0.9706 - output11_binary_accuracy: 0.9900 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00002: val_loss improved from 4.19736 to 3.83350, saving model to BERT/LSTM_addPenalty_64_lr.h5\n",
            "251/251 [==============================] - 99s 395ms/step - loss: 4.2655 - output1_loss: 0.3520 - output2_loss: 0.3019 - output3_loss: 0.3605 - output4_loss: 1.2278 - output5_loss: 0.3693 - output6_loss: 0.3563 - output7_loss: 0.4319 - output8_loss: 0.3303 - output9_loss: 0.3443 - output10_loss: 0.0959 - output11_loss: 0.0719 - output12_loss: 0.0235 - output1_binary_accuracy: 0.8975 - output2_binary_accuracy: 0.9392 - output3_binary_accuracy: 0.9172 - output4_binary_accuracy: 0.7749 - output5_binary_accuracy: 0.9115 - output6_binary_accuracy: 0.9161 - output7_binary_accuracy: 0.8870 - output8_binary_accuracy: 0.9101 - output9_binary_accuracy: 0.9194 - output10_binary_accuracy: 0.9706 - output11_binary_accuracy: 0.9900 - output12_binary_accuracy: 0.9981 - val_loss: 3.8335 - val_output1_loss: 0.2874 - val_output2_loss: 0.2831 - val_output3_loss: 0.3299 - val_output4_loss: 1.2043 - val_output5_loss: 0.3478 - val_output6_loss: 0.3100 - val_output7_loss: 0.3857 - val_output8_loss: 0.2569 - val_output9_loss: 0.2772 - val_output10_loss: 0.0982 - val_output11_loss: 0.0493 - val_output12_loss: 0.0036 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.7881 - val_output5_binary_accuracy: 0.9248 - val_output6_binary_accuracy: 0.9238 - val_output7_binary_accuracy: 0.9014 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9326 - val_output10_binary_accuracy: 0.9727 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.9213 - output1_loss: 0.2892 - output2_loss: 0.2716 - output3_loss: 0.3347 - output4_loss: 1.1796 - output5_loss: 0.3484 - output6_loss: 0.3271 - output7_loss: 0.3823 - output8_loss: 0.2983 - output9_loss: 0.3193 - output10_loss: 0.0820 - output11_loss: 0.0679 - output12_loss: 0.0210 - output1_binary_accuracy: 0.9203 - output2_binary_accuracy: 0.9422 - output3_binary_accuracy: 0.9146 - output4_binary_accuracy: 0.7922 - output5_binary_accuracy: 0.9138 - output6_binary_accuracy: 0.9209 - output7_binary_accuracy: 0.9066 - output8_binary_accuracy: 0.9187 - output9_binary_accuracy: 0.9147 - output10_binary_accuracy: 0.9756 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00003: val_loss improved from 3.83350 to 3.73608, saving model to BERT/LSTM_addPenalty_64_lr.h5\n",
            "251/251 [==============================] - 86s 341ms/step - loss: 3.9213 - output1_loss: 0.2892 - output2_loss: 0.2716 - output3_loss: 0.3347 - output4_loss: 1.1796 - output5_loss: 0.3484 - output6_loss: 0.3271 - output7_loss: 0.3823 - output8_loss: 0.2983 - output9_loss: 0.3193 - output10_loss: 0.0820 - output11_loss: 0.0679 - output12_loss: 0.0210 - output1_binary_accuracy: 0.9203 - output2_binary_accuracy: 0.9422 - output3_binary_accuracy: 0.9146 - output4_binary_accuracy: 0.7922 - output5_binary_accuracy: 0.9138 - output6_binary_accuracy: 0.9209 - output7_binary_accuracy: 0.9066 - output8_binary_accuracy: 0.9187 - output9_binary_accuracy: 0.9147 - output10_binary_accuracy: 0.9756 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981 - val_loss: 3.7361 - val_output1_loss: 0.2578 - val_output2_loss: 0.2581 - val_output3_loss: 0.3567 - val_output4_loss: 1.1777 - val_output5_loss: 0.3517 - val_output6_loss: 0.3233 - val_output7_loss: 0.3716 - val_output8_loss: 0.2318 - val_output9_loss: 0.2680 - val_output10_loss: 0.0907 - val_output11_loss: 0.0434 - val_output12_loss: 0.0053 - val_output1_binary_accuracy: 0.9150 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9268 - val_output4_binary_accuracy: 0.7939 - val_output5_binary_accuracy: 0.9141 - val_output6_binary_accuracy: 0.9199 - val_output7_binary_accuracy: 0.9004 - val_output8_binary_accuracy: 0.9336 - val_output9_binary_accuracy: 0.9326 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 4/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.7000 - output1_loss: 0.2585 - output2_loss: 0.2541 - output3_loss: 0.3268 - output4_loss: 1.1341 - output5_loss: 0.3340 - output6_loss: 0.3104 - output7_loss: 0.3487 - output8_loss: 0.2798 - output9_loss: 0.2995 - output10_loss: 0.0755 - output11_loss: 0.0599 - output12_loss: 0.0187 - output1_binary_accuracy: 0.9319 - output2_binary_accuracy: 0.9491 - output3_binary_accuracy: 0.9192 - output4_binary_accuracy: 0.8020 - output5_binary_accuracy: 0.9141 - output6_binary_accuracy: 0.9260 - output7_binary_accuracy: 0.9137 - output8_binary_accuracy: 0.9250 - output9_binary_accuracy: 0.9160 - output10_binary_accuracy: 0.9780 - output11_binary_accuracy: 0.9902 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00004: val_loss improved from 3.73608 to 3.68064, saving model to BERT/LSTM_addPenalty_64_lr.h5\n",
            "251/251 [==============================] - 85s 340ms/step - loss: 3.7000 - output1_loss: 0.2585 - output2_loss: 0.2541 - output3_loss: 0.3268 - output4_loss: 1.1341 - output5_loss: 0.3340 - output6_loss: 0.3104 - output7_loss: 0.3487 - output8_loss: 0.2798 - output9_loss: 0.2995 - output10_loss: 0.0755 - output11_loss: 0.0599 - output12_loss: 0.0187 - output1_binary_accuracy: 0.9319 - output2_binary_accuracy: 0.9491 - output3_binary_accuracy: 0.9192 - output4_binary_accuracy: 0.8020 - output5_binary_accuracy: 0.9141 - output6_binary_accuracy: 0.9260 - output7_binary_accuracy: 0.9137 - output8_binary_accuracy: 0.9250 - output9_binary_accuracy: 0.9160 - output10_binary_accuracy: 0.9780 - output11_binary_accuracy: 0.9902 - output12_binary_accuracy: 0.9981 - val_loss: 3.6806 - val_output1_loss: 0.2418 - val_output2_loss: 0.2612 - val_output3_loss: 0.3480 - val_output4_loss: 1.1786 - val_output5_loss: 0.3365 - val_output6_loss: 0.3078 - val_output7_loss: 0.3744 - val_output8_loss: 0.2408 - val_output9_loss: 0.2574 - val_output10_loss: 0.0877 - val_output11_loss: 0.0445 - val_output12_loss: 0.0018 - val_output1_binary_accuracy: 0.9268 - val_output2_binary_accuracy: 0.9512 - val_output3_binary_accuracy: 0.9258 - val_output4_binary_accuracy: 0.7998 - val_output5_binary_accuracy: 0.9277 - val_output6_binary_accuracy: 0.9268 - val_output7_binary_accuracy: 0.8994 - val_output8_binary_accuracy: 0.9277 - val_output9_binary_accuracy: 0.9355 - val_output10_binary_accuracy: 0.9717 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.5056 - output1_loss: 0.2243 - output2_loss: 0.2378 - output3_loss: 0.3087 - output4_loss: 1.0917 - output5_loss: 0.3247 - output6_loss: 0.2991 - output7_loss: 0.3342 - output8_loss: 0.2604 - output9_loss: 0.2781 - output10_loss: 0.0734 - output11_loss: 0.0550 - output12_loss: 0.0181 - output1_binary_accuracy: 0.9432 - output2_binary_accuracy: 0.9491 - output3_binary_accuracy: 0.9213 - output4_binary_accuracy: 0.8132 - output5_binary_accuracy: 0.9167 - output6_binary_accuracy: 0.9277 - output7_binary_accuracy: 0.9171 - output8_binary_accuracy: 0.9292 - output9_binary_accuracy: 0.9203 - output10_binary_accuracy: 0.9771 - output11_binary_accuracy: 0.9908 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00005: val_loss did not improve from 3.68064\n",
            "251/251 [==============================] - 84s 336ms/step - loss: 3.5056 - output1_loss: 0.2243 - output2_loss: 0.2378 - output3_loss: 0.3087 - output4_loss: 1.0917 - output5_loss: 0.3247 - output6_loss: 0.2991 - output7_loss: 0.3342 - output8_loss: 0.2604 - output9_loss: 0.2781 - output10_loss: 0.0734 - output11_loss: 0.0550 - output12_loss: 0.0181 - output1_binary_accuracy: 0.9432 - output2_binary_accuracy: 0.9491 - output3_binary_accuracy: 0.9213 - output4_binary_accuracy: 0.8132 - output5_binary_accuracy: 0.9167 - output6_binary_accuracy: 0.9277 - output7_binary_accuracy: 0.9171 - output8_binary_accuracy: 0.9292 - output9_binary_accuracy: 0.9203 - output10_binary_accuracy: 0.9771 - output11_binary_accuracy: 0.9908 - output12_binary_accuracy: 0.9981 - val_loss: 3.7574 - val_output1_loss: 0.2454 - val_output2_loss: 0.2528 - val_output3_loss: 0.3402 - val_output4_loss: 1.2353 - val_output5_loss: 0.3433 - val_output6_loss: 0.2903 - val_output7_loss: 0.3915 - val_output8_loss: 0.2797 - val_output9_loss: 0.2467 - val_output10_loss: 0.0878 - val_output11_loss: 0.0393 - val_output12_loss: 0.0052 - val_output1_binary_accuracy: 0.9316 - val_output2_binary_accuracy: 0.9551 - val_output3_binary_accuracy: 0.9209 - val_output4_binary_accuracy: 0.7891 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.8965 - val_output8_binary_accuracy: 0.9043 - val_output9_binary_accuracy: 0.9404 - val_output10_binary_accuracy: 0.9717 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.1519 - output1_loss: 0.1808 - output2_loss: 0.2104 - output3_loss: 0.2900 - output4_loss: 0.9923 - output5_loss: 0.2963 - output6_loss: 0.2758 - output7_loss: 0.2887 - output8_loss: 0.2367 - output9_loss: 0.2529 - output10_loss: 0.0635 - output11_loss: 0.0484 - output12_loss: 0.0160 - output1_binary_accuracy: 0.9552 - output2_binary_accuracy: 0.9549 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8374 - output5_binary_accuracy: 0.9247 - output6_binary_accuracy: 0.9346 - output7_binary_accuracy: 0.9309 - output8_binary_accuracy: 0.9353 - output9_binary_accuracy: 0.9292 - output10_binary_accuracy: 0.9798 - output11_binary_accuracy: 0.9913 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00006: val_loss improved from 3.68064 to 3.58239, saving model to BERT/LSTM_addPenalty_64_lr.h5\n",
            "251/251 [==============================] - 85s 339ms/step - loss: 3.1519 - output1_loss: 0.1808 - output2_loss: 0.2104 - output3_loss: 0.2900 - output4_loss: 0.9923 - output5_loss: 0.2963 - output6_loss: 0.2758 - output7_loss: 0.2887 - output8_loss: 0.2367 - output9_loss: 0.2529 - output10_loss: 0.0635 - output11_loss: 0.0484 - output12_loss: 0.0160 - output1_binary_accuracy: 0.9552 - output2_binary_accuracy: 0.9549 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8374 - output5_binary_accuracy: 0.9247 - output6_binary_accuracy: 0.9346 - output7_binary_accuracy: 0.9309 - output8_binary_accuracy: 0.9353 - output9_binary_accuracy: 0.9292 - output10_binary_accuracy: 0.9798 - output11_binary_accuracy: 0.9913 - output12_binary_accuracy: 0.9981 - val_loss: 3.5824 - val_output1_loss: 0.2364 - val_output2_loss: 0.2507 - val_output3_loss: 0.3493 - val_output4_loss: 1.1513 - val_output5_loss: 0.3390 - val_output6_loss: 0.2950 - val_output7_loss: 0.3563 - val_output8_loss: 0.2447 - val_output9_loss: 0.2353 - val_output10_loss: 0.0792 - val_output11_loss: 0.0410 - val_output12_loss: 0.0041 - val_output1_binary_accuracy: 0.9297 - val_output2_binary_accuracy: 0.9492 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.8145 - val_output5_binary_accuracy: 0.9199 - val_output6_binary_accuracy: 0.9297 - val_output7_binary_accuracy: 0.9102 - val_output8_binary_accuracy: 0.9209 - val_output9_binary_accuracy: 0.9248 - val_output10_binary_accuracy: 0.9756 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 3.0000e-04\n",
            "Epoch 7/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.9881 - output1_loss: 0.1620 - output2_loss: 0.2037 - output3_loss: 0.2853 - output4_loss: 0.9426 - output5_loss: 0.2858 - output6_loss: 0.2631 - output7_loss: 0.2703 - output8_loss: 0.2242 - output9_loss: 0.2332 - output10_loss: 0.0573 - output11_loss: 0.0451 - output12_loss: 0.0156 - output1_binary_accuracy: 0.9600 - output2_binary_accuracy: 0.9561 - output3_binary_accuracy: 0.9231 - output4_binary_accuracy: 0.8414 - output5_binary_accuracy: 0.9267 - output6_binary_accuracy: 0.9384 - output7_binary_accuracy: 0.9360 - output8_binary_accuracy: 0.9389 - output9_binary_accuracy: 0.9333 - output10_binary_accuracy: 0.9823 - output11_binary_accuracy: 0.9913 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00007: val_loss did not improve from 3.58239\n",
            "251/251 [==============================] - 85s 338ms/step - loss: 2.9881 - output1_loss: 0.1620 - output2_loss: 0.2037 - output3_loss: 0.2853 - output4_loss: 0.9426 - output5_loss: 0.2858 - output6_loss: 0.2631 - output7_loss: 0.2703 - output8_loss: 0.2242 - output9_loss: 0.2332 - output10_loss: 0.0573 - output11_loss: 0.0451 - output12_loss: 0.0156 - output1_binary_accuracy: 0.9600 - output2_binary_accuracy: 0.9561 - output3_binary_accuracy: 0.9231 - output4_binary_accuracy: 0.8414 - output5_binary_accuracy: 0.9267 - output6_binary_accuracy: 0.9384 - output7_binary_accuracy: 0.9360 - output8_binary_accuracy: 0.9389 - output9_binary_accuracy: 0.9333 - output10_binary_accuracy: 0.9823 - output11_binary_accuracy: 0.9913 - output12_binary_accuracy: 0.9981 - val_loss: 3.6139 - val_output1_loss: 0.2365 - val_output2_loss: 0.2651 - val_output3_loss: 0.3519 - val_output4_loss: 1.1539 - val_output5_loss: 0.3420 - val_output6_loss: 0.3038 - val_output7_loss: 0.3628 - val_output8_loss: 0.2447 - val_output9_loss: 0.2267 - val_output10_loss: 0.0799 - val_output11_loss: 0.0427 - val_output12_loss: 0.0037 - val_output1_binary_accuracy: 0.9336 - val_output2_binary_accuracy: 0.9473 - val_output3_binary_accuracy: 0.8994 - val_output4_binary_accuracy: 0.8047 - val_output5_binary_accuracy: 0.9209 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9102 - val_output8_binary_accuracy: 0.9268 - val_output9_binary_accuracy: 0.9346 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 3.0000e-04\n",
            "Epoch 8/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.8136 - output1_loss: 0.1400 - output2_loss: 0.1904 - output3_loss: 0.2797 - output4_loss: 0.8919 - output5_loss: 0.2731 - output6_loss: 0.2551 - output7_loss: 0.2507 - output8_loss: 0.2090 - output9_loss: 0.2195 - output10_loss: 0.0511 - output11_loss: 0.0388 - output12_loss: 0.0143 - output1_binary_accuracy: 0.9678 - output2_binary_accuracy: 0.9583 - output3_binary_accuracy: 0.9181 - output4_binary_accuracy: 0.8569 - output5_binary_accuracy: 0.9288 - output6_binary_accuracy: 0.9417 - output7_binary_accuracy: 0.9400 - output8_binary_accuracy: 0.9427 - output9_binary_accuracy: 0.9399 - output10_binary_accuracy: 0.9843 - output11_binary_accuracy: 0.9930 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00008: val_loss improved from 3.58239 to 3.54951, saving model to BERT/LSTM_addPenalty_64_lr.h5\n",
            "251/251 [==============================] - 85s 341ms/step - loss: 2.8136 - output1_loss: 0.1400 - output2_loss: 0.1904 - output3_loss: 0.2797 - output4_loss: 0.8919 - output5_loss: 0.2731 - output6_loss: 0.2551 - output7_loss: 0.2507 - output8_loss: 0.2090 - output9_loss: 0.2195 - output10_loss: 0.0511 - output11_loss: 0.0388 - output12_loss: 0.0143 - output1_binary_accuracy: 0.9678 - output2_binary_accuracy: 0.9583 - output3_binary_accuracy: 0.9181 - output4_binary_accuracy: 0.8569 - output5_binary_accuracy: 0.9288 - output6_binary_accuracy: 0.9417 - output7_binary_accuracy: 0.9400 - output8_binary_accuracy: 0.9427 - output9_binary_accuracy: 0.9399 - output10_binary_accuracy: 0.9843 - output11_binary_accuracy: 0.9930 - output12_binary_accuracy: 0.9981 - val_loss: 3.5495 - val_output1_loss: 0.2351 - val_output2_loss: 0.2602 - val_output3_loss: 0.3436 - val_output4_loss: 1.1464 - val_output5_loss: 0.3368 - val_output6_loss: 0.2919 - val_output7_loss: 0.3542 - val_output8_loss: 0.2311 - val_output9_loss: 0.2260 - val_output10_loss: 0.0785 - val_output11_loss: 0.0420 - val_output12_loss: 0.0037 - val_output1_binary_accuracy: 0.9326 - val_output2_binary_accuracy: 0.9434 - val_output3_binary_accuracy: 0.9209 - val_output4_binary_accuracy: 0.8057 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9346 - val_output7_binary_accuracy: 0.9150 - val_output8_binary_accuracy: 0.9346 - val_output9_binary_accuracy: 0.9355 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 9.0000e-05\n",
            "Epoch 9/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7783 - output1_loss: 0.1386 - output2_loss: 0.1904 - output3_loss: 0.2754 - output4_loss: 0.8718 - output5_loss: 0.2713 - output6_loss: 0.2517 - output7_loss: 0.2515 - output8_loss: 0.2056 - output9_loss: 0.2180 - output10_loss: 0.0510 - output11_loss: 0.0383 - output12_loss: 0.0147 - output1_binary_accuracy: 0.9681 - output2_binary_accuracy: 0.9574 - output3_binary_accuracy: 0.9232 - output4_binary_accuracy: 0.8569 - output5_binary_accuracy: 0.9294 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9409 - output8_binary_accuracy: 0.9440 - output9_binary_accuracy: 0.9377 - output10_binary_accuracy: 0.9832 - output11_binary_accuracy: 0.9924 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00009: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 338ms/step - loss: 2.7783 - output1_loss: 0.1386 - output2_loss: 0.1904 - output3_loss: 0.2754 - output4_loss: 0.8718 - output5_loss: 0.2713 - output6_loss: 0.2517 - output7_loss: 0.2515 - output8_loss: 0.2056 - output9_loss: 0.2180 - output10_loss: 0.0510 - output11_loss: 0.0383 - output12_loss: 0.0147 - output1_binary_accuracy: 0.9681 - output2_binary_accuracy: 0.9574 - output3_binary_accuracy: 0.9232 - output4_binary_accuracy: 0.8569 - output5_binary_accuracy: 0.9294 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9409 - output8_binary_accuracy: 0.9440 - output9_binary_accuracy: 0.9377 - output10_binary_accuracy: 0.9832 - output11_binary_accuracy: 0.9924 - output12_binary_accuracy: 0.9981 - val_loss: 3.5844 - val_output1_loss: 0.2455 - val_output2_loss: 0.2622 - val_output3_loss: 0.3393 - val_output4_loss: 1.1570 - val_output5_loss: 0.3349 - val_output6_loss: 0.2919 - val_output7_loss: 0.3734 - val_output8_loss: 0.2313 - val_output9_loss: 0.2252 - val_output10_loss: 0.0779 - val_output11_loss: 0.0417 - val_output12_loss: 0.0040 - val_output1_binary_accuracy: 0.9355 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7988 - val_output5_binary_accuracy: 0.9219 - val_output6_binary_accuracy: 0.9355 - val_output7_binary_accuracy: 0.9043 - val_output8_binary_accuracy: 0.9375 - val_output9_binary_accuracy: 0.9287 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 9.0000e-05\n",
            "Epoch 10/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6985 - output1_loss: 0.1311 - output2_loss: 0.1818 - output3_loss: 0.2727 - output4_loss: 0.8508 - output5_loss: 0.2656 - output6_loss: 0.2453 - output7_loss: 0.2409 - output8_loss: 0.2009 - output9_loss: 0.2079 - output10_loss: 0.0502 - output11_loss: 0.0369 - output12_loss: 0.0143 - output1_binary_accuracy: 0.9692 - output2_binary_accuracy: 0.9588 - output3_binary_accuracy: 0.9238 - output4_binary_accuracy: 0.8606 - output5_binary_accuracy: 0.9289 - output6_binary_accuracy: 0.9417 - output7_binary_accuracy: 0.9421 - output8_binary_accuracy: 0.9458 - output9_binary_accuracy: 0.9426 - output10_binary_accuracy: 0.9837 - output11_binary_accuracy: 0.9929 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00010: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 338ms/step - loss: 2.6985 - output1_loss: 0.1311 - output2_loss: 0.1818 - output3_loss: 0.2727 - output4_loss: 0.8508 - output5_loss: 0.2656 - output6_loss: 0.2453 - output7_loss: 0.2409 - output8_loss: 0.2009 - output9_loss: 0.2079 - output10_loss: 0.0502 - output11_loss: 0.0369 - output12_loss: 0.0143 - output1_binary_accuracy: 0.9692 - output2_binary_accuracy: 0.9588 - output3_binary_accuracy: 0.9238 - output4_binary_accuracy: 0.8606 - output5_binary_accuracy: 0.9289 - output6_binary_accuracy: 0.9417 - output7_binary_accuracy: 0.9421 - output8_binary_accuracy: 0.9458 - output9_binary_accuracy: 0.9426 - output10_binary_accuracy: 0.9837 - output11_binary_accuracy: 0.9929 - output12_binary_accuracy: 0.9981 - val_loss: 3.5900 - val_output1_loss: 0.2408 - val_output2_loss: 0.2630 - val_output3_loss: 0.3357 - val_output4_loss: 1.1537 - val_output5_loss: 0.3312 - val_output6_loss: 0.2944 - val_output7_loss: 0.3739 - val_output8_loss: 0.2456 - val_output9_loss: 0.2274 - val_output10_loss: 0.0810 - val_output11_loss: 0.0399 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9326 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.8037 - val_output5_binary_accuracy: 0.9248 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9258 - val_output9_binary_accuracy: 0.9316 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 2.7000e-05\n",
            "Epoch 11/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6657 - output1_loss: 0.1242 - output2_loss: 0.1810 - output3_loss: 0.2703 - output4_loss: 0.8407 - output5_loss: 0.2609 - output6_loss: 0.2476 - output7_loss: 0.2386 - output8_loss: 0.2001 - output9_loss: 0.2056 - output10_loss: 0.0478 - output11_loss: 0.0345 - output12_loss: 0.0142 - output1_binary_accuracy: 0.9699 - output2_binary_accuracy: 0.9600 - output3_binary_accuracy: 0.9259 - output4_binary_accuracy: 0.8642 - output5_binary_accuracy: 0.9323 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9426 - output8_binary_accuracy: 0.9468 - output9_binary_accuracy: 0.9411 - output10_binary_accuracy: 0.9857 - output11_binary_accuracy: 0.9932 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00011: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 337ms/step - loss: 2.6657 - output1_loss: 0.1242 - output2_loss: 0.1810 - output3_loss: 0.2703 - output4_loss: 0.8407 - output5_loss: 0.2609 - output6_loss: 0.2476 - output7_loss: 0.2386 - output8_loss: 0.2001 - output9_loss: 0.2056 - output10_loss: 0.0478 - output11_loss: 0.0345 - output12_loss: 0.0142 - output1_binary_accuracy: 0.9699 - output2_binary_accuracy: 0.9600 - output3_binary_accuracy: 0.9259 - output4_binary_accuracy: 0.8642 - output5_binary_accuracy: 0.9323 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9426 - output8_binary_accuracy: 0.9468 - output9_binary_accuracy: 0.9411 - output10_binary_accuracy: 0.9857 - output11_binary_accuracy: 0.9932 - output12_binary_accuracy: 0.9981 - val_loss: 3.6029 - val_output1_loss: 0.2436 - val_output2_loss: 0.2630 - val_output3_loss: 0.3466 - val_output4_loss: 1.1627 - val_output5_loss: 0.3355 - val_output6_loss: 0.2945 - val_output7_loss: 0.3737 - val_output8_loss: 0.2329 - val_output9_loss: 0.2259 - val_output10_loss: 0.0806 - val_output11_loss: 0.0406 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9326 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9170 - val_output4_binary_accuracy: 0.7988 - val_output5_binary_accuracy: 0.9268 - val_output6_binary_accuracy: 0.9365 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9297 - val_output9_binary_accuracy: 0.9316 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 12/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6748 - output1_loss: 0.1295 - output2_loss: 0.1795 - output3_loss: 0.2697 - output4_loss: 0.8444 - output5_loss: 0.2621 - output6_loss: 0.2469 - output7_loss: 0.2401 - output8_loss: 0.1966 - output9_loss: 0.2057 - output10_loss: 0.0493 - output11_loss: 0.0364 - output12_loss: 0.0144 - output1_binary_accuracy: 0.9678 - output2_binary_accuracy: 0.9598 - output3_binary_accuracy: 0.9239 - output4_binary_accuracy: 0.8654 - output5_binary_accuracy: 0.9326 - output6_binary_accuracy: 0.9411 - output7_binary_accuracy: 0.9432 - output8_binary_accuracy: 0.9463 - output9_binary_accuracy: 0.9424 - output10_binary_accuracy: 0.9842 - output11_binary_accuracy: 0.9927 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00012: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 337ms/step - loss: 2.6748 - output1_loss: 0.1295 - output2_loss: 0.1795 - output3_loss: 0.2697 - output4_loss: 0.8444 - output5_loss: 0.2621 - output6_loss: 0.2469 - output7_loss: 0.2401 - output8_loss: 0.1966 - output9_loss: 0.2057 - output10_loss: 0.0493 - output11_loss: 0.0364 - output12_loss: 0.0144 - output1_binary_accuracy: 0.9678 - output2_binary_accuracy: 0.9598 - output3_binary_accuracy: 0.9239 - output4_binary_accuracy: 0.8654 - output5_binary_accuracy: 0.9326 - output6_binary_accuracy: 0.9411 - output7_binary_accuracy: 0.9432 - output8_binary_accuracy: 0.9463 - output9_binary_accuracy: 0.9424 - output10_binary_accuracy: 0.9842 - output11_binary_accuracy: 0.9927 - output12_binary_accuracy: 0.9981 - val_loss: 3.5984 - val_output1_loss: 0.2454 - val_output2_loss: 0.2639 - val_output3_loss: 0.3452 - val_output4_loss: 1.1473 - val_output5_loss: 0.3330 - val_output6_loss: 0.2950 - val_output7_loss: 0.3759 - val_output8_loss: 0.2409 - val_output9_loss: 0.2262 - val_output10_loss: 0.0815 - val_output11_loss: 0.0408 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9336 - val_output2_binary_accuracy: 0.9424 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.8037 - val_output5_binary_accuracy: 0.9248 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9053 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9297 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 13/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6467 - output1_loss: 0.1229 - output2_loss: 0.1794 - output3_loss: 0.2686 - output4_loss: 0.8332 - output5_loss: 0.2600 - output6_loss: 0.2466 - output7_loss: 0.2346 - output8_loss: 0.1981 - output9_loss: 0.2058 - output10_loss: 0.0490 - output11_loss: 0.0348 - output12_loss: 0.0135 - output1_binary_accuracy: 0.9732 - output2_binary_accuracy: 0.9590 - output3_binary_accuracy: 0.9260 - output4_binary_accuracy: 0.8647 - output5_binary_accuracy: 0.9323 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9453 - output8_binary_accuracy: 0.9482 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9842 - output11_binary_accuracy: 0.9938 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00013: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 84s 337ms/step - loss: 2.6467 - output1_loss: 0.1229 - output2_loss: 0.1794 - output3_loss: 0.2686 - output4_loss: 0.8332 - output5_loss: 0.2600 - output6_loss: 0.2466 - output7_loss: 0.2346 - output8_loss: 0.1981 - output9_loss: 0.2058 - output10_loss: 0.0490 - output11_loss: 0.0348 - output12_loss: 0.0135 - output1_binary_accuracy: 0.9732 - output2_binary_accuracy: 0.9590 - output3_binary_accuracy: 0.9260 - output4_binary_accuracy: 0.8647 - output5_binary_accuracy: 0.9323 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9453 - output8_binary_accuracy: 0.9482 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9842 - output11_binary_accuracy: 0.9938 - output12_binary_accuracy: 0.9981 - val_loss: 3.6189 - val_output1_loss: 0.2467 - val_output2_loss: 0.2635 - val_output3_loss: 0.3484 - val_output4_loss: 1.1594 - val_output5_loss: 0.3389 - val_output6_loss: 0.2954 - val_output7_loss: 0.3729 - val_output8_loss: 0.2403 - val_output9_loss: 0.2282 - val_output10_loss: 0.0813 - val_output11_loss: 0.0407 - val_output12_loss: 0.0033 - val_output1_binary_accuracy: 0.9297 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9160 - val_output4_binary_accuracy: 0.8018 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9287 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6511 - output1_loss: 0.1284 - output2_loss: 0.1773 - output3_loss: 0.2686 - output4_loss: 0.8325 - output5_loss: 0.2606 - output6_loss: 0.2445 - output7_loss: 0.2347 - output8_loss: 0.2001 - output9_loss: 0.2067 - output10_loss: 0.0483 - output11_loss: 0.0358 - output12_loss: 0.0137 - output1_binary_accuracy: 0.9695 - output2_binary_accuracy: 0.9605 - output3_binary_accuracy: 0.9259 - output4_binary_accuracy: 0.8655 - output5_binary_accuracy: 0.9316 - output6_binary_accuracy: 0.9421 - output7_binary_accuracy: 0.9442 - output8_binary_accuracy: 0.9462 - output9_binary_accuracy: 0.9407 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00014: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 337ms/step - loss: 2.6511 - output1_loss: 0.1284 - output2_loss: 0.1773 - output3_loss: 0.2686 - output4_loss: 0.8325 - output5_loss: 0.2606 - output6_loss: 0.2445 - output7_loss: 0.2347 - output8_loss: 0.2001 - output9_loss: 0.2067 - output10_loss: 0.0483 - output11_loss: 0.0358 - output12_loss: 0.0137 - output1_binary_accuracy: 0.9695 - output2_binary_accuracy: 0.9605 - output3_binary_accuracy: 0.9259 - output4_binary_accuracy: 0.8655 - output5_binary_accuracy: 0.9316 - output6_binary_accuracy: 0.9421 - output7_binary_accuracy: 0.9442 - output8_binary_accuracy: 0.9462 - output9_binary_accuracy: 0.9407 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981 - val_loss: 3.6232 - val_output1_loss: 0.2462 - val_output2_loss: 0.2645 - val_output3_loss: 0.3447 - val_output4_loss: 1.1684 - val_output5_loss: 0.3366 - val_output6_loss: 0.2956 - val_output7_loss: 0.3742 - val_output8_loss: 0.2400 - val_output9_loss: 0.2274 - val_output10_loss: 0.0814 - val_output11_loss: 0.0407 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9297 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7988 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9277 - val_output9_binary_accuracy: 0.9287 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6472 - output1_loss: 0.1235 - output2_loss: 0.1769 - output3_loss: 0.2718 - output4_loss: 0.8330 - output5_loss: 0.2610 - output6_loss: 0.2446 - output7_loss: 0.2382 - output8_loss: 0.1979 - output9_loss: 0.2047 - output10_loss: 0.0473 - output11_loss: 0.0339 - output12_loss: 0.0144 - output1_binary_accuracy: 0.9716 - output2_binary_accuracy: 0.9593 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8664 - output5_binary_accuracy: 0.9323 - output6_binary_accuracy: 0.9425 - output7_binary_accuracy: 0.9421 - output8_binary_accuracy: 0.9465 - output9_binary_accuracy: 0.9445 - output10_binary_accuracy: 0.9852 - output11_binary_accuracy: 0.9930 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00015: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 337ms/step - loss: 2.6472 - output1_loss: 0.1235 - output2_loss: 0.1769 - output3_loss: 0.2718 - output4_loss: 0.8330 - output5_loss: 0.2610 - output6_loss: 0.2446 - output7_loss: 0.2382 - output8_loss: 0.1979 - output9_loss: 0.2047 - output10_loss: 0.0473 - output11_loss: 0.0339 - output12_loss: 0.0144 - output1_binary_accuracy: 0.9716 - output2_binary_accuracy: 0.9593 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8664 - output5_binary_accuracy: 0.9323 - output6_binary_accuracy: 0.9425 - output7_binary_accuracy: 0.9421 - output8_binary_accuracy: 0.9465 - output9_binary_accuracy: 0.9445 - output10_binary_accuracy: 0.9852 - output11_binary_accuracy: 0.9930 - output12_binary_accuracy: 0.9981 - val_loss: 3.6118 - val_output1_loss: 0.2474 - val_output2_loss: 0.2605 - val_output3_loss: 0.3474 - val_output4_loss: 1.1633 - val_output5_loss: 0.3365 - val_output6_loss: 0.2959 - val_output7_loss: 0.3728 - val_output8_loss: 0.2387 - val_output9_loss: 0.2273 - val_output10_loss: 0.0815 - val_output11_loss: 0.0369 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9355 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.8008 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9277 - val_output9_binary_accuracy: 0.9268 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 16/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6490 - output1_loss: 0.1269 - output2_loss: 0.1830 - output3_loss: 0.2689 - output4_loss: 0.8356 - output5_loss: 0.2599 - output6_loss: 0.2439 - output7_loss: 0.2350 - output8_loss: 0.1966 - output9_loss: 0.2040 - output10_loss: 0.0474 - output11_loss: 0.0341 - output12_loss: 0.0137 - output1_binary_accuracy: 0.9686 - output2_binary_accuracy: 0.9582 - output3_binary_accuracy: 0.9269 - output4_binary_accuracy: 0.8628 - output5_binary_accuracy: 0.9334 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9457 - output8_binary_accuracy: 0.9491 - output9_binary_accuracy: 0.9422 - output10_binary_accuracy: 0.9851 - output11_binary_accuracy: 0.9924 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00016: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 337ms/step - loss: 2.6490 - output1_loss: 0.1269 - output2_loss: 0.1830 - output3_loss: 0.2689 - output4_loss: 0.8356 - output5_loss: 0.2599 - output6_loss: 0.2439 - output7_loss: 0.2350 - output8_loss: 0.1966 - output9_loss: 0.2040 - output10_loss: 0.0474 - output11_loss: 0.0341 - output12_loss: 0.0137 - output1_binary_accuracy: 0.9686 - output2_binary_accuracy: 0.9582 - output3_binary_accuracy: 0.9269 - output4_binary_accuracy: 0.8628 - output5_binary_accuracy: 0.9334 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9457 - output8_binary_accuracy: 0.9491 - output9_binary_accuracy: 0.9422 - output10_binary_accuracy: 0.9851 - output11_binary_accuracy: 0.9924 - output12_binary_accuracy: 0.9981 - val_loss: 3.6193 - val_output1_loss: 0.2445 - val_output2_loss: 0.2581 - val_output3_loss: 0.3415 - val_output4_loss: 1.1696 - val_output5_loss: 0.3389 - val_output6_loss: 0.2964 - val_output7_loss: 0.3755 - val_output8_loss: 0.2412 - val_output9_loss: 0.2279 - val_output10_loss: 0.0810 - val_output11_loss: 0.0413 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9355 - val_output2_binary_accuracy: 0.9424 - val_output3_binary_accuracy: 0.9170 - val_output4_binary_accuracy: 0.7969 - val_output5_binary_accuracy: 0.9229 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9277 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 17/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6354 - output1_loss: 0.1249 - output2_loss: 0.1790 - output3_loss: 0.2695 - output4_loss: 0.8238 - output5_loss: 0.2582 - output6_loss: 0.2431 - output7_loss: 0.2336 - output8_loss: 0.1989 - output9_loss: 0.2080 - output10_loss: 0.0482 - output11_loss: 0.0346 - output12_loss: 0.0137 - output1_binary_accuracy: 0.9725 - output2_binary_accuracy: 0.9598 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8670 - output5_binary_accuracy: 0.9316 - output6_binary_accuracy: 0.9426 - output7_binary_accuracy: 0.9466 - output8_binary_accuracy: 0.9487 - output9_binary_accuracy: 0.9396 - output10_binary_accuracy: 0.9844 - output11_binary_accuracy: 0.9935 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00017: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 338ms/step - loss: 2.6354 - output1_loss: 0.1249 - output2_loss: 0.1790 - output3_loss: 0.2695 - output4_loss: 0.8238 - output5_loss: 0.2582 - output6_loss: 0.2431 - output7_loss: 0.2336 - output8_loss: 0.1989 - output9_loss: 0.2080 - output10_loss: 0.0482 - output11_loss: 0.0346 - output12_loss: 0.0137 - output1_binary_accuracy: 0.9725 - output2_binary_accuracy: 0.9598 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8670 - output5_binary_accuracy: 0.9316 - output6_binary_accuracy: 0.9426 - output7_binary_accuracy: 0.9466 - output8_binary_accuracy: 0.9487 - output9_binary_accuracy: 0.9396 - output10_binary_accuracy: 0.9844 - output11_binary_accuracy: 0.9935 - output12_binary_accuracy: 0.9981 - val_loss: 3.6019 - val_output1_loss: 0.2473 - val_output2_loss: 0.2632 - val_output3_loss: 0.3413 - val_output4_loss: 1.1672 - val_output5_loss: 0.3341 - val_output6_loss: 0.2909 - val_output7_loss: 0.3701 - val_output8_loss: 0.2406 - val_output9_loss: 0.2213 - val_output10_loss: 0.0809 - val_output11_loss: 0.0414 - val_output12_loss: 0.0035 - val_output1_binary_accuracy: 0.9355 - val_output2_binary_accuracy: 0.9434 - val_output3_binary_accuracy: 0.9160 - val_output4_binary_accuracy: 0.7998 - val_output5_binary_accuracy: 0.9229 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9082 - val_output8_binary_accuracy: 0.9297 - val_output9_binary_accuracy: 0.9268 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 18/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6478 - output1_loss: 0.1274 - output2_loss: 0.1772 - output3_loss: 0.2686 - output4_loss: 0.8330 - output5_loss: 0.2591 - output6_loss: 0.2440 - output7_loss: 0.2353 - output8_loss: 0.1972 - output9_loss: 0.2100 - output10_loss: 0.0463 - output11_loss: 0.0352 - output12_loss: 0.0145 - output1_binary_accuracy: 0.9691 - output2_binary_accuracy: 0.9634 - output3_binary_accuracy: 0.9262 - output4_binary_accuracy: 0.8640 - output5_binary_accuracy: 0.9320 - output6_binary_accuracy: 0.9414 - output7_binary_accuracy: 0.9453 - output8_binary_accuracy: 0.9485 - output9_binary_accuracy: 0.9395 - output10_binary_accuracy: 0.9843 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00018: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 84s 336ms/step - loss: 2.6478 - output1_loss: 0.1274 - output2_loss: 0.1772 - output3_loss: 0.2686 - output4_loss: 0.8330 - output5_loss: 0.2591 - output6_loss: 0.2440 - output7_loss: 0.2353 - output8_loss: 0.1972 - output9_loss: 0.2100 - output10_loss: 0.0463 - output11_loss: 0.0352 - output12_loss: 0.0145 - output1_binary_accuracy: 0.9691 - output2_binary_accuracy: 0.9634 - output3_binary_accuracy: 0.9262 - output4_binary_accuracy: 0.8640 - output5_binary_accuracy: 0.9320 - output6_binary_accuracy: 0.9414 - output7_binary_accuracy: 0.9453 - output8_binary_accuracy: 0.9485 - output9_binary_accuracy: 0.9395 - output10_binary_accuracy: 0.9843 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981 - val_loss: 3.6274 - val_output1_loss: 0.2492 - val_output2_loss: 0.2651 - val_output3_loss: 0.3484 - val_output4_loss: 1.1648 - val_output5_loss: 0.3342 - val_output6_loss: 0.2958 - val_output7_loss: 0.3760 - val_output8_loss: 0.2385 - val_output9_loss: 0.2286 - val_output10_loss: 0.0823 - val_output11_loss: 0.0412 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9336 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9160 - val_output4_binary_accuracy: 0.8018 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9277 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 19/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6363 - output1_loss: 0.1284 - output2_loss: 0.1804 - output3_loss: 0.2664 - output4_loss: 0.8239 - output5_loss: 0.2573 - output6_loss: 0.2426 - output7_loss: 0.2359 - output8_loss: 0.2001 - output9_loss: 0.2051 - output10_loss: 0.0473 - output11_loss: 0.0349 - output12_loss: 0.0140 - output1_binary_accuracy: 0.9685 - output2_binary_accuracy: 0.9589 - output3_binary_accuracy: 0.9274 - output4_binary_accuracy: 0.8673 - output5_binary_accuracy: 0.9330 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9435 - output8_binary_accuracy: 0.9465 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9854 - output11_binary_accuracy: 0.9927 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00019: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 338ms/step - loss: 2.6363 - output1_loss: 0.1284 - output2_loss: 0.1804 - output3_loss: 0.2664 - output4_loss: 0.8239 - output5_loss: 0.2573 - output6_loss: 0.2426 - output7_loss: 0.2359 - output8_loss: 0.2001 - output9_loss: 0.2051 - output10_loss: 0.0473 - output11_loss: 0.0349 - output12_loss: 0.0140 - output1_binary_accuracy: 0.9685 - output2_binary_accuracy: 0.9589 - output3_binary_accuracy: 0.9274 - output4_binary_accuracy: 0.8673 - output5_binary_accuracy: 0.9330 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9435 - output8_binary_accuracy: 0.9465 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9854 - output11_binary_accuracy: 0.9927 - output12_binary_accuracy: 0.9981 - val_loss: 3.6354 - val_output1_loss: 0.2504 - val_output2_loss: 0.2595 - val_output3_loss: 0.3485 - val_output4_loss: 1.1697 - val_output5_loss: 0.3395 - val_output6_loss: 0.2967 - val_output7_loss: 0.3742 - val_output8_loss: 0.2418 - val_output9_loss: 0.2294 - val_output10_loss: 0.0811 - val_output11_loss: 0.0413 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9336 - val_output2_binary_accuracy: 0.9434 - val_output3_binary_accuracy: 0.9170 - val_output4_binary_accuracy: 0.8027 - val_output5_binary_accuracy: 0.9219 - val_output6_binary_accuracy: 0.9375 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9287 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 20/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6140 - output1_loss: 0.1229 - output2_loss: 0.1764 - output3_loss: 0.2692 - output4_loss: 0.8180 - output5_loss: 0.2579 - output6_loss: 0.2428 - output7_loss: 0.2337 - output8_loss: 0.1961 - output9_loss: 0.2021 - output10_loss: 0.0481 - output11_loss: 0.0334 - output12_loss: 0.0134 - output1_binary_accuracy: 0.9732 - output2_binary_accuracy: 0.9613 - output3_binary_accuracy: 0.9263 - output4_binary_accuracy: 0.8668 - output5_binary_accuracy: 0.9348 - output6_binary_accuracy: 0.9417 - output7_binary_accuracy: 0.9463 - output8_binary_accuracy: 0.9500 - output9_binary_accuracy: 0.9405 - output10_binary_accuracy: 0.9841 - output11_binary_accuracy: 0.9930 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00020: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 84s 336ms/step - loss: 2.6140 - output1_loss: 0.1229 - output2_loss: 0.1764 - output3_loss: 0.2692 - output4_loss: 0.8180 - output5_loss: 0.2579 - output6_loss: 0.2428 - output7_loss: 0.2337 - output8_loss: 0.1961 - output9_loss: 0.2021 - output10_loss: 0.0481 - output11_loss: 0.0334 - output12_loss: 0.0134 - output1_binary_accuracy: 0.9732 - output2_binary_accuracy: 0.9613 - output3_binary_accuracy: 0.9263 - output4_binary_accuracy: 0.8668 - output5_binary_accuracy: 0.9348 - output6_binary_accuracy: 0.9417 - output7_binary_accuracy: 0.9463 - output8_binary_accuracy: 0.9500 - output9_binary_accuracy: 0.9405 - output10_binary_accuracy: 0.9841 - output11_binary_accuracy: 0.9930 - output12_binary_accuracy: 0.9981 - val_loss: 3.6443 - val_output1_loss: 0.2509 - val_output2_loss: 0.2663 - val_output3_loss: 0.3477 - val_output4_loss: 1.1731 - val_output5_loss: 0.3349 - val_output6_loss: 0.2928 - val_output7_loss: 0.3800 - val_output8_loss: 0.2421 - val_output9_loss: 0.2293 - val_output10_loss: 0.0823 - val_output11_loss: 0.0414 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9316 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9160 - val_output4_binary_accuracy: 0.8008 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9404 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9277 - val_output9_binary_accuracy: 0.9287 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 21/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6048 - output1_loss: 0.1201 - output2_loss: 0.1748 - output3_loss: 0.2692 - output4_loss: 0.8190 - output5_loss: 0.2563 - output6_loss: 0.2453 - output7_loss: 0.2298 - output8_loss: 0.1956 - output9_loss: 0.2017 - output10_loss: 0.0455 - output11_loss: 0.0335 - output12_loss: 0.0140 - output1_binary_accuracy: 0.9724 - output2_binary_accuracy: 0.9626 - output3_binary_accuracy: 0.9257 - output4_binary_accuracy: 0.8690 - output5_binary_accuracy: 0.9309 - output6_binary_accuracy: 0.9405 - output7_binary_accuracy: 0.9467 - output8_binary_accuracy: 0.9472 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9859 - output11_binary_accuracy: 0.9929 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00021: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 337ms/step - loss: 2.6048 - output1_loss: 0.1201 - output2_loss: 0.1748 - output3_loss: 0.2692 - output4_loss: 0.8190 - output5_loss: 0.2563 - output6_loss: 0.2453 - output7_loss: 0.2298 - output8_loss: 0.1956 - output9_loss: 0.2017 - output10_loss: 0.0455 - output11_loss: 0.0335 - output12_loss: 0.0140 - output1_binary_accuracy: 0.9724 - output2_binary_accuracy: 0.9626 - output3_binary_accuracy: 0.9257 - output4_binary_accuracy: 0.8690 - output5_binary_accuracy: 0.9309 - output6_binary_accuracy: 0.9405 - output7_binary_accuracy: 0.9467 - output8_binary_accuracy: 0.9472 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9859 - output11_binary_accuracy: 0.9929 - output12_binary_accuracy: 0.9981 - val_loss: 3.6236 - val_output1_loss: 0.2472 - val_output2_loss: 0.2666 - val_output3_loss: 0.3416 - val_output4_loss: 1.1691 - val_output5_loss: 0.3324 - val_output6_loss: 0.2968 - val_output7_loss: 0.3753 - val_output8_loss: 0.2419 - val_output9_loss: 0.2258 - val_output10_loss: 0.0820 - val_output11_loss: 0.0415 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9346 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.8047 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9268 - val_output9_binary_accuracy: 0.9297 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 22/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6048 - output1_loss: 0.1215 - output2_loss: 0.1738 - output3_loss: 0.2645 - output4_loss: 0.8231 - output5_loss: 0.2582 - output6_loss: 0.2414 - output7_loss: 0.2297 - output8_loss: 0.1961 - output9_loss: 0.2019 - output10_loss: 0.0465 - output11_loss: 0.0344 - output12_loss: 0.0138 - output1_binary_accuracy: 0.9720 - output2_binary_accuracy: 0.9612 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8639 - output5_binary_accuracy: 0.9307 - output6_binary_accuracy: 0.9427 - output7_binary_accuracy: 0.9487 - output8_binary_accuracy: 0.9492 - output9_binary_accuracy: 0.9432 - output10_binary_accuracy: 0.9856 - output11_binary_accuracy: 0.9927 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00022: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 338ms/step - loss: 2.6048 - output1_loss: 0.1215 - output2_loss: 0.1738 - output3_loss: 0.2645 - output4_loss: 0.8231 - output5_loss: 0.2582 - output6_loss: 0.2414 - output7_loss: 0.2297 - output8_loss: 0.1961 - output9_loss: 0.2019 - output10_loss: 0.0465 - output11_loss: 0.0344 - output12_loss: 0.0138 - output1_binary_accuracy: 0.9720 - output2_binary_accuracy: 0.9612 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8639 - output5_binary_accuracy: 0.9307 - output6_binary_accuracy: 0.9427 - output7_binary_accuracy: 0.9487 - output8_binary_accuracy: 0.9492 - output9_binary_accuracy: 0.9432 - output10_binary_accuracy: 0.9856 - output11_binary_accuracy: 0.9927 - output12_binary_accuracy: 0.9981 - val_loss: 3.6448 - val_output1_loss: 0.2511 - val_output2_loss: 0.2656 - val_output3_loss: 0.3501 - val_output4_loss: 1.1691 - val_output5_loss: 0.3416 - val_output6_loss: 0.2941 - val_output7_loss: 0.3755 - val_output8_loss: 0.2413 - val_output9_loss: 0.2283 - val_output10_loss: 0.0832 - val_output11_loss: 0.0415 - val_output12_loss: 0.0034 - val_output1_binary_accuracy: 0.9297 - val_output2_binary_accuracy: 0.9424 - val_output3_binary_accuracy: 0.9170 - val_output4_binary_accuracy: 0.8047 - val_output5_binary_accuracy: 0.9209 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9268 - val_output9_binary_accuracy: 0.9268 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 23/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6077 - output1_loss: 0.1240 - output2_loss: 0.1751 - output3_loss: 0.2664 - output4_loss: 0.8204 - output5_loss: 0.2595 - output6_loss: 0.2416 - output7_loss: 0.2318 - output8_loss: 0.1930 - output9_loss: 0.2036 - output10_loss: 0.0447 - output11_loss: 0.0343 - output12_loss: 0.0135 - output1_binary_accuracy: 0.9711 - output2_binary_accuracy: 0.9608 - output3_binary_accuracy: 0.9270 - output4_binary_accuracy: 0.8687 - output5_binary_accuracy: 0.9319 - output6_binary_accuracy: 0.9400 - output7_binary_accuracy: 0.9472 - output8_binary_accuracy: 0.9504 - output9_binary_accuracy: 0.9404 - output10_binary_accuracy: 0.9858 - output11_binary_accuracy: 0.9928 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00023: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 339ms/step - loss: 2.6077 - output1_loss: 0.1240 - output2_loss: 0.1751 - output3_loss: 0.2664 - output4_loss: 0.8204 - output5_loss: 0.2595 - output6_loss: 0.2416 - output7_loss: 0.2318 - output8_loss: 0.1930 - output9_loss: 0.2036 - output10_loss: 0.0447 - output11_loss: 0.0343 - output12_loss: 0.0135 - output1_binary_accuracy: 0.9711 - output2_binary_accuracy: 0.9608 - output3_binary_accuracy: 0.9270 - output4_binary_accuracy: 0.8687 - output5_binary_accuracy: 0.9319 - output6_binary_accuracy: 0.9400 - output7_binary_accuracy: 0.9472 - output8_binary_accuracy: 0.9504 - output9_binary_accuracy: 0.9404 - output10_binary_accuracy: 0.9858 - output11_binary_accuracy: 0.9928 - output12_binary_accuracy: 0.9981 - val_loss: 3.6399 - val_output1_loss: 0.2519 - val_output2_loss: 0.2647 - val_output3_loss: 0.3458 - val_output4_loss: 1.1748 - val_output5_loss: 0.3354 - val_output6_loss: 0.2970 - val_output7_loss: 0.3805 - val_output8_loss: 0.2383 - val_output9_loss: 0.2240 - val_output10_loss: 0.0821 - val_output11_loss: 0.0419 - val_output12_loss: 0.0035 - val_output1_binary_accuracy: 0.9336 - val_output2_binary_accuracy: 0.9434 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.7998 - val_output5_binary_accuracy: 0.9238 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9316 - val_output9_binary_accuracy: 0.9297 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 24/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6033 - output1_loss: 0.1206 - output2_loss: 0.1762 - output3_loss: 0.2700 - output4_loss: 0.8130 - output5_loss: 0.2564 - output6_loss: 0.2386 - output7_loss: 0.2346 - output8_loss: 0.1979 - output9_loss: 0.2016 - output10_loss: 0.0468 - output11_loss: 0.0342 - output12_loss: 0.0136 - output1_binary_accuracy: 0.9721 - output2_binary_accuracy: 0.9597 - output3_binary_accuracy: 0.9265 - output4_binary_accuracy: 0.8710 - output5_binary_accuracy: 0.9340 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9441 - output8_binary_accuracy: 0.9490 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00024: val_loss did not improve from 3.54951\n",
            "251/251 [==============================] - 85s 339ms/step - loss: 2.6033 - output1_loss: 0.1206 - output2_loss: 0.1762 - output3_loss: 0.2700 - output4_loss: 0.8130 - output5_loss: 0.2564 - output6_loss: 0.2386 - output7_loss: 0.2346 - output8_loss: 0.1979 - output9_loss: 0.2016 - output10_loss: 0.0468 - output11_loss: 0.0342 - output12_loss: 0.0136 - output1_binary_accuracy: 0.9721 - output2_binary_accuracy: 0.9597 - output3_binary_accuracy: 0.9265 - output4_binary_accuracy: 0.8710 - output5_binary_accuracy: 0.9340 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9441 - output8_binary_accuracy: 0.9490 - output9_binary_accuracy: 0.9420 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981 - val_loss: 3.6343 - val_output1_loss: 0.2489 - val_output2_loss: 0.2646 - val_output3_loss: 0.3477 - val_output4_loss: 1.1714 - val_output5_loss: 0.3400 - val_output6_loss: 0.2959 - val_output7_loss: 0.3807 - val_output8_loss: 0.2302 - val_output9_loss: 0.2293 - val_output10_loss: 0.0814 - val_output11_loss: 0.0407 - val_output12_loss: 0.0033 - val_output1_binary_accuracy: 0.9336 - val_output2_binary_accuracy: 0.9424 - val_output3_binary_accuracy: 0.9170 - val_output4_binary_accuracy: 0.8018 - val_output5_binary_accuracy: 0.9209 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9053 - val_output8_binary_accuracy: 0.9316 - val_output9_binary_accuracy: 0.9258 - val_output10_binary_accuracy: 0.9785 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c3c482c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfSJxN--xs1",
        "colab_type": "text"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDym2PgJ6ml",
        "colab_type": "code",
        "outputId": "8e074c5a-7c37-490d-ded1-263a36069d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1259, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 1259, 768)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 1259, 128)    426496      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1259, 128)    98816       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          65792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256)          0           concatenate[0][0]                \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           add[0][0]                        \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 659,980\n",
            "Trainable params: 659,980\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onSOnIBxPXa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(Name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZwqpZmP_pVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class testDataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=25, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim, self.n_channels))\n",
        "        #y = np.zeros((self.batch_size,self.n_classes), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            try:\n",
        "              temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              X[i,0:temp.shape[0],:] =temp \n",
        "              del temp\n",
        "            except:\n",
        "              print('Faile to load the data: BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "            # Store sample\n",
        "            # Store class\n",
        "            #y[i,:] = np.array(list_IDs_temp.iloc[i,0:12])\n",
        "\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnTSkm2_EBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator=testDataGenerator(Test,'Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MneDN8jV-spA",
        "colab_type": "code",
        "outputId": "e8491e28-ea6d-4faf-ac19-c00e884fb9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "prediction = model.predict_generator(test_generator)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-342c80f366ab>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "Faile to load the data: BERT/vector/Test_250089_25728.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0iEXswMaFjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Prediction=np.array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKCnqyr_dH-",
        "colab_type": "code",
        "outputId": "3c0d5471-4eeb-4806-8aa9-de0eda607845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IOU=0\n",
        "for i in range(len(Test)):\n",
        "  pred=Prediction[0:N_CLASS,i,0]\n",
        "  labels=np.array(Test.iloc[i,0:N_CLASS])\n",
        "  ioU=np.sum((pred>=0.5)&(labels==1))/np.sum( (pred>=0.5) | (labels==1))\n",
        "  IOU+=ioU\n",
        "IOU=IOU/len(Test)\n",
        "print(IOU)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6471171171171172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DavG4UnTDpVw",
        "colab_type": "code",
        "outputId": "d22cd4be-2e67-4da7-9213-da56abc83368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ACC=0\n",
        "for i in range(len(Test)):\n",
        "  pred=Prediction[0:N_CLASS,i,0]\n",
        "  labels=np.array(Test.iloc[i,0:N_CLASS])\n",
        "  acc=np.sum((pred>=0.5)==labels)/12\n",
        "  ACC+=acc\n",
        "ACC=ACC/len(Test)\n",
        "print(ACC)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9257657657657649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV-AOnmQh8B3",
        "colab_type": "code",
        "outputId": "d2bcc4e6-75c0-4477-f4bd-ffa2efd1a3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "for i in range(N_CLASS):\n",
        "  print(np.sum(Test.iloc[:,i]==1)/len(Test),np.sum((Prediction[i,:,0]>=0.5)==(Test.iloc[:,i]))/len(Test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23135135135135135 0.92\n",
            "0.05837837837837838 0.9437837837837838\n",
            "0.08108108108108109 0.9091891891891892\n",
            "0.24756756756756756 0.7718918918918919\n",
            "0.0918918918918919 0.9091891891891892\n",
            "0.11135135135135135 0.932972972972973\n",
            "0.4043243243243243 0.9124324324324324\n",
            "0.11891891891891893 0.9221621621621622\n",
            "0.07243243243243243 0.9297297297297298\n",
            "0.02918918918918919 0.9686486486486486\n",
            "0.004324324324324324 0.9913513513513513\n",
            "0.002162162162162162 0.9978378378378379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STX-AG6uZs4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "4f4d2a7d-965d-42ea-e58a-f1803edd12ce"
      },
      "source": [
        "for i in range(N_CLASS):\n",
        "  pred=Prediction[i,:,0]\n",
        "  labels=np.array(Test.iloc[:,i])\n",
        "  print(precision_recall_fscore_support(labels, pred>=0.5, average='binary',zero_division=1))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.8181818181818182, 0.8411214953271028, 0.8294930875576038, None)\n",
            "(0.525, 0.3888888888888889, 0.4468085106382979, None)\n",
            "(0.38461538461538464, 0.2, 0.2631578947368421, None)\n",
            "(0.5529411764705883, 0.4104803493449782, 0.47117794486215536, None)\n",
            "(0.509090909090909, 0.32941176470588235, 0.4, None)\n",
            "(0.735632183908046, 0.6213592233009708, 0.6736842105263158, None)\n",
            "(0.9103641456582633, 0.8689839572192514, 0.8891928864569083, None)\n",
            "(0.6826923076923077, 0.6454545454545455, 0.663551401869159, None)\n",
            "(0.5161290322580645, 0.47761194029850745, 0.49612403100775193, None)\n",
            "(0.4772727272727273, 0.7777777777777778, 0.5915492957746479, None)\n",
            "(0.16666666666666666, 0.25, 0.2, None)\n",
            "(1.0, 0.0, 0.0, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96IhGmpUPb3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dc07d59-d41c-430e-850e-d7b0b62bb6d5"
      },
      "source": [
        "# Precision\n",
        "Precision=0\n",
        "N=len(Test)\n",
        "for i in range(len(Test)):\n",
        "  pred=Prediction[0:N_CLASS,i,0]\n",
        "  labels=np.array(Test.iloc[i,0:N_CLASS])\n",
        "  if np.sum(pred>=0.5)==0:\n",
        "    N-=1\n",
        "    continue\n",
        "  precision=np.sum(((pred>=0.5)&(labels==1)))/np.sum(pred>=0.5)\n",
        "  Precision+=precision\n",
        "Precision=Precision/N\n",
        "print(Precision)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7673495754891102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uHRW1sBb28Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59c8f238-8571-4db5-f446-314e424e2dba"
      },
      "source": [
        "# Precision\n",
        "Precision=0\n",
        "N=N_CLASS\n",
        "for i in range(N_CLASS):\n",
        "  pred=Prediction[i,:,0]\n",
        "  labels=np.array(Test.iloc[:,i])\n",
        "  if np.sum(pred>=0.5)==0:\n",
        "    N-=1\n",
        "    continue\n",
        "  precision=np.sum(((pred>=0.5)&(labels==1)))/np.sum(pred>=0.5)\n",
        "  Precision+=precision\n",
        "Precision=Precision/N\n",
        "print(Precision)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5707805774377068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j71RT6UzYD2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2890dfe-eb1c-4ad4-d71f-3223717ef1fd"
      },
      "source": [
        "Recall=0\n",
        "N=len(Test)\n",
        "for i in range(len(Test)):\n",
        "  pred=Prediction[0:N_CLASS,i,0]\n",
        "  labels=np.array(Test.iloc[i,0:N_CLASS])\n",
        "  if np.sum(labels)==0:\n",
        "    N-=1\n",
        "    continue\n",
        "  recall=np.sum(((pred>=0.5)&(labels==1)))/np.sum(labels)\n",
        "  Recall+=recall\n",
        "Recall=Recall/N\n",
        "print(Precision)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7673495754891102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-jYFNVZcj1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d432910d-a455-4e2d-ddd9-e7b54de348a2"
      },
      "source": [
        "# Precision\n",
        "Recall=0\n",
        "N=N_CLASS\n",
        "for i in range(N_CLASS):\n",
        "  pred=Prediction[0:N_CLASS,i,0]\n",
        "  labels=np.array(Test.iloc[i,0:N_CLASS])\n",
        "  if np.sum(labels)==0:\n",
        "    N-=1\n",
        "    continue\n",
        "  recall=np.sum(((pred>=0.5)&(labels==1)))/np.sum(labels)\n",
        "  Recall+=recall\n",
        "Recall=Recall/N\n",
        "print(Recall)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7083333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3GWspxEe93u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true=np.array(Test.iloc[:,0:N_CLASS])\n",
        "y_pred=Prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHjjga8Rf5pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hamming_score(y_true, y_pred, toggle_output=False):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        if toggle_output:\n",
        "            print('set_true: {0}'.format([id2label[id] for id in set_true]), 'set_pred: {0}'.format([id2label[id] for id in set_pred]))\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        #print('tmp_a: {0}'.format(tmp_a))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIWmhjAYgzlg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75b253a3-2fbf-454c-8a09-722797cdf51b"
      },
      "source": [
        "hamming_score(y_true, y_pred, toggle_output=False)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6471171171171172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHKfPrFie7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "def f1(y_true, y_pred):\n",
        "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        \n",
        "        correct_preds += len(set_true & set_pred)\n",
        "        total_preds += len(set_pred)\n",
        "        total_correct += len(set_true)\n",
        "\n",
        "    p = correct_preds / total_preds if correct_preds > 0 else 0\n",
        "    r = correct_preds / total_correct if correct_preds > 0 else 0\n",
        "    f1 = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
        "    return p, r, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seCa3eD5cvdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e79ef98-3348-4313-fc1e-8ef3e865127b"
      },
      "source": [
        "f1(y_true, y_pred)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7195945945945946, 0.6339285714285714, 0.6740506329113924)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    }
  ]
}