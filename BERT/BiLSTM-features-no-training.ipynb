{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtsyang/UserIntentPrediction/blob/BERT/BERT/BiLSTM-features-no-training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot0Ha--FR-S1",
        "colab_type": "code",
        "outputId": "1b8bcd15-ddc7-4a42-ed93-c0e4800f25ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6DT7DNwSNn9",
        "colab_type": "code",
        "outputId": "574e80a9-bf42-4445-ae94-26504daef362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Change youe folder\n",
        "# Make sure you have a folder BERT under this: YOUR_FOLDER/BERT\n",
        "%cd '/content/drive/My Drive/UserIntentPrediction'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/UserIntentPrediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De681umQRanU",
        "colab_type": "code",
        "outputId": "3416866a-c46e-4f10-bb34-8f8b4e52cfa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
        "from tensorflow.keras.layers  import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import pickle\n",
        "import sklearn\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import smart_cond\n",
        "from functools import partial\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print('Tensorflow Version:',tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIpXSpeYR4rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_MODELS = 1\n",
        "BATCH_SIZE = 32\n",
        "LSTM_UNITS = 64\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
        "EPOCHS = 15\n",
        "MAX_LEN = 1259\n",
        "N_CHANNELS=768\n",
        "N_CLASS=12\n",
        "N_Features=24\n",
        "INDEX_Features=range(-24,-0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lcdmN7BSHGl",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p2_0TqoR9ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train=pd.read_csv('data/train_features.csv').reset_index(drop=True)\n",
        "Valid=pd.read_csv('data/valid_features.csv').reset_index(drop=True)\n",
        "Test=pd.read_csv('data/test_features.csv').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjliEKeAhO4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=BATCH_SIZE, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        x = np.zeros((self.batch_size, self.dim, self.n_channels))\n",
        "        y = np.zeros((self.batch_size,self.n_classes), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            try:\n",
        "              temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              x[i,0:temp.shape[0],:] =temp \n",
        "              del temp\n",
        "            except:\n",
        "              print('Faile to load the data: BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "            # Store sample\n",
        "            # Store class\n",
        "            y[i,:] = np.array(list_IDs_temp.iloc[i,0:12])\n",
        "        Y=[]\n",
        "        for i in range(self.n_classes):\n",
        "          Y+=[y[:,i].reshape((self.batch_size,))]\n",
        "        X=[x,np.array(list_IDs_temp.iloc[:,INDEX_Features])]\n",
        "        return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ijHEnaK7opB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_generator = DataGenerator(Train,'Train')\n",
        "validation_generator = DataGenerator(Valid,'Valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBl5lHEfSGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict={}\n",
        "for i in range(N_CLASS):\n",
        "  ratioTrue=np.sum(Train.iloc[:,i])/len(Train)\n",
        "  classWeight_Dict['output'+str(i+1)]={0:1+1/((1-ratioTrue)/(ratioTrue)+1),1:1+(1-ratioTrue)/(ratioTrue)/((1-ratioTrue)/(ratioTrue)+1)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8C5_nNdl9Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict['output4'][1]+=1\n",
        "classWeight_Dict['output4'][0]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaoPIhG5PE0e",
        "colab_type": "code",
        "outputId": "a146083e-e557-49ef-b9ab-424fcb5d7e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "classWeight_Dict"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output1': {0: 1.234499007936508, 1: 1.765500992063492},\n",
              " 'output10': {0: 1.0336061507936507, 1: 1.9663938492063493},\n",
              " 'output11': {0: 1.0100446428571428, 1: 1.9899553571428572},\n",
              " 'output12': {0: 1.001860119047619, 1: 1.998139880952381},\n",
              " 'output2': {0: 1.0603918650793651, 1: 1.9396081349206349},\n",
              " 'output3': {0: 1.0744047619047619, 1: 1.9255952380952381},\n",
              " 'output4': {0: 3.247147817460317, 1: 3.752852182539683},\n",
              " 'output5': {0: 1.0875496031746033, 1: 1.9124503968253967},\n",
              " 'output6': {0: 1.1071428571428572, 1: 1.8928571428571428},\n",
              " 'output7': {0: 1.3979414682539684, 1: 1.6020585317460316},\n",
              " 'output8': {0: 1.1070188492063493, 1: 1.8929811507936507},\n",
              " 'output9': {0: 1.0767609126984128, 1: 1.9232390873015874}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2mz_N6c7mEx",
        "colab_type": "text"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytjcvIOnMiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_crossentropy(y_true, y_pred, weights,from_logits=False,label_smoothing=0):\n",
        "\n",
        "    y_pred = ops.convert_to_tensor(y_pred)\n",
        "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
        "    label_smoothing = ops.convert_to_tensor(label_smoothing, dtype=K.floatx())\n",
        "    def _smooth_labels():\n",
        "      return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
        "    y_true = smart_cond.smart_cond(label_smoothing,_smooth_labels, lambda: y_true)\n",
        "    \n",
        "    mask0 = tf.subtract(tf.constant(1.0, dtype=K.floatx()),y_true)\n",
        "    mask0=tf.math.scalar_mul(tf.constant(weights[0], dtype=K.floatx()),mask0)\n",
        "    mask1 =tf.math.scalar_mul(tf.constant(weights[1], dtype=K.floatx()),y_true)\n",
        "    mask=tf.math.add(mask0,mask1)\n",
        "\n",
        "    return K.mean(tf.math.multiply(K.binary_crossentropy(y_true, y_pred, from_logits=from_logits),mask), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKQSOUM5saC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    inputs1 = Input(shape=(MAX_LEN,N_CHANNELS))\n",
        "    inputs2 = Input(shape=(N_Features,))\n",
        "\n",
        "    x = SpatialDropout1D(0.2)(inputs1)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "\n",
        "    hidden = concatenate([\n",
        "        GlobalMaxPooling1D()(x),\n",
        "        GlobalAveragePooling1D()(x),\n",
        "        inputs2,\n",
        "    ])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS+24, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS+24, activation='relu')(hidden)])\n",
        "    RESULT=[]\n",
        "    for i in range(N_CLASS):\n",
        "      RESULT+=[Dense(1, activation='sigmoid',name='output'+str(i+1))(hidden)]\n",
        "    LOSS={}\n",
        "    for i in  range(N_CLASS):\n",
        "      LOSS['output'+str(i+1)]=partial(binary_crossentropy, weights=classWeight_Dict['output'+str(i+1)])\n",
        "      LOSS['output'+str(i+1)].__name__ = 'loss'+str(i+1)\n",
        "\n",
        "    inputs={'inputs1':inputs1,'inputs2':inputs2}\n",
        "    model = Model(inputs=inputs, outputs=RESULT)\n",
        "    model.compile(loss=LOSS, optimizer='adam',metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N37opYym6CCC",
        "colab_type": "code",
        "outputId": "137b75a0-aff1-4743-9a87-d294ef2ac3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1259, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 1259, 768)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 1259, 128)    426496      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1259, 128)    98816       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 24)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 280)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 280)          78680       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 280)          0           concatenate[0][0]                \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 280)          78680       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 280)          0           add[0][0]                        \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            281         add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 686,044\n",
            "Trainable params: 686,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sb5GQmKeI_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback=ReduceLROnPlateau(patience=1,min_lr=0.00001,factor=0.3)\n",
        "Name='BERT/LSTM_addFeatures.h5'\n",
        "checkpointer = ModelCheckpoint(filepath=Name, verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4To3UbV67kft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=training_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpointer,callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfSJxN--xs1",
        "colab_type": "text"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDym2PgJ6ml",
        "colab_type": "code",
        "outputId": "035ea333-b773-4e38-ee8f-8aedd41b43a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1259, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 1259, 768)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 1259, 128)    426496      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1259, 128)    98816       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 24)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 280)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 280)          78680       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 280)          0           concatenate[0][0]                \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 280)          78680       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 280)          0           add[0][0]                        \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            281         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            281         add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 686,044\n",
            "Trainable params: 686,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onSOnIBxPXa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(Name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZwqpZmP_pVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class testDataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=25, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "         # Initialization\n",
        "        x = np.zeros((self.batch_size, self.dim, self.n_channels))\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            try:\n",
        "              temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              x[i,0:temp.shape[0],:] =temp \n",
        "              del temp\n",
        "            except:\n",
        "              print('Faile to load the data: BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "\n",
        "          \n",
        "        X=[x,np.array(list_IDs_temp.iloc[:,INDEX_Features])]\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnTSkm2_EBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator=testDataGenerator(Test,'Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MneDN8jV-spA",
        "colab_type": "code",
        "outputId": "e3d28ae8-0cc4-4b97-a053-3d829fe9bc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "prediction = model.predict_generator(test_generator)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-342c80f366ab>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "Faile to load the data: BERT/vector/Test_250089_25728.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0iEXswMaFjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Prediction=np.array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3GWspxEe93u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true=np.array(Test.iloc[:,0:N_CLASS])\n",
        "y_pred=Prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHjjga8Rf5pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hamming_score(y_true, y_pred, toggle_output=False):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        if toggle_output:\n",
        "            print('set_true: {0}'.format([id2label[id] for id in set_true]), 'set_pred: {0}'.format([id2label[id] for id in set_pred]))\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        #print('tmp_a: {0}'.format(tmp_a))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIWmhjAYgzlg",
        "colab_type": "code",
        "outputId": "d1433a1d-ed53-4561-daa3-062fc5cf905c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hamming_score(y_true, y_pred, toggle_output=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6816936936936936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHKfPrFie7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "def f1(y_true, y_pred):\n",
        "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        \n",
        "        correct_preds += len(set_true & set_pred)\n",
        "        total_preds += len(set_pred)\n",
        "        total_correct += len(set_true)\n",
        "\n",
        "    p = correct_preds / total_preds if correct_preds > 0 else 0\n",
        "    r = correct_preds / total_correct if correct_preds > 0 else 0\n",
        "    f1 = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
        "    return p, r, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seCa3eD5cvdx",
        "colab_type": "code",
        "outputId": "1171c2aa-dda8-4446-ca19-b9ba9bd8aff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1(y_true, y_pred)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.768624014022787, 0.6525297619047619, 0.7058350100603622)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}