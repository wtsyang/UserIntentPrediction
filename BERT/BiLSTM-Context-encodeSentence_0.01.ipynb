{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMM8M3aVfl1Nt7xxUAwYKTL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtsyang/UserIntentPrediction/blob/BERT/BERT/BiLSTM-Context-encodeSentence_0.01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot0Ha--FR-S1",
        "colab_type": "code",
        "outputId": "b886a731-910c-442b-e6ba-d46c0a0f1199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6DT7DNwSNn9",
        "colab_type": "code",
        "outputId": "2fe476ce-b216-4ef9-878d-a336394d2005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/UserIntentPrediction'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/UserIntentPrediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De681umQRanU",
        "colab_type": "code",
        "outputId": "74002dc2-1ee9-4b71-a17b-eff97cdeecfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
        "from tensorflow.keras.layers  import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import pickle\n",
        "import sklearn\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import smart_cond\n",
        "from functools import partial\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print('Tensorflow Version:',tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIpXSpeYR4rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_MODELS = 1\n",
        "BATCH_SIZE = 32\n",
        "LSTM_UNITS = 64\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS \n",
        "EPOCHS = 15\n",
        "MAX_LEN = 1259\n",
        "N_CHANNELS=768\n",
        "N_CLASS=12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lcdmN7BSHGl",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p2_0TqoR9ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train=pd.read_csv('data/Train_Preprocessing.csv').reset_index(drop=True)\n",
        "Valid=pd.read_csv('data/Valid_Preprocessing.csv').reset_index(drop=True)\n",
        "Test=pd.read_csv('data/Test_Preprocessing.csv').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjliEKeAhO4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=BATCH_SIZE, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim*3, self.n_channels))\n",
        "        y = np.zeros((self.batch_size,self.n_classes), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            pos=list_IDs_temp.loc[i,'utterance_pos']\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            latter=len(self.list_IDs.loc[(self.list_IDs['utterance_pos']==(pos+1))&(self.list_IDs['diaglogID']==(diaglogID)),:])\n",
        "            temp3=np.zeros(( 512, self.n_channels))\n",
        "            temp1=np.ones(( 512, self.n_channels))\n",
        "\n",
        "            try:\n",
        "              if pos>1:\n",
        "                temp1=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-1)+'_'+str(diaglogID)+'.npy')\n",
        "            except:\n",
        "              pass\n",
        "\n",
        "            try:\n",
        "              temp2=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "            except:\n",
        "              temp2=np.zeros(( 512, self.n_channels))\n",
        "            \n",
        "            try:\n",
        "              if latter==1:\n",
        "                temp3=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID+1)+'_'+str(diaglogID)+'.npy')\n",
        "            except:\n",
        "              pass\n",
        "            \n",
        "            temp=np.concatenate((temp1,temp2,temp3),axis=0)\n",
        "\n",
        "            # Store sample\n",
        "            X[i,0:temp.shape[0],:] =temp \n",
        "            del temp\n",
        "            del temp1\n",
        "            del temp2\n",
        "            del temp3\n",
        "\n",
        "            # Store class\n",
        "            y[i,:] = np.array(list_IDs_temp.iloc[i,0:self.n_classes])\n",
        "\n",
        "        Y=[]\n",
        "        for i in range(self.n_classes):\n",
        "          Y+=[y[:,i].reshape((self.batch_size,))]\n",
        "        Pos=np.array(list_IDs_temp.loc[:,'utterance_pos'])\n",
        "        return [X,Pos], Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ijHEnaK7opB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_generator = DataGenerator(Train,'Train')\n",
        "validation_generator = DataGenerator(Valid,'Valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBl5lHEfSGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict={}\n",
        "for i in range(N_CLASS):\n",
        "  ratioTrue=np.sum(Train.iloc[:,i])/len(Train)\n",
        "  classWeight_Dict['output'+str(i+1)]={0:1+1/((1-ratioTrue)/(ratioTrue)+1),1:1+(1-ratioTrue)/(ratioTrue)/((1-ratioTrue)/(ratioTrue)+1)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8C5_nNdl9Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict['output4'][1]+=1\n",
        "classWeight_Dict['output4'][0]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaoPIhG5PE0e",
        "colab_type": "code",
        "outputId": "b9e35767-518d-48e4-d7ed-bcb1c7783b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "classWeight_Dict"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output1': {0: 1.2345571818407344, 1: 1.7654428181592656},\n",
              " 'output10': {0: 1.0336144877201687, 1: 1.9663855122798313},\n",
              " 'output11': {0: 1.0100471347060282, 1: 1.9899528652939718},\n",
              " 'output12': {0: 1.0018605805011163, 1: 1.9981394194988837},\n",
              " 'output2': {0: 1.0604068469362442, 1: 1.9395931530637558},\n",
              " 'output3': {0: 1.074423220044654, 1: 1.925576779955346},\n",
              " 'output4': {0: 2.247085090548251, 1: 2.752914909451749},\n",
              " 'output5': {0: 1.0875713222525427, 1: 1.912428677747457},\n",
              " 'output6': {0: 1.1071694368643017, 1: 1.8928305631356983},\n",
              " 'output7': {0: 1.3979161498387498, 1: 1.6020838501612502},\n",
              " 'output8': {0: 1.1070453981642272, 1: 1.8929546018357728},\n",
              " 'output9': {0: 1.076779955346068, 1: 1.923220044653932}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2mz_N6c7mEx",
        "colab_type": "text"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytjcvIOnMiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_crossentropy(y_true, y_pred, weights,from_logits=False,label_smoothing=0):\n",
        "\n",
        "    y_pred = ops.convert_to_tensor(y_pred)\n",
        "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
        "    label_smoothing = ops.convert_to_tensor(label_smoothing, dtype=K.floatx())\n",
        "    def _smooth_labels():\n",
        "      return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
        "    y_true = smart_cond.smart_cond(label_smoothing,_smooth_labels, lambda: y_true)\n",
        "    \n",
        "    mask0 = tf.subtract(tf.constant(1.0, dtype=K.floatx()),y_true)\n",
        "    mask0=tf.math.scalar_mul(tf.constant(weights[0], dtype=K.floatx()),mask0)\n",
        "    mask1 =tf.math.scalar_mul(tf.constant(weights[1], dtype=K.floatx()),y_true)\n",
        "    mask=tf.math.add(mask0,mask1)\n",
        "\n",
        "    return K.mean(tf.math.multiply(K.binary_crossentropy(y_true, y_pred, from_logits=from_logits),mask), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKQSOUM5saC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    inputs1 = Input(shape=(MAX_LEN*3,N_CHANNELS))\n",
        "    inputs2 = Input(shape=(1,))\n",
        "    x = SpatialDropout1D(0.2)(inputs1)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "\n",
        "    hidden = concatenate([\n",
        "        GlobalMaxPooling1D()(x),\n",
        "        GlobalAveragePooling1D()(x),\n",
        "        inputs2,\n",
        "    ])\n",
        "\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS+1, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS+1, activation='relu')(hidden)])\n",
        "    RESULT=[]\n",
        "    for i in range(N_CLASS):\n",
        "      RESULT+=[Dense(1, activation='sigmoid',name='output'+str(i+1))(hidden)]\n",
        "    LOSS={}\n",
        "    for i in  range(N_CLASS):\n",
        "      LOSS['output'+str(i+1)]=partial(binary_crossentropy, weights=classWeight_Dict['output'+str(i+1)])\n",
        "      LOSS['output'+str(i+1)].__name__ = 'loss'+str(i+1)\n",
        "\n",
        "    inputs={'inputs1':inputs1,'inputs2':inputs2}\n",
        "    model = Model(inputs=inputs, outputs=RESULT)\n",
        "    model.compile(loss=LOSS, optimizer='adam',metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N37opYym6CCC",
        "colab_type": "code",
        "outputId": "e67acc35-d6c5-464d-8896-1c92252c8f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 3777, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_3 (SpatialDro (None, 3777, 768)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 3777, 128)    426496      spatial_dropout1d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) (None, 3777, 128)    98816       bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 257)          0           global_max_pooling1d_3[0][0]     \n",
            "                                                                 global_average_pooling1d_3[0][0] \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 257)          66306       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 257)          0           concatenate_3[0][0]              \n",
            "                                                                 dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 257)          66306       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 257)          0           add_6[0][0]                      \n",
            "                                                                 dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            258         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            258         add_7[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 661,020\n",
            "Trainable params: 661,020\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sb5GQmKeI_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback=ReduceLROnPlateau(patience=1,min_lr=0.00001,factor=0.3)\n",
        "Name='BERT/BiLSTM_Context_addPositionEncoding_0.01.h5'\n",
        "checkpointer = ModelCheckpoint(filepath=Name, verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4To3UbV67kft",
        "colab_type": "code",
        "outputId": "a00caba2-7f3f-4035-882c-6416df55ced0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=training_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpointer,callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 5.3154 - output1_loss: 0.2614 - output2_loss: 0.3553 - output3_loss: 0.4302 - output4_loss: 1.3369 - output5_loss: 0.4532 - output6_loss: 0.5167 - output7_loss: 0.7784 - output8_loss: 0.4414 - output9_loss: 0.4168 - output10_loss: 0.1867 - output11_loss: 0.1000 - output12_loss: 0.0386 - output1_binary_accuracy: 0.9564 - output2_binary_accuracy: 0.9360 - output3_binary_accuracy: 0.9197 - output4_binary_accuracy: 0.7488 - output5_binary_accuracy: 0.9124 - output6_binary_accuracy: 0.8892 - output7_binary_accuracy: 0.7206 - output8_binary_accuracy: 0.8879 - output9_binary_accuracy: 0.9223 - output10_binary_accuracy: 0.9589 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9903\n",
            "Epoch 00001: val_loss improved from inf to 4.46806, saving model to BERT/BiLSTM_Context_addPositionEncoding_0.01.h5\n",
            "251/251 [==============================] - 214s 852ms/step - loss: 5.3154 - output1_loss: 0.2614 - output2_loss: 0.3553 - output3_loss: 0.4302 - output4_loss: 1.3369 - output5_loss: 0.4532 - output6_loss: 0.5167 - output7_loss: 0.7784 - output8_loss: 0.4414 - output9_loss: 0.4168 - output10_loss: 0.1867 - output11_loss: 0.1000 - output12_loss: 0.0386 - output1_binary_accuracy: 0.9564 - output2_binary_accuracy: 0.9360 - output3_binary_accuracy: 0.9197 - output4_binary_accuracy: 0.7488 - output5_binary_accuracy: 0.9124 - output6_binary_accuracy: 0.8892 - output7_binary_accuracy: 0.7206 - output8_binary_accuracy: 0.8879 - output9_binary_accuracy: 0.9223 - output10_binary_accuracy: 0.9589 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9903 - val_loss: 4.4681 - val_output1_loss: 0.1605 - val_output2_loss: 0.3152 - val_output3_loss: 0.3812 - val_output4_loss: 1.1862 - val_output5_loss: 0.3994 - val_output6_loss: 0.4829 - val_output7_loss: 0.6047 - val_output8_loss: 0.3422 - val_output9_loss: 0.3520 - val_output10_loss: 0.1770 - val_output11_loss: 0.0574 - val_output12_loss: 0.0093 - val_output1_binary_accuracy: 0.9775 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9277 - val_output4_binary_accuracy: 0.8008 - val_output5_binary_accuracy: 0.9199 - val_output6_binary_accuracy: 0.8955 - val_output7_binary_accuracy: 0.8018 - val_output8_binary_accuracy: 0.9131 - val_output9_binary_accuracy: 0.9248 - val_output10_binary_accuracy: 0.9492 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "251/251 [==============================] - ETA: 0s - loss: 4.4599 - output1_loss: 0.1472 - output2_loss: 0.2961 - output3_loss: 0.3885 - output4_loss: 1.2345 - output5_loss: 0.4055 - output6_loss: 0.4608 - output7_loss: 0.5632 - output8_loss: 0.3566 - output9_loss: 0.3668 - output10_loss: 0.1322 - output11_loss: 0.0842 - output12_loss: 0.0241 - output1_binary_accuracy: 0.9801 - output2_binary_accuracy: 0.9377 - output3_binary_accuracy: 0.9253 - output4_binary_accuracy: 0.7751 - output5_binary_accuracy: 0.9064 - output6_binary_accuracy: 0.8897 - output7_binary_accuracy: 0.8315 - output8_binary_accuracy: 0.9036 - output9_binary_accuracy: 0.9150 - output10_binary_accuracy: 0.9664 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfSJxN--xs1",
        "colab_type": "text"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDym2PgJ6ml",
        "colab_type": "code",
        "outputId": "68e3159e-2b61-4382-dd34-7cff6b5b8c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 3777, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_2 (SpatialDro (None, 3777, 768)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 3777, 128)    426496      spatial_dropout1d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 3777, 128)    98816       bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 257)          0           global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_average_pooling1d_2[0][0] \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 257)          66306       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 257)          0           concatenate_2[0][0]              \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 257)          66306       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 257)          0           add_4[0][0]                      \n",
            "                                                                 dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            258         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            258         add_5[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 661,020\n",
            "Trainable params: 661,020\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onSOnIBxPXa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(Name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZwqpZmP_pVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class testDataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=25, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim*3, self.n_channels))\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            pos=list_IDs_temp.loc[i,'utterance_pos']\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            latter=len(self.list_IDs.loc[(self.list_IDs['utterance_pos']==(pos+1))&(self.list_IDs['diaglogID']==(diaglogID)),:])\n",
        "            temp3=np.zeros(( 512, self.n_channels))\n",
        "            temp1=np.zeros(( 512, self.n_channels))\n",
        "\n",
        "            try:\n",
        "              if pos>1:\n",
        "                temp1=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID-1)+'_'+str(diaglogID)+'.npy')\n",
        "            except:\n",
        "              pass\n",
        "\n",
        "            try:\n",
        "              temp2=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "            except:\n",
        "              temp2=np.zeros(( 512, self.n_channels))\n",
        "            \n",
        "            try:\n",
        "              if latter==1:\n",
        "                temp3=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID+1)+'_'+str(diaglogID)+'.npy')\n",
        "            except:\n",
        "              pass\n",
        "            \n",
        "            temp=np.concatenate((temp1,temp2,temp3),axis=0)\n",
        "\n",
        "            # Store sample\n",
        "            X[i,0:temp.shape[0],:] =temp \n",
        "            del temp\n",
        "            del temp1\n",
        "            del temp2\n",
        "            del temp3\n",
        "\n",
        "        Pos=np.array(list_IDs_temp.loc[:,'utterance_pos'])\n",
        "        return [X,Pos]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnTSkm2_EBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator=testDataGenerator(Test,'Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MneDN8jV-spA",
        "colab_type": "code",
        "outputId": "453bd9ce-96cd-4d42-8217-bc1ee43270cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "prediction = model.predict_generator(test_generator)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-42-342c80f366ab>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0iEXswMaFjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Prediction=np.array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3GWspxEe93u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true=np.array(Test.iloc[:,0:N_CLASS])\n",
        "y_pred=Prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHjjga8Rf5pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hamming_score(y_true, y_pred, toggle_output=False):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        if toggle_output:\n",
        "            print('set_true: {0}'.format([id2label[id] for id in set_true]), 'set_pred: {0}'.format([id2label[id] for id in set_pred]))\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        #print('tmp_a: {0}'.format(tmp_a))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIWmhjAYgzlg",
        "colab_type": "code",
        "outputId": "04d2ba55-2b14-409d-d944-0ddc16409388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hamming_score(y_true, y_pred, toggle_output=False)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6516936936936937"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHKfPrFie7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "def f1(y_true, y_pred):\n",
        "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        \n",
        "        correct_preds += len(set_true & set_pred)\n",
        "        total_preds += len(set_pred)\n",
        "        total_correct += len(set_true)\n",
        "\n",
        "    p = correct_preds / total_preds if correct_preds > 0 else 0\n",
        "    r = correct_preds / total_correct if correct_preds > 0 else 0\n",
        "    f1 = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
        "    return p, r, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seCa3eD5cvdx",
        "colab_type": "code",
        "outputId": "db2b1643-e5fb-49dd-9621-c30dd3d090a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1(y_true, y_pred)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7297297297297297, 0.6227678571428571, 0.672019269369731)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TShpwbNovrP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}