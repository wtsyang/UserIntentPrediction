{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMG0De+eHVKVHB7zoTfW7V1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtsyang/UserIntentPrediction/blob/BERT/BERT/LSTM-multiPrediction_addPenality_32_lrschedule.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot0Ha--FR-S1",
        "colab_type": "code",
        "outputId": "b7e80f26-fafe-446f-cee5-34a1990f2c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6DT7DNwSNn9",
        "colab_type": "code",
        "outputId": "b515dfc8-8942-4adc-e78a-1ea052d7dc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/UserIntentPrediction'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/UserIntentPrediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De681umQRanU",
        "colab_type": "code",
        "outputId": "a2f17148-55b9-408c-e322-a569bb94ed08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
        "from tensorflow.keras.layers  import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import pickle\n",
        "import sklearn\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import smart_cond\n",
        "from functools import partial\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print('Tensorflow Version:',tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIpXSpeYR4rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_MODELS = 1\n",
        "BATCH_SIZE = 32\n",
        "LSTM_UNITS = 32\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
        "EPOCHS = 24\n",
        "MAX_LEN = 1259\n",
        "N_CHANNELS=768\n",
        "N_CLASS=12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lcdmN7BSHGl",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p2_0TqoR9ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train=pd.read_csv('data/Train_Preprocessing.csv').reset_index(drop=True)\n",
        "Valid=pd.read_csv('data/Valid_Preprocessing.csv').reset_index(drop=True)\n",
        "Test=pd.read_csv('data/Test_Preprocessing.csv').reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjliEKeAhO4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=BATCH_SIZE, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim, self.n_channels))\n",
        "        y = np.zeros((self.batch_size,self.n_classes), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            try:\n",
        "              temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              X[i,0:temp.shape[0],:] =temp \n",
        "              del temp\n",
        "            except:\n",
        "              print('Faile to load the data: BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "            # Store sample\n",
        "            # Store class\n",
        "            y[i,:] = np.array(list_IDs_temp.iloc[i,0:12])\n",
        "        Y=[]\n",
        "        for i in range(self.n_classes):\n",
        "          Y+=[y[:,i].reshape((self.batch_size,))]\n",
        "        return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ijHEnaK7opB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_generator = DataGenerator(Train,'Train')\n",
        "validation_generator = DataGenerator(Valid,'Valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBl5lHEfSGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict={}\n",
        "for i in range(N_CLASS):\n",
        "  ratioTrue=np.sum(Train.iloc[:,i])/len(Train)\n",
        "  classWeight_Dict['output'+str(i+1)]={0:1+1/((1-ratioTrue)/(ratioTrue)+1),1:1+(1-ratioTrue)/(ratioTrue)/((1-ratioTrue)/(ratioTrue)+1)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8C5_nNdl9Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight_Dict['output4'][1]+=1\n",
        "classWeight_Dict['output4'][0]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaoPIhG5PE0e",
        "colab_type": "code",
        "outputId": "03b7d9d7-1db4-4808-9ffd-4df4937a686e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "classWeight_Dict"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output1': {0: 1.2345571818407344, 1: 1.7654428181592656},\n",
              " 'output10': {0: 1.0336144877201687, 1: 1.9663855122798313},\n",
              " 'output11': {0: 1.0100471347060282, 1: 1.9899528652939718},\n",
              " 'output12': {0: 1.0018605805011163, 1: 1.9981394194988837},\n",
              " 'output2': {0: 1.0604068469362442, 1: 1.9395931530637558},\n",
              " 'output3': {0: 1.074423220044654, 1: 1.925576779955346},\n",
              " 'output4': {0: 2.247085090548251, 1: 2.752914909451749},\n",
              " 'output5': {0: 1.0875713222525427, 1: 1.912428677747457},\n",
              " 'output6': {0: 1.1071694368643017, 1: 1.8928305631356983},\n",
              " 'output7': {0: 1.3979161498387498, 1: 1.6020838501612502},\n",
              " 'output8': {0: 1.1070453981642272, 1: 1.8929546018357728},\n",
              " 'output9': {0: 1.076779955346068, 1: 1.923220044653932}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2mz_N6c7mEx",
        "colab_type": "text"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytjcvIOnMiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_crossentropy(y_true, y_pred, weights,from_logits=False,label_smoothing=0):\n",
        "\n",
        "    y_pred = ops.convert_to_tensor(y_pred)\n",
        "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
        "    label_smoothing = ops.convert_to_tensor(label_smoothing, dtype=K.floatx())\n",
        "    def _smooth_labels():\n",
        "      return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
        "    y_true = smart_cond.smart_cond(label_smoothing,_smooth_labels, lambda: y_true)\n",
        "    \n",
        "    mask0 = tf.subtract(tf.constant(1.0, dtype=K.floatx()),y_true)\n",
        "    mask0=tf.math.scalar_mul(tf.constant(weights[0], dtype=K.floatx()),mask0)\n",
        "    mask1 =tf.math.scalar_mul(tf.constant(weights[1], dtype=K.floatx()),y_true)\n",
        "    mask=tf.math.add(mask0,mask1)\n",
        "\n",
        "    return K.mean(tf.math.multiply(K.binary_crossentropy(y_true, y_pred, from_logits=from_logits),mask), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKQSOUM5saC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    inputs = Input(shape=(MAX_LEN,N_CHANNELS))\n",
        "    x = SpatialDropout1D(0.2)(inputs)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "\n",
        "    hidden = concatenate([\n",
        "        GlobalMaxPooling1D()(x),\n",
        "        GlobalAveragePooling1D()(x),\n",
        "    ])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    RESULT=[]\n",
        "    for i in range(N_CLASS):\n",
        "      RESULT+=[Dense(1, activation='sigmoid',name='output'+str(i+1))(hidden)]\n",
        "    LOSS={}\n",
        "    for i in  range(N_CLASS):\n",
        "      LOSS['output'+str(i+1)]=partial(binary_crossentropy, weights=classWeight_Dict['output'+str(i+1)])\n",
        "      LOSS['output'+str(i+1)].__name__ = 'loss'+str(i+1)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=RESULT)\n",
        "    model.compile(loss=LOSS, optimizer='adam',metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N37opYym6CCC",
        "colab_type": "code",
        "outputId": "02879f50-c9d6-40fb-ea52-89cea8946073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1259, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 1259, 768)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 1259, 64)     205056      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1259, 64)     24832       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 64)           0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 64)           0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          16512       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 128)          0           concatenate[0][0]                \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          16512       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 128)          0           add[0][0]                        \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            129         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            129         add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 264,460\n",
            "Trainable params: 264,460\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sb5GQmKeI_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback=ReduceLROnPlateau(patience=1,min_lr=0.00001,factor=0.3)\n",
        "Name='BERT/LSTM_addPenalty_32_lr.h5'\n",
        "checkpointer = ModelCheckpoint(filepath=Name, verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4To3UbV67kft",
        "colab_type": "code",
        "outputId": "91d1bd14-b9b0-48a0-d17c-d975176aeb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=training_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpointer,callback])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-d8713d19c50f>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Faile to load the data: BERT/vector/Train_178608_18987.npy\n",
            "Epoch 1/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 5.5911 - output1_loss: 0.6088 - output2_loss: 0.3468 - output3_loss: 0.4413 - output4_loss: 1.3757 - output5_loss: 0.4825 - output6_loss: 0.5056 - output7_loss: 0.6506 - output8_loss: 0.4419 - output9_loss: 0.4119 - output10_loss: 0.1910 - output11_loss: 0.0898 - output12_loss: 0.0452 - output1_binary_accuracy: 0.8028 - output2_binary_accuracy: 0.9319 - output3_binary_accuracy: 0.9207 - output4_binary_accuracy: 0.7475 - output5_binary_accuracy: 0.8962 - output6_binary_accuracy: 0.8919 - output7_binary_accuracy: 0.8007 - output8_binary_accuracy: 0.8970 - output9_binary_accuracy: 0.9202 - output10_binary_accuracy: 0.9483 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9904 \n",
            "Epoch 00001: val_loss improved from inf to 4.46460, saving model to BERT/LSTM_addPenalty_32_lr.h5\n",
            "251/251 [==============================] - 4460s 18s/step - loss: 5.5911 - output1_loss: 0.6088 - output2_loss: 0.3468 - output3_loss: 0.4413 - output4_loss: 1.3757 - output5_loss: 0.4825 - output6_loss: 0.5056 - output7_loss: 0.6506 - output8_loss: 0.4419 - output9_loss: 0.4119 - output10_loss: 0.1910 - output11_loss: 0.0898 - output12_loss: 0.0452 - output1_binary_accuracy: 0.8028 - output2_binary_accuracy: 0.9319 - output3_binary_accuracy: 0.9207 - output4_binary_accuracy: 0.7475 - output5_binary_accuracy: 0.8962 - output6_binary_accuracy: 0.8919 - output7_binary_accuracy: 0.8007 - output8_binary_accuracy: 0.8970 - output9_binary_accuracy: 0.9202 - output10_binary_accuracy: 0.9483 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9904 - val_loss: 4.4646 - val_output1_loss: 0.3518 - val_output2_loss: 0.3147 - val_output3_loss: 0.4000 - val_output4_loss: 1.2352 - val_output5_loss: 0.4115 - val_output6_loss: 0.4349 - val_output7_loss: 0.4941 - val_output8_loss: 0.3030 - val_output9_loss: 0.3211 - val_output10_loss: 0.1333 - val_output11_loss: 0.0599 - val_output12_loss: 0.0051 - val_output1_binary_accuracy: 0.9004 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9277 - val_output4_binary_accuracy: 0.7783 - val_output5_binary_accuracy: 0.9189 - val_output6_binary_accuracy: 0.9004 - val_output7_binary_accuracy: 0.8730 - val_output8_binary_accuracy: 0.9131 - val_output9_binary_accuracy: 0.9316 - val_output10_binary_accuracy: 0.9590 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 4.4524 - output1_loss: 0.3552 - output2_loss: 0.3030 - output3_loss: 0.3866 - output4_loss: 1.2426 - output5_loss: 0.4144 - output6_loss: 0.4078 - output7_loss: 0.4440 - output8_loss: 0.3311 - output9_loss: 0.3545 - output10_loss: 0.1100 - output11_loss: 0.0774 - output12_loss: 0.0257 - output1_binary_accuracy: 0.8980 - output2_binary_accuracy: 0.9394 - output3_binary_accuracy: 0.9232 - output4_binary_accuracy: 0.7776 - output5_binary_accuracy: 0.9105 - output6_binary_accuracy: 0.8998 - output7_binary_accuracy: 0.8851 - output8_binary_accuracy: 0.9066 - output9_binary_accuracy: 0.9151 - output10_binary_accuracy: 0.9660 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00002: val_loss improved from 4.46460 to 4.04581, saving model to BERT/LSTM_addPenalty_32_lr.h5\n",
            "251/251 [==============================] - 152s 605ms/step - loss: 4.4524 - output1_loss: 0.3552 - output2_loss: 0.3030 - output3_loss: 0.3866 - output4_loss: 1.2426 - output5_loss: 0.4144 - output6_loss: 0.4078 - output7_loss: 0.4440 - output8_loss: 0.3311 - output9_loss: 0.3545 - output10_loss: 0.1100 - output11_loss: 0.0774 - output12_loss: 0.0257 - output1_binary_accuracy: 0.8980 - output2_binary_accuracy: 0.9394 - output3_binary_accuracy: 0.9232 - output4_binary_accuracy: 0.7776 - output5_binary_accuracy: 0.9105 - output6_binary_accuracy: 0.8998 - output7_binary_accuracy: 0.8851 - output8_binary_accuracy: 0.9066 - output9_binary_accuracy: 0.9151 - output10_binary_accuracy: 0.9660 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981 - val_loss: 4.0458 - val_output1_loss: 0.2992 - val_output2_loss: 0.2820 - val_output3_loss: 0.3445 - val_output4_loss: 1.2140 - val_output5_loss: 0.3527 - val_output6_loss: 0.3592 - val_output7_loss: 0.4103 - val_output8_loss: 0.3263 - val_output9_loss: 0.2901 - val_output10_loss: 0.1071 - val_output11_loss: 0.0547 - val_output12_loss: 0.0055 - val_output1_binary_accuracy: 0.9111 - val_output2_binary_accuracy: 0.9316 - val_output3_binary_accuracy: 0.9248 - val_output4_binary_accuracy: 0.7725 - val_output5_binary_accuracy: 0.9160 - val_output6_binary_accuracy: 0.9199 - val_output7_binary_accuracy: 0.8926 - val_output8_binary_accuracy: 0.8799 - val_output9_binary_accuracy: 0.9307 - val_output10_binary_accuracy: 0.9678 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 4.0538 - output1_loss: 0.2984 - output2_loss: 0.2903 - output3_loss: 0.3563 - output4_loss: 1.1851 - output5_loss: 0.3667 - output6_loss: 0.3484 - output7_loss: 0.3970 - output8_loss: 0.2977 - output9_loss: 0.3318 - output10_loss: 0.0908 - output11_loss: 0.0684 - output12_loss: 0.0231 - output1_binary_accuracy: 0.9182 - output2_binary_accuracy: 0.9387 - output3_binary_accuracy: 0.9153 - output4_binary_accuracy: 0.7916 - output5_binary_accuracy: 0.9107 - output6_binary_accuracy: 0.9138 - output7_binary_accuracy: 0.9023 - output8_binary_accuracy: 0.9193 - output9_binary_accuracy: 0.9153 - output10_binary_accuracy: 0.9747 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00003: val_loss improved from 4.04581 to 3.74746, saving model to BERT/LSTM_addPenalty_32_lr.h5\n",
            "251/251 [==============================] - 141s 560ms/step - loss: 4.0538 - output1_loss: 0.2984 - output2_loss: 0.2903 - output3_loss: 0.3563 - output4_loss: 1.1851 - output5_loss: 0.3667 - output6_loss: 0.3484 - output7_loss: 0.3970 - output8_loss: 0.2977 - output9_loss: 0.3318 - output10_loss: 0.0908 - output11_loss: 0.0684 - output12_loss: 0.0231 - output1_binary_accuracy: 0.9182 - output2_binary_accuracy: 0.9387 - output3_binary_accuracy: 0.9153 - output4_binary_accuracy: 0.7916 - output5_binary_accuracy: 0.9107 - output6_binary_accuracy: 0.9138 - output7_binary_accuracy: 0.9023 - output8_binary_accuracy: 0.9193 - output9_binary_accuracy: 0.9153 - output10_binary_accuracy: 0.9747 - output11_binary_accuracy: 0.9899 - output12_binary_accuracy: 0.9981 - val_loss: 3.7475 - val_output1_loss: 0.2840 - val_output2_loss: 0.2627 - val_output3_loss: 0.3269 - val_output4_loss: 1.1663 - val_output5_loss: 0.3467 - val_output6_loss: 0.3102 - val_output7_loss: 0.3850 - val_output8_loss: 0.2581 - val_output9_loss: 0.2634 - val_output10_loss: 0.0941 - val_output11_loss: 0.0470 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9150 - val_output2_binary_accuracy: 0.9434 - val_output3_binary_accuracy: 0.9297 - val_output4_binary_accuracy: 0.7871 - val_output5_binary_accuracy: 0.9209 - val_output6_binary_accuracy: 0.9316 - val_output7_binary_accuracy: 0.8984 - val_output8_binary_accuracy: 0.9316 - val_output9_binary_accuracy: 0.9326 - val_output10_binary_accuracy: 0.9717 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 4/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.8338 - output1_loss: 0.2690 - output2_loss: 0.2709 - output3_loss: 0.3328 - output4_loss: 1.1433 - output5_loss: 0.3548 - output6_loss: 0.3208 - output7_loss: 0.3722 - output8_loss: 0.2836 - output9_loss: 0.3201 - output10_loss: 0.0826 - output11_loss: 0.0632 - output12_loss: 0.0206 - output1_binary_accuracy: 0.9272 - output2_binary_accuracy: 0.9399 - output3_binary_accuracy: 0.9192 - output4_binary_accuracy: 0.7972 - output5_binary_accuracy: 0.9126 - output6_binary_accuracy: 0.9243 - output7_binary_accuracy: 0.9051 - output8_binary_accuracy: 0.9227 - output9_binary_accuracy: 0.9119 - output10_binary_accuracy: 0.9771 - output11_binary_accuracy: 0.9902 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00004: val_loss improved from 3.74746 to 3.69343, saving model to BERT/LSTM_addPenalty_32_lr.h5\n",
            "251/251 [==============================] - 142s 566ms/step - loss: 3.8338 - output1_loss: 0.2690 - output2_loss: 0.2709 - output3_loss: 0.3328 - output4_loss: 1.1433 - output5_loss: 0.3548 - output6_loss: 0.3208 - output7_loss: 0.3722 - output8_loss: 0.2836 - output9_loss: 0.3201 - output10_loss: 0.0826 - output11_loss: 0.0632 - output12_loss: 0.0206 - output1_binary_accuracy: 0.9272 - output2_binary_accuracy: 0.9399 - output3_binary_accuracy: 0.9192 - output4_binary_accuracy: 0.7972 - output5_binary_accuracy: 0.9126 - output6_binary_accuracy: 0.9243 - output7_binary_accuracy: 0.9051 - output8_binary_accuracy: 0.9227 - output9_binary_accuracy: 0.9119 - output10_binary_accuracy: 0.9771 - output11_binary_accuracy: 0.9902 - output12_binary_accuracy: 0.9981 - val_loss: 3.6934 - val_output1_loss: 0.2794 - val_output2_loss: 0.2621 - val_output3_loss: 0.3145 - val_output4_loss: 1.1786 - val_output5_loss: 0.3374 - val_output6_loss: 0.3002 - val_output7_loss: 0.3646 - val_output8_loss: 0.2479 - val_output9_loss: 0.2777 - val_output10_loss: 0.0910 - val_output11_loss: 0.0382 - val_output12_loss: 0.0017 - val_output1_binary_accuracy: 0.9277 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9287 - val_output4_binary_accuracy: 0.7812 - val_output5_binary_accuracy: 0.9219 - val_output6_binary_accuracy: 0.9307 - val_output7_binary_accuracy: 0.9043 - val_output8_binary_accuracy: 0.9346 - val_output9_binary_accuracy: 0.9170 - val_output10_binary_accuracy: 0.9756 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.6630 - output1_loss: 0.2462 - output2_loss: 0.2557 - output3_loss: 0.3242 - output4_loss: 1.1181 - output5_loss: 0.3397 - output6_loss: 0.3031 - output7_loss: 0.3479 - output8_loss: 0.2666 - output9_loss: 0.3076 - output10_loss: 0.0763 - output11_loss: 0.0583 - output12_loss: 0.0192 - output1_binary_accuracy: 0.9361 - output2_binary_accuracy: 0.9450 - output3_binary_accuracy: 0.9183 - output4_binary_accuracy: 0.8037 - output5_binary_accuracy: 0.9131 - output6_binary_accuracy: 0.9308 - output7_binary_accuracy: 0.9121 - output8_binary_accuracy: 0.9275 - output9_binary_accuracy: 0.9178 - output10_binary_accuracy: 0.9753 - output11_binary_accuracy: 0.9915 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00005: val_loss improved from 3.69343 to 3.69255, saving model to BERT/LSTM_addPenalty_32_lr.h5\n",
            "251/251 [==============================] - 142s 566ms/step - loss: 3.6630 - output1_loss: 0.2462 - output2_loss: 0.2557 - output3_loss: 0.3242 - output4_loss: 1.1181 - output5_loss: 0.3397 - output6_loss: 0.3031 - output7_loss: 0.3479 - output8_loss: 0.2666 - output9_loss: 0.3076 - output10_loss: 0.0763 - output11_loss: 0.0583 - output12_loss: 0.0192 - output1_binary_accuracy: 0.9361 - output2_binary_accuracy: 0.9450 - output3_binary_accuracy: 0.9183 - output4_binary_accuracy: 0.8037 - output5_binary_accuracy: 0.9131 - output6_binary_accuracy: 0.9308 - output7_binary_accuracy: 0.9121 - output8_binary_accuracy: 0.9275 - output9_binary_accuracy: 0.9178 - output10_binary_accuracy: 0.9753 - output11_binary_accuracy: 0.9915 - output12_binary_accuracy: 0.9981 - val_loss: 3.6925 - val_output1_loss: 0.2985 - val_output2_loss: 0.2580 - val_output3_loss: 0.3086 - val_output4_loss: 1.1714 - val_output5_loss: 0.3627 - val_output6_loss: 0.2862 - val_output7_loss: 0.3539 - val_output8_loss: 0.2555 - val_output9_loss: 0.2672 - val_output10_loss: 0.0893 - val_output11_loss: 0.0390 - val_output12_loss: 0.0023 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7783 - val_output5_binary_accuracy: 0.8887 - val_output6_binary_accuracy: 0.9355 - val_output7_binary_accuracy: 0.9092 - val_output8_binary_accuracy: 0.9258 - val_output9_binary_accuracy: 0.9199 - val_output10_binary_accuracy: 0.9775 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.5133 - output1_loss: 0.2264 - output2_loss: 0.2436 - output3_loss: 0.3156 - output4_loss: 1.0755 - output5_loss: 0.3273 - output6_loss: 0.3011 - output7_loss: 0.3322 - output8_loss: 0.2595 - output9_loss: 0.2881 - output10_loss: 0.0732 - output11_loss: 0.0537 - output12_loss: 0.0173 - output1_binary_accuracy: 0.9416 - output2_binary_accuracy: 0.9463 - output3_binary_accuracy: 0.9178 - output4_binary_accuracy: 0.8161 - output5_binary_accuracy: 0.9186 - output6_binary_accuracy: 0.9297 - output7_binary_accuracy: 0.9167 - output8_binary_accuracy: 0.9280 - output9_binary_accuracy: 0.9163 - output10_binary_accuracy: 0.9787 - output11_binary_accuracy: 0.9918 - output12_binary_accuracy: 0.9983\n",
            "Epoch 00006: val_loss improved from 3.69255 to 3.63828, saving model to BERT/LSTM_addPenalty_32_lr.h5\n",
            "251/251 [==============================] - 142s 564ms/step - loss: 3.5133 - output1_loss: 0.2264 - output2_loss: 0.2436 - output3_loss: 0.3156 - output4_loss: 1.0755 - output5_loss: 0.3273 - output6_loss: 0.3011 - output7_loss: 0.3322 - output8_loss: 0.2595 - output9_loss: 0.2881 - output10_loss: 0.0732 - output11_loss: 0.0537 - output12_loss: 0.0173 - output1_binary_accuracy: 0.9416 - output2_binary_accuracy: 0.9463 - output3_binary_accuracy: 0.9178 - output4_binary_accuracy: 0.8161 - output5_binary_accuracy: 0.9186 - output6_binary_accuracy: 0.9297 - output7_binary_accuracy: 0.9167 - output8_binary_accuracy: 0.9280 - output9_binary_accuracy: 0.9163 - output10_binary_accuracy: 0.9787 - output11_binary_accuracy: 0.9918 - output12_binary_accuracy: 0.9983 - val_loss: 3.6383 - val_output1_loss: 0.2512 - val_output2_loss: 0.2420 - val_output3_loss: 0.3194 - val_output4_loss: 1.1856 - val_output5_loss: 0.3342 - val_output6_loss: 0.3030 - val_output7_loss: 0.3506 - val_output8_loss: 0.2510 - val_output9_loss: 0.2675 - val_output10_loss: 0.0893 - val_output11_loss: 0.0388 - val_output12_loss: 0.0057 - val_output1_binary_accuracy: 0.9229 - val_output2_binary_accuracy: 0.9375 - val_output3_binary_accuracy: 0.9219 - val_output4_binary_accuracy: 0.7861 - val_output5_binary_accuracy: 0.9268 - val_output6_binary_accuracy: 0.9297 - val_output7_binary_accuracy: 0.9121 - val_output8_binary_accuracy: 0.9268 - val_output9_binary_accuracy: 0.9072 - val_output10_binary_accuracy: 0.9766 - val_output11_binary_accuracy: 0.9932 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.3742 - output1_loss: 0.2053 - output2_loss: 0.2333 - output3_loss: 0.3027 - output4_loss: 1.0421 - output5_loss: 0.3162 - output6_loss: 0.2917 - output7_loss: 0.3154 - output8_loss: 0.2555 - output9_loss: 0.2760 - output10_loss: 0.0691 - output11_loss: 0.0483 - output12_loss: 0.0186 - output1_binary_accuracy: 0.9481 - output2_binary_accuracy: 0.9482 - output3_binary_accuracy: 0.9203 - output4_binary_accuracy: 0.8238 - output5_binary_accuracy: 0.9187 - output6_binary_accuracy: 0.9330 - output7_binary_accuracy: 0.9219 - output8_binary_accuracy: 0.9305 - output9_binary_accuracy: 0.9208 - output10_binary_accuracy: 0.9801 - output11_binary_accuracy: 0.9918 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00007: val_loss did not improve from 3.63828\n",
            "251/251 [==============================] - 142s 565ms/step - loss: 3.3742 - output1_loss: 0.2053 - output2_loss: 0.2333 - output3_loss: 0.3027 - output4_loss: 1.0421 - output5_loss: 0.3162 - output6_loss: 0.2917 - output7_loss: 0.3154 - output8_loss: 0.2555 - output9_loss: 0.2760 - output10_loss: 0.0691 - output11_loss: 0.0483 - output12_loss: 0.0186 - output1_binary_accuracy: 0.9481 - output2_binary_accuracy: 0.9482 - output3_binary_accuracy: 0.9203 - output4_binary_accuracy: 0.8238 - output5_binary_accuracy: 0.9187 - output6_binary_accuracy: 0.9330 - output7_binary_accuracy: 0.9219 - output8_binary_accuracy: 0.9305 - output9_binary_accuracy: 0.9208 - output10_binary_accuracy: 0.9801 - output11_binary_accuracy: 0.9918 - output12_binary_accuracy: 0.9981 - val_loss: 3.6428 - val_output1_loss: 0.2576 - val_output2_loss: 0.2695 - val_output3_loss: 0.3180 - val_output4_loss: 1.1910 - val_output5_loss: 0.3329 - val_output6_loss: 0.2958 - val_output7_loss: 0.3502 - val_output8_loss: 0.2411 - val_output9_loss: 0.2491 - val_output10_loss: 0.0966 - val_output11_loss: 0.0364 - val_output12_loss: 0.0045 - val_output1_binary_accuracy: 0.9209 - val_output2_binary_accuracy: 0.9502 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.7803 - val_output5_binary_accuracy: 0.9219 - val_output6_binary_accuracy: 0.9375 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9268 - val_output9_binary_accuracy: 0.9238 - val_output10_binary_accuracy: 0.9766 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 8/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 3.0497 - output1_loss: 0.1666 - output2_loss: 0.2127 - output3_loss: 0.2927 - output4_loss: 0.9554 - output5_loss: 0.2955 - output6_loss: 0.2627 - output7_loss: 0.2782 - output8_loss: 0.2224 - output9_loss: 0.2482 - output10_loss: 0.0573 - output11_loss: 0.0409 - output12_loss: 0.0172 - output1_binary_accuracy: 0.9602 - output2_binary_accuracy: 0.9523 - output3_binary_accuracy: 0.9236 - output4_binary_accuracy: 0.8393 - output5_binary_accuracy: 0.9229 - output6_binary_accuracy: 0.9394 - output7_binary_accuracy: 0.9336 - output8_binary_accuracy: 0.9397 - output9_binary_accuracy: 0.9284 - output10_binary_accuracy: 0.9839 - output11_binary_accuracy: 0.9932 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00008: val_loss improved from 3.63828 to 3.60180, saving model to BERT/LSTM_addPenalty_32_lr.h5\n",
            "251/251 [==============================] - 142s 566ms/step - loss: 3.0497 - output1_loss: 0.1666 - output2_loss: 0.2127 - output3_loss: 0.2927 - output4_loss: 0.9554 - output5_loss: 0.2955 - output6_loss: 0.2627 - output7_loss: 0.2782 - output8_loss: 0.2224 - output9_loss: 0.2482 - output10_loss: 0.0573 - output11_loss: 0.0409 - output12_loss: 0.0172 - output1_binary_accuracy: 0.9602 - output2_binary_accuracy: 0.9523 - output3_binary_accuracy: 0.9236 - output4_binary_accuracy: 0.8393 - output5_binary_accuracy: 0.9229 - output6_binary_accuracy: 0.9394 - output7_binary_accuracy: 0.9336 - output8_binary_accuracy: 0.9397 - output9_binary_accuracy: 0.9284 - output10_binary_accuracy: 0.9839 - output11_binary_accuracy: 0.9932 - output12_binary_accuracy: 0.9981 - val_loss: 3.6018 - val_output1_loss: 0.2780 - val_output2_loss: 0.2467 - val_output3_loss: 0.3069 - val_output4_loss: 1.1764 - val_output5_loss: 0.3292 - val_output6_loss: 0.2883 - val_output7_loss: 0.3577 - val_output8_loss: 0.2434 - val_output9_loss: 0.2471 - val_output10_loss: 0.0893 - val_output11_loss: 0.0351 - val_output12_loss: 0.0035 - val_output1_binary_accuracy: 0.9307 - val_output2_binary_accuracy: 0.9443 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.8008 - val_output5_binary_accuracy: 0.9092 - val_output6_binary_accuracy: 0.9375 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9316 - val_output9_binary_accuracy: 0.9150 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9941 - val_output12_binary_accuracy: 1.0000 - lr: 3.0000e-04\n",
            "Epoch 9/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.9456 - output1_loss: 0.1544 - output2_loss: 0.2032 - output3_loss: 0.2856 - output4_loss: 0.9243 - output5_loss: 0.2804 - output6_loss: 0.2636 - output7_loss: 0.2671 - output8_loss: 0.2168 - output9_loss: 0.2397 - output10_loss: 0.0554 - output11_loss: 0.0389 - output12_loss: 0.0162 - output1_binary_accuracy: 0.9629 - output2_binary_accuracy: 0.9522 - output3_binary_accuracy: 0.9227 - output4_binary_accuracy: 0.8476 - output5_binary_accuracy: 0.9234 - output6_binary_accuracy: 0.9385 - output7_binary_accuracy: 0.9346 - output8_binary_accuracy: 0.9416 - output9_binary_accuracy: 0.9294 - output10_binary_accuracy: 0.9832 - output11_binary_accuracy: 0.9934 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00009: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 562ms/step - loss: 2.9456 - output1_loss: 0.1544 - output2_loss: 0.2032 - output3_loss: 0.2856 - output4_loss: 0.9243 - output5_loss: 0.2804 - output6_loss: 0.2636 - output7_loss: 0.2671 - output8_loss: 0.2168 - output9_loss: 0.2397 - output10_loss: 0.0554 - output11_loss: 0.0389 - output12_loss: 0.0162 - output1_binary_accuracy: 0.9629 - output2_binary_accuracy: 0.9522 - output3_binary_accuracy: 0.9227 - output4_binary_accuracy: 0.8476 - output5_binary_accuracy: 0.9234 - output6_binary_accuracy: 0.9385 - output7_binary_accuracy: 0.9346 - output8_binary_accuracy: 0.9416 - output9_binary_accuracy: 0.9294 - output10_binary_accuracy: 0.9832 - output11_binary_accuracy: 0.9934 - output12_binary_accuracy: 0.9981 - val_loss: 3.6505 - val_output1_loss: 0.2844 - val_output2_loss: 0.2527 - val_output3_loss: 0.3151 - val_output4_loss: 1.1797 - val_output5_loss: 0.3508 - val_output6_loss: 0.2860 - val_output7_loss: 0.3643 - val_output8_loss: 0.2485 - val_output9_loss: 0.2420 - val_output10_loss: 0.0860 - val_output11_loss: 0.0376 - val_output12_loss: 0.0032 - val_output1_binary_accuracy: 0.9229 - val_output2_binary_accuracy: 0.9424 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.7949 - val_output5_binary_accuracy: 0.9258 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9043 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9277 - val_output10_binary_accuracy: 0.9736 - val_output11_binary_accuracy: 0.9961 - val_output12_binary_accuracy: 1.0000 - lr: 3.0000e-04\n",
            "Epoch 10/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.8192 - output1_loss: 0.1417 - output2_loss: 0.2014 - output3_loss: 0.2803 - output4_loss: 0.8767 - output5_loss: 0.2741 - output6_loss: 0.2495 - output7_loss: 0.2554 - output8_loss: 0.2050 - output9_loss: 0.2282 - output10_loss: 0.0525 - output11_loss: 0.0383 - output12_loss: 0.0162 - output1_binary_accuracy: 0.9666 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9207 - output4_binary_accuracy: 0.8603 - output5_binary_accuracy: 0.9294 - output6_binary_accuracy: 0.9424 - output7_binary_accuracy: 0.9360 - output8_binary_accuracy: 0.9462 - output9_binary_accuracy: 0.9349 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9932 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00010: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 562ms/step - loss: 2.8192 - output1_loss: 0.1417 - output2_loss: 0.2014 - output3_loss: 0.2803 - output4_loss: 0.8767 - output5_loss: 0.2741 - output6_loss: 0.2495 - output7_loss: 0.2554 - output8_loss: 0.2050 - output9_loss: 0.2282 - output10_loss: 0.0525 - output11_loss: 0.0383 - output12_loss: 0.0162 - output1_binary_accuracy: 0.9666 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9207 - output4_binary_accuracy: 0.8603 - output5_binary_accuracy: 0.9294 - output6_binary_accuracy: 0.9424 - output7_binary_accuracy: 0.9360 - output8_binary_accuracy: 0.9462 - output9_binary_accuracy: 0.9349 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9932 - output12_binary_accuracy: 0.9981 - val_loss: 3.6303 - val_output1_loss: 0.2794 - val_output2_loss: 0.2475 - val_output3_loss: 0.3185 - val_output4_loss: 1.1906 - val_output5_loss: 0.3337 - val_output6_loss: 0.2836 - val_output7_loss: 0.3634 - val_output8_loss: 0.2426 - val_output9_loss: 0.2419 - val_output10_loss: 0.0897 - val_output11_loss: 0.0363 - val_output12_loss: 0.0032 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.8047 - val_output5_binary_accuracy: 0.9219 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9053 - val_output8_binary_accuracy: 0.9385 - val_output9_binary_accuracy: 0.9209 - val_output10_binary_accuracy: 0.9756 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 9.0000e-05\n",
            "Epoch 11/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7587 - output1_loss: 0.1347 - output2_loss: 0.1959 - output3_loss: 0.2811 - output4_loss: 0.8536 - output5_loss: 0.2695 - output6_loss: 0.2516 - output7_loss: 0.2459 - output8_loss: 0.2012 - output9_loss: 0.2241 - output10_loss: 0.0513 - output11_loss: 0.0346 - output12_loss: 0.0153 - output1_binary_accuracy: 0.9686 - output2_binary_accuracy: 0.9537 - output3_binary_accuracy: 0.9262 - output4_binary_accuracy: 0.8611 - output5_binary_accuracy: 0.9304 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9397 - output8_binary_accuracy: 0.9482 - output9_binary_accuracy: 0.9335 - output10_binary_accuracy: 0.9841 - output11_binary_accuracy: 0.9940 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00011: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 142s 565ms/step - loss: 2.7587 - output1_loss: 0.1347 - output2_loss: 0.1959 - output3_loss: 0.2811 - output4_loss: 0.8536 - output5_loss: 0.2695 - output6_loss: 0.2516 - output7_loss: 0.2459 - output8_loss: 0.2012 - output9_loss: 0.2241 - output10_loss: 0.0513 - output11_loss: 0.0346 - output12_loss: 0.0153 - output1_binary_accuracy: 0.9686 - output2_binary_accuracy: 0.9537 - output3_binary_accuracy: 0.9262 - output4_binary_accuracy: 0.8611 - output5_binary_accuracy: 0.9304 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9397 - output8_binary_accuracy: 0.9482 - output9_binary_accuracy: 0.9335 - output10_binary_accuracy: 0.9841 - output11_binary_accuracy: 0.9940 - output12_binary_accuracy: 0.9981 - val_loss: 3.6362 - val_output1_loss: 0.2801 - val_output2_loss: 0.2498 - val_output3_loss: 0.3182 - val_output4_loss: 1.1909 - val_output5_loss: 0.3375 - val_output6_loss: 0.2843 - val_output7_loss: 0.3611 - val_output8_loss: 0.2471 - val_output9_loss: 0.2447 - val_output10_loss: 0.0827 - val_output11_loss: 0.0368 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9404 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.7979 - val_output5_binary_accuracy: 0.9209 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9082 - val_output8_binary_accuracy: 0.9307 - val_output9_binary_accuracy: 0.9258 - val_output10_binary_accuracy: 0.9766 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 2.7000e-05\n",
            "Epoch 12/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7448 - output1_loss: 0.1327 - output2_loss: 0.1902 - output3_loss: 0.2738 - output4_loss: 0.8495 - output5_loss: 0.2732 - output6_loss: 0.2481 - output7_loss: 0.2504 - output8_loss: 0.1997 - output9_loss: 0.2261 - output10_loss: 0.0509 - output11_loss: 0.0357 - output12_loss: 0.0144 - output1_binary_accuracy: 0.9717 - output2_binary_accuracy: 0.9568 - output3_binary_accuracy: 0.9262 - output4_binary_accuracy: 0.8647 - output5_binary_accuracy: 0.9282 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9373 - output8_binary_accuracy: 0.9471 - output9_binary_accuracy: 0.9350 - output10_binary_accuracy: 0.9847 - output11_binary_accuracy: 0.9941 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00012: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 562ms/step - loss: 2.7448 - output1_loss: 0.1327 - output2_loss: 0.1902 - output3_loss: 0.2738 - output4_loss: 0.8495 - output5_loss: 0.2732 - output6_loss: 0.2481 - output7_loss: 0.2504 - output8_loss: 0.1997 - output9_loss: 0.2261 - output10_loss: 0.0509 - output11_loss: 0.0357 - output12_loss: 0.0144 - output1_binary_accuracy: 0.9717 - output2_binary_accuracy: 0.9568 - output3_binary_accuracy: 0.9262 - output4_binary_accuracy: 0.8647 - output5_binary_accuracy: 0.9282 - output6_binary_accuracy: 0.9419 - output7_binary_accuracy: 0.9373 - output8_binary_accuracy: 0.9471 - output9_binary_accuracy: 0.9350 - output10_binary_accuracy: 0.9847 - output11_binary_accuracy: 0.9941 - output12_binary_accuracy: 0.9981 - val_loss: 3.6375 - val_output1_loss: 0.2782 - val_output2_loss: 0.2460 - val_output3_loss: 0.3192 - val_output4_loss: 1.1971 - val_output5_loss: 0.3363 - val_output6_loss: 0.2853 - val_output7_loss: 0.3653 - val_output8_loss: 0.2430 - val_output9_loss: 0.2401 - val_output10_loss: 0.0872 - val_output11_loss: 0.0367 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9277 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7979 - val_output5_binary_accuracy: 0.9219 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9346 - val_output9_binary_accuracy: 0.9229 - val_output10_binary_accuracy: 0.9756 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 13/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7458 - output1_loss: 0.1342 - output2_loss: 0.1937 - output3_loss: 0.2766 - output4_loss: 0.8514 - output5_loss: 0.2681 - output6_loss: 0.2471 - output7_loss: 0.2448 - output8_loss: 0.2001 - output9_loss: 0.2279 - output10_loss: 0.0517 - output11_loss: 0.0351 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9683 - output2_binary_accuracy: 0.9572 - output3_binary_accuracy: 0.9264 - output4_binary_accuracy: 0.8599 - output5_binary_accuracy: 0.9297 - output6_binary_accuracy: 0.9406 - output7_binary_accuracy: 0.9394 - output8_binary_accuracy: 0.9495 - output9_binary_accuracy: 0.9336 - output10_binary_accuracy: 0.9847 - output11_binary_accuracy: 0.9939 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00013: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 563ms/step - loss: 2.7458 - output1_loss: 0.1342 - output2_loss: 0.1937 - output3_loss: 0.2766 - output4_loss: 0.8514 - output5_loss: 0.2681 - output6_loss: 0.2471 - output7_loss: 0.2448 - output8_loss: 0.2001 - output9_loss: 0.2279 - output10_loss: 0.0517 - output11_loss: 0.0351 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9683 - output2_binary_accuracy: 0.9572 - output3_binary_accuracy: 0.9264 - output4_binary_accuracy: 0.8599 - output5_binary_accuracy: 0.9297 - output6_binary_accuracy: 0.9406 - output7_binary_accuracy: 0.9394 - output8_binary_accuracy: 0.9495 - output9_binary_accuracy: 0.9336 - output10_binary_accuracy: 0.9847 - output11_binary_accuracy: 0.9939 - output12_binary_accuracy: 0.9981 - val_loss: 3.6349 - val_output1_loss: 0.2775 - val_output2_loss: 0.2373 - val_output3_loss: 0.3187 - val_output4_loss: 1.1971 - val_output5_loss: 0.3338 - val_output6_loss: 0.2846 - val_output7_loss: 0.3626 - val_output8_loss: 0.2473 - val_output9_loss: 0.2444 - val_output10_loss: 0.0916 - val_output11_loss: 0.0368 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9414 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7949 - val_output5_binary_accuracy: 0.9219 - val_output6_binary_accuracy: 0.9404 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9326 - val_output9_binary_accuracy: 0.9229 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7364 - output1_loss: 0.1328 - output2_loss: 0.1903 - output3_loss: 0.2765 - output4_loss: 0.8459 - output5_loss: 0.2678 - output6_loss: 0.2474 - output7_loss: 0.2451 - output8_loss: 0.2019 - output9_loss: 0.2254 - output10_loss: 0.0528 - output11_loss: 0.0354 - output12_loss: 0.0151 - output1_binary_accuracy: 0.9685 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9260 - output4_binary_accuracy: 0.8609 - output5_binary_accuracy: 0.9304 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9389 - output8_binary_accuracy: 0.9440 - output9_binary_accuracy: 0.9331 - output10_binary_accuracy: 0.9834 - output11_binary_accuracy: 0.9943 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00014: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 563ms/step - loss: 2.7364 - output1_loss: 0.1328 - output2_loss: 0.1903 - output3_loss: 0.2765 - output4_loss: 0.8459 - output5_loss: 0.2678 - output6_loss: 0.2474 - output7_loss: 0.2451 - output8_loss: 0.2019 - output9_loss: 0.2254 - output10_loss: 0.0528 - output11_loss: 0.0354 - output12_loss: 0.0151 - output1_binary_accuracy: 0.9685 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9260 - output4_binary_accuracy: 0.8609 - output5_binary_accuracy: 0.9304 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9389 - output8_binary_accuracy: 0.9440 - output9_binary_accuracy: 0.9331 - output10_binary_accuracy: 0.9834 - output11_binary_accuracy: 0.9943 - output12_binary_accuracy: 0.9981 - val_loss: 3.6591 - val_output1_loss: 0.2831 - val_output2_loss: 0.2499 - val_output3_loss: 0.3171 - val_output4_loss: 1.1987 - val_output5_loss: 0.3384 - val_output6_loss: 0.2858 - val_output7_loss: 0.3641 - val_output8_loss: 0.2453 - val_output9_loss: 0.2453 - val_output10_loss: 0.0917 - val_output11_loss: 0.0367 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.7949 - val_output5_binary_accuracy: 0.9199 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9316 - val_output9_binary_accuracy: 0.9238 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7289 - output1_loss: 0.1322 - output2_loss: 0.1909 - output3_loss: 0.2764 - output4_loss: 0.8531 - output5_loss: 0.2695 - output6_loss: 0.2432 - output7_loss: 0.2403 - output8_loss: 0.1989 - output9_loss: 0.2226 - output10_loss: 0.0526 - output11_loss: 0.0343 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9696 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9216 - output4_binary_accuracy: 0.8629 - output5_binary_accuracy: 0.9295 - output6_binary_accuracy: 0.9436 - output7_binary_accuracy: 0.9397 - output8_binary_accuracy: 0.9490 - output9_binary_accuracy: 0.9343 - output10_binary_accuracy: 0.9837 - output11_binary_accuracy: 0.9943 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00015: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 142s 565ms/step - loss: 2.7289 - output1_loss: 0.1322 - output2_loss: 0.1909 - output3_loss: 0.2764 - output4_loss: 0.8531 - output5_loss: 0.2695 - output6_loss: 0.2432 - output7_loss: 0.2403 - output8_loss: 0.1989 - output9_loss: 0.2226 - output10_loss: 0.0526 - output11_loss: 0.0343 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9696 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9216 - output4_binary_accuracy: 0.8629 - output5_binary_accuracy: 0.9295 - output6_binary_accuracy: 0.9436 - output7_binary_accuracy: 0.9397 - output8_binary_accuracy: 0.9490 - output9_binary_accuracy: 0.9343 - output10_binary_accuracy: 0.9837 - output11_binary_accuracy: 0.9943 - output12_binary_accuracy: 0.9981 - val_loss: 3.6539 - val_output1_loss: 0.2835 - val_output2_loss: 0.2507 - val_output3_loss: 0.3157 - val_output4_loss: 1.1946 - val_output5_loss: 0.3354 - val_output6_loss: 0.2856 - val_output7_loss: 0.3641 - val_output8_loss: 0.2481 - val_output9_loss: 0.2451 - val_output10_loss: 0.0912 - val_output11_loss: 0.0367 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9277 - val_output2_binary_accuracy: 0.9395 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.7988 - val_output5_binary_accuracy: 0.9189 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9316 - val_output9_binary_accuracy: 0.9229 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 16/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7436 - output1_loss: 0.1337 - output2_loss: 0.1902 - output3_loss: 0.2753 - output4_loss: 0.8499 - output5_loss: 0.2694 - output6_loss: 0.2456 - output7_loss: 0.2462 - output8_loss: 0.2025 - output9_loss: 0.2266 - output10_loss: 0.0533 - output11_loss: 0.0359 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9679 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9233 - output4_binary_accuracy: 0.8635 - output5_binary_accuracy: 0.9309 - output6_binary_accuracy: 0.9424 - output7_binary_accuracy: 0.9390 - output8_binary_accuracy: 0.9458 - output9_binary_accuracy: 0.9338 - output10_binary_accuracy: 0.9847 - output11_binary_accuracy: 0.9939 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00016: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 142s 566ms/step - loss: 2.7436 - output1_loss: 0.1337 - output2_loss: 0.1902 - output3_loss: 0.2753 - output4_loss: 0.8499 - output5_loss: 0.2694 - output6_loss: 0.2456 - output7_loss: 0.2462 - output8_loss: 0.2025 - output9_loss: 0.2266 - output10_loss: 0.0533 - output11_loss: 0.0359 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9679 - output2_binary_accuracy: 0.9564 - output3_binary_accuracy: 0.9233 - output4_binary_accuracy: 0.8635 - output5_binary_accuracy: 0.9309 - output6_binary_accuracy: 0.9424 - output7_binary_accuracy: 0.9390 - output8_binary_accuracy: 0.9458 - output9_binary_accuracy: 0.9338 - output10_binary_accuracy: 0.9847 - output11_binary_accuracy: 0.9939 - output12_binary_accuracy: 0.9981 - val_loss: 3.6584 - val_output1_loss: 0.2831 - val_output2_loss: 0.2496 - val_output3_loss: 0.3193 - val_output4_loss: 1.1968 - val_output5_loss: 0.3396 - val_output6_loss: 0.2862 - val_output7_loss: 0.3650 - val_output8_loss: 0.2444 - val_output9_loss: 0.2430 - val_output10_loss: 0.0914 - val_output11_loss: 0.0368 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9238 - val_output2_binary_accuracy: 0.9395 - val_output3_binary_accuracy: 0.9180 - val_output4_binary_accuracy: 0.8008 - val_output5_binary_accuracy: 0.9180 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9316 - val_output9_binary_accuracy: 0.9268 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 17/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7343 - output1_loss: 0.1318 - output2_loss: 0.1900 - output3_loss: 0.2788 - output4_loss: 0.8500 - output5_loss: 0.2668 - output6_loss: 0.2449 - output7_loss: 0.2452 - output8_loss: 0.1994 - output9_loss: 0.2249 - output10_loss: 0.0519 - output11_loss: 0.0353 - output12_loss: 0.0152 - output1_binary_accuracy: 0.9692 - output2_binary_accuracy: 0.9549 - output3_binary_accuracy: 0.9246 - output4_binary_accuracy: 0.8634 - output5_binary_accuracy: 0.9314 - output6_binary_accuracy: 0.9429 - output7_binary_accuracy: 0.9390 - output8_binary_accuracy: 0.9491 - output9_binary_accuracy: 0.9349 - output10_binary_accuracy: 0.9853 - output11_binary_accuracy: 0.9941 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00017: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 563ms/step - loss: 2.7343 - output1_loss: 0.1318 - output2_loss: 0.1900 - output3_loss: 0.2788 - output4_loss: 0.8500 - output5_loss: 0.2668 - output6_loss: 0.2449 - output7_loss: 0.2452 - output8_loss: 0.1994 - output9_loss: 0.2249 - output10_loss: 0.0519 - output11_loss: 0.0353 - output12_loss: 0.0152 - output1_binary_accuracy: 0.9692 - output2_binary_accuracy: 0.9549 - output3_binary_accuracy: 0.9246 - output4_binary_accuracy: 0.8634 - output5_binary_accuracy: 0.9314 - output6_binary_accuracy: 0.9429 - output7_binary_accuracy: 0.9390 - output8_binary_accuracy: 0.9491 - output9_binary_accuracy: 0.9349 - output10_binary_accuracy: 0.9853 - output11_binary_accuracy: 0.9941 - output12_binary_accuracy: 0.9981 - val_loss: 3.6657 - val_output1_loss: 0.2833 - val_output2_loss: 0.2506 - val_output3_loss: 0.3199 - val_output4_loss: 1.2036 - val_output5_loss: 0.3327 - val_output6_loss: 0.2848 - val_output7_loss: 0.3648 - val_output8_loss: 0.2491 - val_output9_loss: 0.2457 - val_output10_loss: 0.0915 - val_output11_loss: 0.0366 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9248 - val_output2_binary_accuracy: 0.9395 - val_output3_binary_accuracy: 0.9170 - val_output4_binary_accuracy: 0.7988 - val_output5_binary_accuracy: 0.9189 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9053 - val_output8_binary_accuracy: 0.9307 - val_output9_binary_accuracy: 0.9258 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 18/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7264 - output1_loss: 0.1296 - output2_loss: 0.1925 - output3_loss: 0.2744 - output4_loss: 0.8454 - output5_loss: 0.2672 - output6_loss: 0.2461 - output7_loss: 0.2428 - output8_loss: 0.2014 - output9_loss: 0.2238 - output10_loss: 0.0523 - output11_loss: 0.0358 - output12_loss: 0.0151 - output1_binary_accuracy: 0.9705 - output2_binary_accuracy: 0.9551 - output3_binary_accuracy: 0.9249 - output4_binary_accuracy: 0.8633 - output5_binary_accuracy: 0.9303 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9397 - output8_binary_accuracy: 0.9460 - output9_binary_accuracy: 0.9360 - output10_binary_accuracy: 0.9848 - output11_binary_accuracy: 0.9940 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00018: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 142s 567ms/step - loss: 2.7264 - output1_loss: 0.1296 - output2_loss: 0.1925 - output3_loss: 0.2744 - output4_loss: 0.8454 - output5_loss: 0.2672 - output6_loss: 0.2461 - output7_loss: 0.2428 - output8_loss: 0.2014 - output9_loss: 0.2238 - output10_loss: 0.0523 - output11_loss: 0.0358 - output12_loss: 0.0151 - output1_binary_accuracy: 0.9705 - output2_binary_accuracy: 0.9551 - output3_binary_accuracy: 0.9249 - output4_binary_accuracy: 0.8633 - output5_binary_accuracy: 0.9303 - output6_binary_accuracy: 0.9415 - output7_binary_accuracy: 0.9397 - output8_binary_accuracy: 0.9460 - output9_binary_accuracy: 0.9360 - output10_binary_accuracy: 0.9848 - output11_binary_accuracy: 0.9940 - output12_binary_accuracy: 0.9981 - val_loss: 3.6551 - val_output1_loss: 0.2864 - val_output2_loss: 0.2506 - val_output3_loss: 0.3161 - val_output4_loss: 1.1983 - val_output5_loss: 0.3341 - val_output6_loss: 0.2829 - val_output7_loss: 0.3629 - val_output8_loss: 0.2465 - val_output9_loss: 0.2455 - val_output10_loss: 0.0918 - val_output11_loss: 0.0368 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.8008 - val_output5_binary_accuracy: 0.9199 - val_output6_binary_accuracy: 0.9414 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9326 - val_output9_binary_accuracy: 0.9229 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 19/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7261 - output1_loss: 0.1360 - output2_loss: 0.1888 - output3_loss: 0.2739 - output4_loss: 0.8371 - output5_loss: 0.2705 - output6_loss: 0.2446 - output7_loss: 0.2484 - output8_loss: 0.1981 - output9_loss: 0.2269 - output10_loss: 0.0519 - output11_loss: 0.0344 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9683 - output2_binary_accuracy: 0.9567 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8637 - output5_binary_accuracy: 0.9298 - output6_binary_accuracy: 0.9447 - output7_binary_accuracy: 0.9370 - output8_binary_accuracy: 0.9482 - output9_binary_accuracy: 0.9345 - output10_binary_accuracy: 0.9849 - output11_binary_accuracy: 0.9938 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00019: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 142s 564ms/step - loss: 2.7261 - output1_loss: 0.1360 - output2_loss: 0.1888 - output3_loss: 0.2739 - output4_loss: 0.8371 - output5_loss: 0.2705 - output6_loss: 0.2446 - output7_loss: 0.2484 - output8_loss: 0.1981 - output9_loss: 0.2269 - output10_loss: 0.0519 - output11_loss: 0.0344 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9683 - output2_binary_accuracy: 0.9567 - output3_binary_accuracy: 0.9254 - output4_binary_accuracy: 0.8637 - output5_binary_accuracy: 0.9298 - output6_binary_accuracy: 0.9447 - output7_binary_accuracy: 0.9370 - output8_binary_accuracy: 0.9482 - output9_binary_accuracy: 0.9345 - output10_binary_accuracy: 0.9849 - output11_binary_accuracy: 0.9938 - output12_binary_accuracy: 0.9981 - val_loss: 3.6706 - val_output1_loss: 0.2846 - val_output2_loss: 0.2510 - val_output3_loss: 0.3188 - val_output4_loss: 1.2002 - val_output5_loss: 0.3385 - val_output6_loss: 0.2855 - val_output7_loss: 0.3642 - val_output8_loss: 0.2500 - val_output9_loss: 0.2466 - val_output10_loss: 0.0912 - val_output11_loss: 0.0368 - val_output12_loss: 0.0032 - val_output1_binary_accuracy: 0.9268 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7998 - val_output5_binary_accuracy: 0.9160 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9053 - val_output8_binary_accuracy: 0.9307 - val_output9_binary_accuracy: 0.9229 - val_output10_binary_accuracy: 0.9756 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 20/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7129 - output1_loss: 0.1343 - output2_loss: 0.1918 - output3_loss: 0.2713 - output4_loss: 0.8370 - output5_loss: 0.2677 - output6_loss: 0.2439 - output7_loss: 0.2461 - output8_loss: 0.1979 - output9_loss: 0.2226 - output10_loss: 0.0510 - output11_loss: 0.0340 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9689 - output2_binary_accuracy: 0.9554 - output3_binary_accuracy: 0.9226 - output4_binary_accuracy: 0.8670 - output5_binary_accuracy: 0.9307 - output6_binary_accuracy: 0.9441 - output7_binary_accuracy: 0.9390 - output8_binary_accuracy: 0.9488 - output9_binary_accuracy: 0.9354 - output10_binary_accuracy: 0.9854 - output11_binary_accuracy: 0.9943 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00020: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 563ms/step - loss: 2.7129 - output1_loss: 0.1343 - output2_loss: 0.1918 - output3_loss: 0.2713 - output4_loss: 0.8370 - output5_loss: 0.2677 - output6_loss: 0.2439 - output7_loss: 0.2461 - output8_loss: 0.1979 - output9_loss: 0.2226 - output10_loss: 0.0510 - output11_loss: 0.0340 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9689 - output2_binary_accuracy: 0.9554 - output3_binary_accuracy: 0.9226 - output4_binary_accuracy: 0.8670 - output5_binary_accuracy: 0.9307 - output6_binary_accuracy: 0.9441 - output7_binary_accuracy: 0.9390 - output8_binary_accuracy: 0.9488 - output9_binary_accuracy: 0.9354 - output10_binary_accuracy: 0.9854 - output11_binary_accuracy: 0.9943 - output12_binary_accuracy: 0.9981 - val_loss: 3.6565 - val_output1_loss: 0.2870 - val_output2_loss: 0.2466 - val_output3_loss: 0.3169 - val_output4_loss: 1.2039 - val_output5_loss: 0.3347 - val_output6_loss: 0.2816 - val_output7_loss: 0.3661 - val_output8_loss: 0.2485 - val_output9_loss: 0.2395 - val_output10_loss: 0.0918 - val_output11_loss: 0.0368 - val_output12_loss: 0.0031 - val_output1_binary_accuracy: 0.9258 - val_output2_binary_accuracy: 0.9395 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.7998 - val_output5_binary_accuracy: 0.9209 - val_output6_binary_accuracy: 0.9404 - val_output7_binary_accuracy: 0.9082 - val_output8_binary_accuracy: 0.9307 - val_output9_binary_accuracy: 0.9258 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 21/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7376 - output1_loss: 0.1342 - output2_loss: 0.1937 - output3_loss: 0.2763 - output4_loss: 0.8487 - output5_loss: 0.2663 - output6_loss: 0.2479 - output7_loss: 0.2468 - output8_loss: 0.1983 - output9_loss: 0.2257 - output10_loss: 0.0500 - output11_loss: 0.0346 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9688 - output2_binary_accuracy: 0.9538 - output3_binary_accuracy: 0.9234 - output4_binary_accuracy: 0.8606 - output5_binary_accuracy: 0.9299 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9395 - output8_binary_accuracy: 0.9496 - output9_binary_accuracy: 0.9345 - output10_binary_accuracy: 0.9856 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00021: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 564ms/step - loss: 2.7376 - output1_loss: 0.1342 - output2_loss: 0.1937 - output3_loss: 0.2763 - output4_loss: 0.8487 - output5_loss: 0.2663 - output6_loss: 0.2479 - output7_loss: 0.2468 - output8_loss: 0.1983 - output9_loss: 0.2257 - output10_loss: 0.0500 - output11_loss: 0.0346 - output12_loss: 0.0150 - output1_binary_accuracy: 0.9688 - output2_binary_accuracy: 0.9538 - output3_binary_accuracy: 0.9234 - output4_binary_accuracy: 0.8606 - output5_binary_accuracy: 0.9299 - output6_binary_accuracy: 0.9422 - output7_binary_accuracy: 0.9395 - output8_binary_accuracy: 0.9496 - output9_binary_accuracy: 0.9345 - output10_binary_accuracy: 0.9856 - output11_binary_accuracy: 0.9933 - output12_binary_accuracy: 0.9981 - val_loss: 3.6648 - val_output1_loss: 0.2820 - val_output2_loss: 0.2511 - val_output3_loss: 0.3119 - val_output4_loss: 1.2023 - val_output5_loss: 0.3398 - val_output6_loss: 0.2859 - val_output7_loss: 0.3657 - val_output8_loss: 0.2492 - val_output9_loss: 0.2453 - val_output10_loss: 0.0915 - val_output11_loss: 0.0370 - val_output12_loss: 0.0032 - val_output1_binary_accuracy: 0.9268 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.8018 - val_output5_binary_accuracy: 0.9189 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9287 - val_output9_binary_accuracy: 0.9248 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 22/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7256 - output1_loss: 0.1299 - output2_loss: 0.1945 - output3_loss: 0.2754 - output4_loss: 0.8490 - output5_loss: 0.2672 - output6_loss: 0.2425 - output7_loss: 0.2405 - output8_loss: 0.1990 - output9_loss: 0.2256 - output10_loss: 0.0505 - output11_loss: 0.0357 - output12_loss: 0.0157 - output1_binary_accuracy: 0.9701 - output2_binary_accuracy: 0.9551 - output3_binary_accuracy: 0.9243 - output4_binary_accuracy: 0.8597 - output5_binary_accuracy: 0.9319 - output6_binary_accuracy: 0.9445 - output7_binary_accuracy: 0.9400 - output8_binary_accuracy: 0.9462 - output9_binary_accuracy: 0.9348 - output10_binary_accuracy: 0.9857 - output11_binary_accuracy: 0.9935 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00022: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 563ms/step - loss: 2.7256 - output1_loss: 0.1299 - output2_loss: 0.1945 - output3_loss: 0.2754 - output4_loss: 0.8490 - output5_loss: 0.2672 - output6_loss: 0.2425 - output7_loss: 0.2405 - output8_loss: 0.1990 - output9_loss: 0.2256 - output10_loss: 0.0505 - output11_loss: 0.0357 - output12_loss: 0.0157 - output1_binary_accuracy: 0.9701 - output2_binary_accuracy: 0.9551 - output3_binary_accuracy: 0.9243 - output4_binary_accuracy: 0.8597 - output5_binary_accuracy: 0.9319 - output6_binary_accuracy: 0.9445 - output7_binary_accuracy: 0.9400 - output8_binary_accuracy: 0.9462 - output9_binary_accuracy: 0.9348 - output10_binary_accuracy: 0.9857 - output11_binary_accuracy: 0.9935 - output12_binary_accuracy: 0.9981 - val_loss: 3.6741 - val_output1_loss: 0.2855 - val_output2_loss: 0.2518 - val_output3_loss: 0.3187 - val_output4_loss: 1.2076 - val_output5_loss: 0.3373 - val_output6_loss: 0.2834 - val_output7_loss: 0.3628 - val_output8_loss: 0.2492 - val_output9_loss: 0.2465 - val_output10_loss: 0.0912 - val_output11_loss: 0.0370 - val_output12_loss: 0.0033 - val_output1_binary_accuracy: 0.9248 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7949 - val_output5_binary_accuracy: 0.9160 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9062 - val_output8_binary_accuracy: 0.9307 - val_output9_binary_accuracy: 0.9209 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 23/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.7172 - output1_loss: 0.1339 - output2_loss: 0.1873 - output3_loss: 0.2774 - output4_loss: 0.8509 - output5_loss: 0.2668 - output6_loss: 0.2439 - output7_loss: 0.2395 - output8_loss: 0.1983 - output9_loss: 0.2184 - output10_loss: 0.0515 - output11_loss: 0.0336 - output12_loss: 0.0157 - output1_binary_accuracy: 0.9691 - output2_binary_accuracy: 0.9534 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8619 - output5_binary_accuracy: 0.9293 - output6_binary_accuracy: 0.9429 - output7_binary_accuracy: 0.9419 - output8_binary_accuracy: 0.9468 - output9_binary_accuracy: 0.9348 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9944 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00023: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 563ms/step - loss: 2.7172 - output1_loss: 0.1339 - output2_loss: 0.1873 - output3_loss: 0.2774 - output4_loss: 0.8509 - output5_loss: 0.2668 - output6_loss: 0.2439 - output7_loss: 0.2395 - output8_loss: 0.1983 - output9_loss: 0.2184 - output10_loss: 0.0515 - output11_loss: 0.0336 - output12_loss: 0.0157 - output1_binary_accuracy: 0.9691 - output2_binary_accuracy: 0.9534 - output3_binary_accuracy: 0.9214 - output4_binary_accuracy: 0.8619 - output5_binary_accuracy: 0.9293 - output6_binary_accuracy: 0.9429 - output7_binary_accuracy: 0.9419 - output8_binary_accuracy: 0.9468 - output9_binary_accuracy: 0.9348 - output10_binary_accuracy: 0.9846 - output11_binary_accuracy: 0.9944 - output12_binary_accuracy: 0.9981 - val_loss: 3.6717 - val_output1_loss: 0.2846 - val_output2_loss: 0.2517 - val_output3_loss: 0.3182 - val_output4_loss: 1.2050 - val_output5_loss: 0.3370 - val_output6_loss: 0.2857 - val_output7_loss: 0.3657 - val_output8_loss: 0.2491 - val_output9_loss: 0.2432 - val_output10_loss: 0.0916 - val_output11_loss: 0.0368 - val_output12_loss: 0.0032 - val_output1_binary_accuracy: 0.9248 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9189 - val_output4_binary_accuracy: 0.7969 - val_output5_binary_accuracy: 0.9199 - val_output6_binary_accuracy: 0.9385 - val_output7_binary_accuracy: 0.9072 - val_output8_binary_accuracy: 0.9297 - val_output9_binary_accuracy: 0.9248 - val_output10_binary_accuracy: 0.9756 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 24/24\n",
            "251/251 [==============================] - ETA: 0s - loss: 2.6923 - output1_loss: 0.1282 - output2_loss: 0.1904 - output3_loss: 0.2747 - output4_loss: 0.8384 - output5_loss: 0.2645 - output6_loss: 0.2444 - output7_loss: 0.2396 - output8_loss: 0.1928 - output9_loss: 0.2200 - output10_loss: 0.0497 - output11_loss: 0.0344 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9717 - output2_binary_accuracy: 0.9556 - output3_binary_accuracy: 0.9231 - output4_binary_accuracy: 0.8663 - output5_binary_accuracy: 0.9309 - output6_binary_accuracy: 0.9435 - output7_binary_accuracy: 0.9411 - output8_binary_accuracy: 0.9503 - output9_binary_accuracy: 0.9368 - output10_binary_accuracy: 0.9861 - output11_binary_accuracy: 0.9938 - output12_binary_accuracy: 0.9981\n",
            "Epoch 00024: val_loss did not improve from 3.60180\n",
            "251/251 [==============================] - 141s 560ms/step - loss: 2.6923 - output1_loss: 0.1282 - output2_loss: 0.1904 - output3_loss: 0.2747 - output4_loss: 0.8384 - output5_loss: 0.2645 - output6_loss: 0.2444 - output7_loss: 0.2396 - output8_loss: 0.1928 - output9_loss: 0.2200 - output10_loss: 0.0497 - output11_loss: 0.0344 - output12_loss: 0.0155 - output1_binary_accuracy: 0.9717 - output2_binary_accuracy: 0.9556 - output3_binary_accuracy: 0.9231 - output4_binary_accuracy: 0.8663 - output5_binary_accuracy: 0.9309 - output6_binary_accuracy: 0.9435 - output7_binary_accuracy: 0.9411 - output8_binary_accuracy: 0.9503 - output9_binary_accuracy: 0.9368 - output10_binary_accuracy: 0.9861 - output11_binary_accuracy: 0.9938 - output12_binary_accuracy: 0.9981 - val_loss: 3.6690 - val_output1_loss: 0.2816 - val_output2_loss: 0.2510 - val_output3_loss: 0.3175 - val_output4_loss: 1.2057 - val_output5_loss: 0.3364 - val_output6_loss: 0.2858 - val_output7_loss: 0.3655 - val_output8_loss: 0.2481 - val_output9_loss: 0.2454 - val_output10_loss: 0.0917 - val_output11_loss: 0.0369 - val_output12_loss: 0.0032 - val_output1_binary_accuracy: 0.9277 - val_output2_binary_accuracy: 0.9385 - val_output3_binary_accuracy: 0.9199 - val_output4_binary_accuracy: 0.7969 - val_output5_binary_accuracy: 0.9189 - val_output6_binary_accuracy: 0.9395 - val_output7_binary_accuracy: 0.9082 - val_output8_binary_accuracy: 0.9307 - val_output9_binary_accuracy: 0.9229 - val_output10_binary_accuracy: 0.9746 - val_output11_binary_accuracy: 0.9951 - val_output12_binary_accuracy: 1.0000 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f52a324b400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfSJxN--xs1",
        "colab_type": "text"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDym2PgJ6ml",
        "colab_type": "code",
        "outputId": "8e074c5a-7c37-490d-ded1-263a36069d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1259, 768)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d (SpatialDropo (None, 1259, 768)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 1259, 128)    426496      spatial_dropout1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1259, 128)    98816       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          65792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256)          0           concatenate[0][0]                \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           add[0][0]                        \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output1 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output2 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output3 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output4 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output5 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output6 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output7 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output8 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output9 (Dense)                 (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output10 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output11 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "output12 (Dense)                (None, 1)            257         add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 659,980\n",
            "Trainable params: 659,980\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onSOnIBxPXa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(Name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZwqpZmP_pVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class testDataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, pdDataFrame, dbName, labels=['oQ', 'RQ', 'CQ', 'FD', 'FQ', 'IR', 'PA', 'PF', 'NF', 'GG', 'JK', 'O'],\\\n",
        "                 batch_size=25, dim=MAX_LEN, n_channels=N_CHANNELS,\\\n",
        "                 n_classes=N_CLASS, shuffle=False):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = pdDataFrame\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.dbName=dbName\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = self.list_IDs.iloc[indexes,:]\n",
        "\n",
        "        # Generate data\n",
        "        X = self.__data_generation(list_IDs_temp.reset_index(drop=True))\n",
        "\n",
        "        return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.dim, self.n_channels))\n",
        "        #y = np.zeros((self.batch_size,self.n_classes), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i in range(len(list_IDs_temp)):\n",
        "            utterenceID=list_IDs_temp.loc[i,'id']\n",
        "            diaglogID=list_IDs_temp.loc[i,'diaglogID']\n",
        "            try:\n",
        "              temp=np.load('BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "              X[i,0:temp.shape[0],:] =temp \n",
        "              del temp\n",
        "            except:\n",
        "              print('Faile to load the data: BERT/vector/'+self.dbName+'_'+str(utterenceID)+'_'+str(diaglogID)+'.npy')\n",
        "            # Store sample\n",
        "            # Store class\n",
        "            #y[i,:] = np.array(list_IDs_temp.iloc[i,0:12])\n",
        "\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgnTSkm2_EBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator=testDataGenerator(Test,'Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MneDN8jV-spA",
        "colab_type": "code",
        "outputId": "caf1c198-3f67-4772-8081-6287738604a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "prediction = model.predict_generator(test_generator)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-342c80f366ab>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0iEXswMaFjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Prediction=np.array(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3GWspxEe93u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true=np.array(Test.iloc[:,0:N_CLASS])\n",
        "y_pred=Prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHjjga8Rf5pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hamming_score(y_true, y_pred, toggle_output=False):\n",
        "    '''\n",
        "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
        "    https://stackoverflow.com/q/32239577/395857\n",
        "    '''\n",
        "    acc_list = []\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        if toggle_output:\n",
        "            print('set_true: {0}'.format([id2label[id] for id in set_true]), 'set_pred: {0}'.format([id2label[id] for id in set_pred]))\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        #print('tmp_a: {0}'.format(tmp_a))\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIWmhjAYgzlg",
        "colab_type": "code",
        "outputId": "d9103424-c852-4763-b2ca-d1715d1ea22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hamming_score(y_true, y_pred, toggle_output=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6301261261261261"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHKfPrFie7Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   \n",
        "def f1(y_true, y_pred):\n",
        "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i,:])[0])\n",
        "        set_pred = set( np.where(y_pred[:,i,0]>=0.5)[0])\n",
        "        \n",
        "        correct_preds += len(set_true & set_pred)\n",
        "        total_preds += len(set_pred)\n",
        "        total_correct += len(set_true)\n",
        "\n",
        "    p = correct_preds / total_preds if correct_preds > 0 else 0\n",
        "    r = correct_preds / total_correct if correct_preds > 0 else 0\n",
        "    f1 = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
        "    return p, r, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seCa3eD5cvdx",
        "colab_type": "code",
        "outputId": "3e88912a-b1ad-4d62-c79e-12ce1ef56e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1(y_true, y_pred)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7060301507537688, 0.6272321428571429, 0.6643026004728132)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgbLgBxPLAs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}